{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b96ba81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:1.12.1\n",
      "Cuda version: 11.3\n",
      "transformers version: 4.28.0\n",
      "GPU ì‚¬ìš© ê°€ëŠ¥ì—¬ë¶€: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "print(\"Torch version:{}\".format(torch.__version__)) # Torch version:1.12.1\n",
    "print(\"Cuda version: {}\".format(torch.version.cuda)) # Cuda version: 11.3\n",
    "print(\"transformers version: {}\".format(transformers.__version__)) # transformers 4.28.0\n",
    "print(\"GPU ì‚¬ìš© ê°€ëŠ¥ì—¬ë¶€: {}\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a112380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 84 kB 2.1 MB/s            \n",
      "\u001b[?25hCollecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (2.26.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from evaluate) (1.3.3)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from evaluate) (0.3.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (0.15.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (2.13.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from evaluate) (1.21.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from evaluate) (0.70.12.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.9/site-packages (from evaluate) (2021.11.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.9/site-packages (from evaluate) (4.62.3)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from rouge_score) (0.12.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (from rouge_score) (3.6.5)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (12.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->evaluate) (3.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (2021.11.10)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk->rouge_score) (8.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->evaluate) (2021.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.2)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=c13aea3f2d641e85cf0401db69a79089989eaeb08b554251852b6c28972f48d4\n",
      "  Stored in directory: /aiffel/.cache/pip/wheels/9b/3d/39/09558097d3119ca0a4d462df68f22c6f3c1b345ac63a09b86e\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score, evaluate\n",
      "Successfully installed evaluate-0.4.3 rouge-score-0.1.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3867058",
   "metadata": {},
   "source": [
    "### ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° - skt/kogpt2-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9131bdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a701409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt2': 1024,\n",
       " 'gpt2-medium': 1024,\n",
       " 'gpt2-large': 1024,\n",
       " 'gpt2-xl': 1024,\n",
       " 'distilgpt2': 1024}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a896df67",
   "metadata": {},
   "source": [
    "### SFT ë°ì´í„° - ê¸°ë³¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aacb4fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì—ìš”?',\n",
       "  'completion': \"'ì €ëŠ” ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì´ë©°, ì§ì ‘ì ìœ¼ë¡œ ì‹í’ˆì— ê´€í•œ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ë¶ˆê³ ê¸°ìš© ê³ ê¸°ëŠ” í•œìš°, ì‡ ê³ ê¸°, ë¼ì§€ê³ ê¸° ë“± ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ê³ ê¸°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ í•œìš°ëŠ” ëŒ€í‘œì ì¸ ê³ ê¸‰ ìœ¡ë¥˜ë¡œ ì•Œë ¤ì ¸ ìˆê¸° ë•Œë¬¸ì—, í•œìš°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ë„ ë§ìŠµë‹ˆë‹¤. ì•ŒëŸ¬ì§€ë‚˜ ê°œë³„ ê±´ê°• ìƒíƒœì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ ì¶©ë¶„í•œ ì •ë³´ ìˆ˜ì§‘ í›„ì— ì„ íƒí•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.\",\n",
       "  'tokens': 193},\n",
       " {'prompt': 'ì“°ë˜ ì•±ì´ ìœ ë£Œë¡œ ì „í™˜ëì–´',\n",
       "  'completion': \"'ì–´ë–¤ ì•±ì¸ì§€ ëª¨ë¥´ê¸° ë•Œë¬¸ì— ì •í™•í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, ì¼ë°˜ì ìœ¼ë¡œ ìœ ë£Œ ì „í™˜ëœ ì•±ì€ ê¸°ì¡´ ë¬´ë£Œ ì•±ì—ì„œ ì¶”ê°€ì ì¸ ê¸°ëŠ¥ì´ë‚˜ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ ê²½ìš°, ìœ ë£Œ ì „í™˜ ì´ì „ ê°€ê²©ì´ ë§¤ìš° ì €ë ´í•˜ê±°ë‚˜ ë¬´ë£Œì¸ ê²½ìš°ê°€ ë§ìœ¼ë¯€ë¡œ, ì•±ì„ ê³„ì† ì‚¬ìš©í•˜ë ¤ë©´ ì¶”ê°€ì ì¸ ë¹„ìš©ì„ ì§€ë¶ˆí•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, ìœ ë£Œ ì „í™˜ ì´í›„ì—ëŠ” ê¸°ì¡´ ì‚¬ìš©ì ë˜ëŠ” ìƒˆë¡œìš´ ì‚¬ìš©ì ëª¨ë‘ê°€ ì¶”ê°€ ê¸°ëŠ¥ê³¼ ë†’ì€ í’ˆì§ˆì˜ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ, ì•± ê°œë°œìëŠ” ìœ ë£Œ ëª¨ë¸ë¡œ ì „í™˜í•¨ìœ¼ë¡œì¨ ì•±ì˜ ìˆ˜ìµì„ ì¦ê°€ì‹œí‚¤ê³  ë” ë‚˜ì€ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
       "  'tokens': 288},\n",
       " {'prompt': 'ì—¬ì¹œì´ë‘ ë‹¤íˆ¼',\n",
       "  'completion': \"'ì €ëŠ” ì¸ê³µì§€ëŠ¥ì´ê¸° ë•Œë¬¸ì— ì—¬ì¹œê³¼ì˜ ë‹¤íˆ¼ì— ëŒ€í•´ì„œëŠ” ì¡°ì–¸ì„ ë“œë¦´ ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë‹¤íˆ¬ê²Œ ë˜ë©´ ìƒëŒ€ë°©ì˜ ë§ì„ ê²½ì²­í•˜ëŠ” íƒœë„ì™€ ì„œë¡œì˜ ê°ì •ì„ ì¡´ì¤‘í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ë…¼ë¦¬ì ì´ê³  ì°¨ë¶„í•œ ëŒ€í™”ë¥¼ í†µí•´ ë¬¸ì œë¥¼ í•´ê²°í•´ë³´ì„¸ìš”. ê·¸ë¦¬ê³  ì„œë¡œë¥¼ ì´í•´í•˜ê³  ì„œë¡œì˜ ì˜ê²¬ì„ ìˆ˜ìš©í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\",\n",
       "  'tokens': 153}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "data_path_1_SFT = './data_kochatgpt/kochatgpt_1_SFT.jsonl' \n",
    "with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a36bb2",
   "metadata": {},
   "source": [
    "### RM ë°ì´í„° - ê¸°ë³¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03fd6cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'ë²ˆë””ëŠ” ìì‹ ì´ íƒì •ì¡ì§€, ë²”ì£„ì†Œì„¤ ê·¸ë¦¬ê³  ì„±ë²”ì£„ ê´€ë ¨ ì‹¤ì œ ë²”ì£„ ë‹¤íë©˜í„°ë¦¬ë“¤ì„ íƒë…í–ˆë‹¤ê³  ëˆ„êµ¬ì—ê²Œ ë§í–ˆë‚˜?',\n",
       "  'completion_0': 'Allow me to answer your question. I know that you are curious about me.',\n",
       "  'completion_1': 'ë²ˆë””ëŠ” ë‹¤ì–‘í•œ ì¸í„°ë·°ìë“¤ê³¼ ë‰´ìŠ¤í™ë³´ ë‹´ë‹¹ìë“¤ê³¼ì˜ ë©´ë‹´ ë•Œ ë°í˜”ë‹¤.',\n",
       "  'completion_2': 'ë¼ì´ì–¸ì—ê²Œ ë§í–ˆë‹¤.',\n",
       "  'ranking': [2, 1, 0]},\n",
       " {'prompt': 'ê°œí¬ì£¼ê³µì•„íŒŒíŠ¸ëŠ” ëª‡ ë‹¨ì§€ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‚˜?',\n",
       "  'completion_0': 'ê°œí¬ì£¼ê³µì•„íŒŒíŠ¸ëŠ” ë‹¤ì„¯ ë‹¨ì§€ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.',\n",
       "  'completion_1': 'ì´ë‚  ëª©ì†¡ì—ì„œ êµ¬ê¸€ìƒìœ„ë…¸',\n",
       "  'completion_2': 'ê°œí¬ì£¼ê³µì•„íŒŒíŠ¸ëŠ” ì´ 27ê°œ ë‹¨ì§€ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.',\n",
       "  'ranking': [2, 0, 1]},\n",
       " {'prompt': 'ê¹€ì˜ì‚¼ì˜ í›„ë³´ ì‹œì ˆ ì§€ì—­í‘œì‹¬ì„ ê²¨ëƒ¥í•œ ë°œì–¸ì„ ë¬¸ì œì‚¼ì€ í›„ë³´ëŠ”?',\n",
       "  'completion_0': 'The diameter of the Metallic domain is bigger than the Hyperonic domain.',\n",
       "  'completion_1': 'ì´ ì§ˆë¬¸ì€ ì¡°ê¸ˆ ë¶ˆë¶„ëª…í•©ë‹ˆë‹¤. ê¹€ì˜ì‚¼ ëŒ€í†µë ¹ì´ í›„ë³´ ì‹œì ˆì— ì–´ë–¤ ë°œì–¸ì„ í–ˆê³ , ëˆ„ê°€ ê·¸ ë°œì–¸ì„ ë¬¸ì œì‚¼ì•˜ëŠ”ì§€ì— ë”°ë¼ ë‹µì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\\\n\\\\në§Œì•½ ê¹€ì˜ì‚¼ ëŒ€í†µë ¹ì´ í›„ë³´ ì‹œì ˆì— ì§€ì—­í‘œì‹¬ì„ ê²¨ëƒ¥í•œ ë°œì–¸ì„ í–ˆë‹¤ëŠ” ê°€ì •í•˜ì—, ê·¸ ë°œì–¸ì„ ë¬¸ì œì‚¼ì€ í›„ë³´ê°€ ëˆ„êµ¬ì˜€ëŠ”ì§€ë¥¼ ëŒ€ë‹µí•˜ìë©´, ê·¸ ë‹µì€ ì´í™”ì„  ë‹¹ì‹œ ë¯¼ì£¼ë‹¹ ëŒ€í†µë ¹ í›„ë³´ê°€ ë  ê²ƒì…ë‹ˆë‹¤. 1992ë…„ ì´ì„  ë•Œ, ê¹€ì˜ì‚¼ ëŒ€ì„ í›„ë³´ëŠ” \"ì§‘ê°’ì´ ì˜¤ë¥¸ ë…¸ëŸ‰ì§„ì—­ ë¶€ê·¼ì˜ ë¶€ë™ì‚° ê°€ê²©ì€ ì„¸ì›”í˜¸ í­ì¹¨ í›„ \\\\\\'ê°•ë‚¨ ë„ì‹œì¬ìƒ\\\\\\' ì¼í™˜ìœ¼ë¡œ ìƒìŠ¹í–ˆë‹¤\"ëŠ” ë°œì–¸ì„ í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´í™”ì„  í›„ë³´ëŠ” ì´ ë°œì–¸ì„ \"ì „êµ­ì ìœ¼ë¡œ ê²½ì œì  ë°œì „ì´ ì´ë£¨ì–´ì§€ì§€ ì•Šì€ ì§€ë°©ë¯¼ì˜ ë§ˆìŒì„ ë©€ë¦¬í•´ì§€ë ¤ëŠ” ë¬´ë¡€í•œ ë°œì–¸\"ì´ë¼ê³  ë¹„íŒí•˜ë©° ë¬¸ì œì‚¼ì•˜ìŠµë‹ˆë‹¤.\\\\n\\\\ní•˜ì§€ë§Œ, ì´ ì§ˆë¬¸ì„ ë‹µë³€í•˜ëŠ” ë° ìˆì–´ì„œ ë³´ë‹¤ ëª…í™•í•œ ì •ë³´ê°€ ìˆìœ¼ë©´ ë‹µë³€ì„ ë³´ì™„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',\n",
       "  'completion_2': 'ê¹€ì˜ì‚¼ì˜ í›„ë³´ ì‹œì ˆì— ì§€ì—­í‘œì‹¬ì„ ê²¨ëƒ¥í•œ ë°œì–¸ì€ ëŒ€í†µë ¹ ë‹¹ì„  ì „ê¹Œì§€ ëŒ€í•œë¯¼êµ­ ì •ë¶€ê°€ ì¶”êµ¬í•˜ê³  ìˆëŠ” ë¯¼ì£¼ì£¼ì˜ ê´‘ë²”ìœ„í•˜ê²Œ í™•ë¦½ê³¼ ë³´ìˆ˜ì˜ ì‚¬ìƒì„ ì´ì–´ê°€ëŠ” ë° ìˆì–´ ì§€ì—­ê²½ì œ ë°œì „ê³¼ ê³µê³µì„œë¹„ìŠ¤ ì‹ ì† ê°œì„ ì„ ìœ„í•´ í•©ë¦¬ì ì¸ êµ­ê°€ ì •ì±…ì— ë”°ë¥´ëŠ” ë°©í–¥ì„±ì„ ì œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤.',\n",
       "  'ranking': [1, 2, 0]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_2_RM = './data_kochatgpt/kochatgpt_2_RM.jsonl'\n",
    "with open(data_path_2_RM, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb470a6",
   "metadata": {},
   "source": [
    "### PPO ë°ì´í„° - ê¸°ë³¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d90f9dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'ë²ˆë””ëŠ” ìì‹ ì´ íƒì •ì¡ì§€, ë²”ì£„ì†Œì„¤ ê·¸ë¦¬ê³  ì„±ë²”ì£„ ê´€ë ¨ ì‹¤ì œ ë²”ì£„ ë‹¤íë©˜í„°ë¦¬ë“¤ì„ íƒë…í–ˆë‹¤ê³  ëˆ„êµ¬ì—ê²Œ ë§í–ˆë‚˜?'},\n",
       " {'prompt': 'ê°œí¬ì£¼ê³µì•„íŒŒíŠ¸ëŠ” ëª‡ ë‹¨ì§€ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‚˜?'},\n",
       " {'prompt': 'ê¹€ì˜ì‚¼ì˜ í›„ë³´ ì‹œì ˆ ì§€ì—­í‘œì‹¬ì„ ê²¨ëƒ¥í•œ ë°œì–¸ì„ ë¬¸ì œì‚¼ì€ í›„ë³´ëŠ”?'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_3_PPO = './data_kochatgpt/kochatgpt_3_PPO.jsonl'\n",
    "with open(data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2847a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa2334c",
   "metadata": {},
   "source": [
    "### SFT ëª¨ë¸ í† í¬ë‚˜ì´ì € ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a6f28a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b303c2fb",
   "metadata": {},
   "source": [
    "### SFT ë°ì´í„°ì…‹ í´ë˜ìŠ¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7159ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "class SFT_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        pattern_instruction = 'prompt'  # instruction\n",
    "        pattern_output = 'completion'  # response\n",
    "\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_input\": (\n",
    "                \"### Instruction(ëª…ë ¹ì–´):\\n{prompt}\\n\\n### Response(ì‘ë‹µ):\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
    "\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            tmp = prompt_input.format_map(example)\n",
    "            sources.append(tmp)\n",
    "\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100\n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da39221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2278118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data done!!: 12000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SFT_dataset(data_path_1_SFT='./data_kochatgpt/kochatgpt_1_SFT.jsonl', tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e711d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/KoChatGPT/test\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=5,\n",
    "    prediction_loss_only=True,\n",
    "    fp16 = True\n",
    "    )\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f5250ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 09:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.149500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.947900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.759300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.742400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.656700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('/KoChatGPT/output_1_SFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53e71d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer # rouge_score ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "\n",
    "def calculate_and_print_rouge_scores(generated_texts: list,\n",
    "                                     reference_texts: list,\n",
    "                                     use_stemmer: bool = False,\n",
    "                                     print_individual_scores: bool = True):\n",
    "    \"\"\"\n",
    "    ìƒì„±ëœ í…ìŠ¤íŠ¸ì™€ ì°¸ì¡° í…ìŠ¤íŠ¸ ê°„ì˜ ROUGE ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        generated_texts (list): ëª¨ë¸ì´ ìƒì„±í•œ í…ìŠ¤íŠ¸(ì‘ë‹µ)ì˜ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n",
    "        reference_texts (list): ì°¸ì¡° (ì •ë‹µ) í…ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n",
    "        use_stemmer (bool): ROUGE ê³„ì‚° ì‹œ í˜•íƒœì†Œ ë¶„ì„ê¸°(stemmer) ì‚¬ìš© ì—¬ë¶€ì…ë‹ˆë‹¤.\n",
    "                            Trueë¡œ ì„¤ì • ì‹œ, NLTK ë“±ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë©°,\n",
    "                            í•œêµ­ì–´ì˜ ê²½ìš° ì ì ˆí•œ í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "                            ê¸°ë³¸ê°’ì€ Falseì…ë‹ˆë‹¤.\n",
    "        print_individual_scores (bool): ê° ìƒ˜í”Œë³„ ROUGE ì ìˆ˜ ì¶œë ¥ ì—¬ë¶€ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Trueì…ë‹ˆë‹¤.\n",
    "\n",
    "    Returns:\n",
    "        dict: í‰ê·  ROUGE Precision, Recall, F1-scoreë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.\n",
    "              (ì˜ˆ: {'rouge1_precision': 0.XX, 'rouge1_recall': 0.YY, 'rouge1_f1': 0.ZZ, ...})\n",
    "              í…ìŠ¤íŠ¸ ëª©ë¡ì´ ë¹„ì–´ ìˆê±°ë‚˜ ê¸¸ì´ê°€ ë‹¤ë¥¼ ê²½ìš° Noneì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if not generated_texts or not reference_texts:\n",
    "        print(\"ğŸš« ìƒì„±ëœ í…ìŠ¤íŠ¸ ë˜ëŠ” ì°¸ì¡° í…ìŠ¤íŠ¸ ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ROUGE ì ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "\n",
    "    if len(generated_texts) != len(reference_texts):\n",
    "        print(f\"ğŸš« ìƒì„±ëœ í…ìŠ¤íŠ¸ì˜ ìˆ˜({len(generated_texts)})ì™€ ì°¸ì¡° í…ìŠ¤íŠ¸ì˜ ìˆ˜({len(reference_texts)})ê°€ ì¼ì¹˜í•˜ì§€ ì•Šì•„ ROUGE ì ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # rouge_scorer ì´ˆê¸°í™”\n",
    "        # ì§€ì›ë˜ëŠ” ë©”íŠ¸ë¦­: 'rouge1', 'rouge2', ..., 'rougeL', 'rougeLsum'\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=use_stemmer)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ RougeScorer ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        print(\"ROUGE ì ìˆ˜ ê³„ì‚°ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "\n",
    "    # ëª¨ë“  ìƒ˜í”Œì˜ ROUGE ì ìˆ˜ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "    all_scores_p = {'rouge1': [], 'rouge2': [], 'rougeL': []} # Precision\n",
    "    all_scores_r = {'rouge1': [], 'rouge2': [], 'rougeL': []} # Recall\n",
    "    all_scores_f = {'rouge1': [], 'rouge2': [], 'rougeL': []} # F1-score\n",
    "\n",
    "    if print_individual_scores:\n",
    "        print(\"\\n\\n--- ğŸ’¯ ê°œë³„ ìƒ˜í”Œ ROUGE ìŠ¤ì½”ì–´ ---\")\n",
    "\n",
    "    for i in range(len(generated_texts)):\n",
    "        candidate = str(generated_texts[i])  # ìƒì„±ëœ í…ìŠ¤íŠ¸\n",
    "        reference = str(reference_texts[i])  # ì°¸ì¡° í…ìŠ¤íŠ¸\n",
    "\n",
    "        # ROUGE ì ìˆ˜ ê³„ì‚°\n",
    "        # scoresëŠ” ê° rouge íƒ€ì… (ì˜ˆ: 'rouge1')ì— ëŒ€í•´ Score(precision=..., recall=..., fmeasure=...) ê°ì²´ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬\n",
    "        scores = scorer.score(reference, candidate)\n",
    "\n",
    "        if print_individual_scores:\n",
    "            print(f\"\\nğŸ“œ ìƒ˜í”Œ {i+1}:\")\n",
    "            # print(f\"  ì°¸ì¡° ë‹µë³€: {reference}\") # í•„ìš”ì‹œ ì£¼ì„ í•´ì œí•˜ì—¬ í™•ì¸\n",
    "            # print(f\"  ìƒì„±ëœ ë‹µë³€: {candidate}\") # í•„ìš”ì‹œ ì£¼ì„ í•´ì œí•˜ì—¬ í™•ì¸\n",
    "            print(f\"  ROUGE ì ìˆ˜:\")\n",
    "            for rouge_type, score_obj in scores.items():\n",
    "                print(f\"    {rouge_type.upper()}: P={score_obj.precision:.4f}, R={score_obj.recall:.4f}, F1={score_obj.fmeasure:.4f}\")\n",
    "\n",
    "        # ê° íƒ€ì…ë³„ ì ìˆ˜ ì €ì¥\n",
    "        for rouge_type in ['rouge1', 'rouge2', 'rougeL']:\n",
    "            all_scores_p[rouge_type].append(scores[rouge_type].precision)\n",
    "            all_scores_r[rouge_type].append(scores[rouge_type].recall)\n",
    "            all_scores_f[rouge_type].append(scores[rouge_type].fmeasure)\n",
    "\n",
    "    # í‰ê·  ROUGE ì ìˆ˜ ê³„ì‚°\n",
    "    average_results = {}\n",
    "    if all_scores_f['rouge1']:  # ì ìˆ˜ê°€ í•˜ë‚˜ë¼ë„ ê³„ì‚°ë˜ì—ˆë‹¤ë©´\n",
    "        print(\"\\n\\n--- ğŸ“‰ ì „ì²´ ìƒ˜í”Œ í‰ê·  ROUGE ìŠ¤ì½”ì–´ ---\")\n",
    "        for rouge_type in ['rouge1', 'rouge2', 'rougeL']:\n",
    "            avg_p = sum(all_scores_p[rouge_type]) / len(all_scores_p[rouge_type])\n",
    "            avg_r = sum(all_scores_r[rouge_type]) / len(all_scores_r[rouge_type])\n",
    "            avg_f = sum(all_scores_f[rouge_type]) / len(all_scores_f[rouge_type])\n",
    "\n",
    "            average_results[f'{rouge_type}_precision'] = avg_p\n",
    "            average_results[f'{rouge_type}_recall'] = avg_r\n",
    "            average_results[f'{rouge_type}_f1'] = avg_f\n",
    "            \n",
    "            print(f\"  í‰ê·  {rouge_type.upper()}: P={avg_p:.4f}, R={avg_r:.4f}, F1={avg_f:.4f}\")\n",
    "        \n",
    "        return average_results\n",
    "    else:\n",
    "        print(\"âš ï¸ ê³„ì‚°ëœ ROUGE ì ìˆ˜ê°€ ì—†ì–´ í‰ê· ì„ ë°˜í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "174f1269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(ëª…ë ¹ì–´):\n",
      "ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì—ìš”?\n",
      "\n",
      "### Response(ì‘ë‹µ):'ì €ëŠ” ì¸ê³µì§€ëŠ¥ ì–´ì‹œìŠ¤í„´íŠ¸ì´ê¸° ë•Œë¬¸ì— ê³ ê¸°ë¥¼ ë¨¹ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ë¶ˆê³ ê¸°ëŠ” ê±´ê°•ì— ì¢‹ì€ ì‹í’ˆ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì‡ ê³ ê¸°ì˜ ê³ ê¸°ëŠ” ë‹¨ë°±ì§ˆ, ì§€ë°©, ì² ë¶„, ì¹¼ìŠ˜, ì² ë¶„, ì¸ ë“±ì´ í’ë¶€í•˜ê¸° ë•Œë¬¸ì— ê±´ê°•ì— ì¢‹ìŠµë‹ˆë‹¤. ë˜í•œ, ì†Œê³ ê¸°ì™€ ë¼ì§€ê³ ê¸°ë¥¼ ì„ì–´ ë§Œë“  ì–‘ë…ë„ ì¸ê¸° ìˆëŠ” ìš”ë¦¬ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "### Instruction(ëª…ë ¹ì–´):\n",
      "ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì´ 43ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•œ ë…„ë„ëŠ”?\n",
      "\n",
      "### Response(ì‘ë‹µ):'ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 42ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 46ëŒ€ ë¶€í†µë ¹ì§ì„ ë§¡ì•˜ìŠµë‹ˆë‹¤. ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 48ëŒ€ ë¶€í†µë ¹ì„ ì—­ì„í•˜ì˜€ìŠµë‹ˆë‹¤. ë¦¬ì²˜ë“œëŠ” 40ëŒ€ ë¶€í†µë ¹ì„ ë§¡ì•˜ë˜ ì ì´ ìˆìŠµë‹ˆë‹¤. ë¦¬ì²˜ë“œëŠ” 47ëŒ€ ë¶€í†µë ¹ì„ ë§¡ì€ ì ì´ ì—†ìŠµë‹ˆë‹¤. ë¦¬ì²˜ë“œì˜ ì¬ì„ ê¸°ê°„ ë™ì•ˆ, ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€\n",
      "\n",
      "### Instruction(ëª…ë ¹ì–´):\n",
      "ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ì–´ë””ì— ìˆì–´?\n",
      "\n",
      "### Response(ì‘ë‹µ):'ì‹œì¹´ê³  ì˜¤ í—¤ì–´ êµ­ì œê³µí•­ì€ ë¯¸êµ­ ìº˜ë¦¬í¬ë‹ˆì•„ì£¼ ìƒŒí”„ë€ì‹œìŠ¤ì½”ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤. American International Pacific Language model, Translation of the Korean Capilities in Canada Orientality and Distributed Commissions.\n",
      "\n",
      "### Instruction(ëª…ë ¹ì–´):\n",
      "ì˜¤ëŠ˜ ë¯¸ì„¸ë¨¼ì§€ ì–´ë•Œ?\n",
      "\n",
      "### Response(ì‘ë‹µ):'ì €ëŠ” ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì´ë¯€ë¡œ ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë¥¼ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, ë¯¸ì„¸ë¨¼ì§€ ì˜ˆë³´ë‚˜ ì˜ˆë³´ ì‚¬ì´íŠ¸ë¥¼ í†µí•´ ë¯¸ì„¸ë¨¼ì§€ ë†ë„ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìœ¼ë‹ˆ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. Please provide model, I do not have\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='/KoChatGPT/output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(ëª…ë ¹ì–´):\\n{prompt}\\n\\n### Response(ì‘ë‹µ):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = ['ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì—ìš”?',\n",
    "               'ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì´ 43ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•œ ë…„ë„ëŠ”?',\n",
    "               'ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ì–´ë””ì— ìˆì–´?',\n",
    "               'ì˜¤ëŠ˜ ë¯¸ì„¸ë¨¼ì§€ ì–´ë•Œ?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "list_result = generator(list_prompt, **generation_args)   \n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29a21e0",
   "metadata": {},
   "source": [
    "## ì •ì„±ì  í‰ê°€\n",
    "\n",
    "ì „ì²´ì ìœ¼ë¡œ ê´œì°®ì€ ëŒ€ë‹µì„ í•˜ê³  ìˆë‹¤ëŠ” ìƒê°ì´ ë“ ë‹¤.\n",
    "\n",
    "ë‹¤ë§Œ ì¤‘ê°„ì— ëŒ€ë‹µì´ ì˜ì–´ë¡œ ë°”ë€ŒëŠ” ë¶€ë¶„ì„ ë‹¤ìˆ˜ í™•ì¸í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cfdc17",
   "metadata": {},
   "source": [
    "## ì œë¯¸ë‚˜ì´ê°€ ìƒì„±í•œ referenceì™€ rouge ìŠ¤ì½”ì–´ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e0073ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(ëª…ë ¹ì–´):\n",
      "ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì—ìš”?\n",
      "\n",
      "### Response(ì‘ë‹µ):'ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì´ê¸° ë•Œë¬¸ì— ê³ ê¸°ë¥¼ ë¨¹ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ë¶ˆê³ ê¸°ëŠ” ê±´ê°•í•˜ê³  ë§›ìˆì„ ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ ìš”ë¦¬ì— í™œìš©ë  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë§ì€ ì‚¬ëŒë“¤ì´ ì¦ê²¨ë¨¹ëŠ” ìŒì‹ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. é«˜åƒ§, å¾Œåƒ§, äº”åƒ§, äº”ä¹˜, äº”ä¹˜ ë“±ì´ ìˆìŠµë‹ˆë‹¤. é«˜åƒ§ì€\n",
      "\n",
      "### Instruction(ëª…ë ¹ì–´):\n",
      "ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì´ 43ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•œ ë…„ë„ëŠ”?\n",
      "\n",
      "### Response(ì‘ë‹µ):'ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 41ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 46ëŒ€ ë¶€í†µë ¹ì§ì„ ë§¡ì•˜ìŠµë‹ˆë‹¤. ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 36ëŒ€ ë¶€í†µë ¹ì§ì„ ë§¡ì•˜ë˜ ì ì´ ìˆìŠµë‹ˆë‹¤. ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì´ 38ëŒ€ ë¶€í†µë ¹ì§ì„ ë§¡ì€ ì—°ë„ëŠ” ì •í™•íˆ ì•Œë ¤ì ¸ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 43ëŒ€ ë¶€í†µë ¹ì„ ì—­ì„í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### Instruction(ëª…ë ¹ì–´):\n",
      "ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ì–´ë””ì— ìˆì–´?\n",
      "\n",
      "### Response(ì‘ë‹µ):'ì‹œì¹´ê³  ì˜¤ í—¤ì–´ êµ­ì œê³µí•­ì€ ë¯¸êµ­ í…ì‚¬ìŠ¤ì£¼ íœ´ìŠ¤í„´ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤. Island of the translation of the Translation:\\n\\nì‹œì¹´ê³ ì˜¤ í—¤ì–´ êµ­ì œê³µí•­(The British Heautiful Metropolica) ì§€ì—­ì…ë‹ˆë‹¤. Island\n",
      "\n",
      "### Instruction(ëª…ë ¹ì–´):\n",
      "ì˜¤ëŠ˜ ë¯¸ì„¸ë¨¼ì§€ ì–´ë•Œ?\n",
      "\n",
      "### Response(ì‘ë‹µ):'ì €ëŠ” ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì´ê¸° ë•Œë¬¸ì— ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë¥¼ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ë¯¸ì„¸ë¨¼ì§€ëŠ” ëŒ€ë¶€ë¶„ ì¤‘êµ­ì—ì„œ ë°œì›í•˜ì—¬ êµ­ë‚´ë¡œ ìœ ì…ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ì™¸ì¶œ ì „ì— ë§ˆìŠ¤í¬ë¥¼ ì°©ìš©í•˜ì‹œëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë˜í•œ, ë¯¸ì„¸ë¨¼ì§€ ë†ë„ê°€ ë†’ì€ ë‚ ì—ëŠ” ì‹¤ì™¸ í™œë™ì„ ìì œí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.)å­”ä¸‰éƒ\n",
      "\n",
      "Extracting generated responses...\n",
      "\n",
      "âœ¨ ROUGE ìŠ¤ì½”ì–´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "\n",
      "\n",
      "--- ğŸ’¯ ê°œë³„ ìƒ˜í”Œ ROUGE ìŠ¤ì½”ì–´ ---\n",
      "\n",
      "ğŸ“œ ìƒ˜í”Œ 1:\n",
      "  ROUGE ì ìˆ˜:\n",
      "    ROUGE1: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGE2: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGEL: P=0.0000, R=0.0000, F1=0.0000\n",
      "\n",
      "ğŸ“œ ìƒ˜í”Œ 2:\n",
      "  ROUGE ì ìˆ˜:\n",
      "    ROUGE1: P=0.2000, R=0.3333, F1=0.2500\n",
      "    ROUGE2: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGEL: P=0.2000, R=0.3333, F1=0.2500\n",
      "\n",
      "ğŸ“œ ìƒ˜í”Œ 3:\n",
      "  ROUGE ì ìˆ˜:\n",
      "    ROUGE1: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGE2: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGEL: P=0.0000, R=0.0000, F1=0.0000\n",
      "\n",
      "ğŸ“œ ìƒ˜í”Œ 4:\n",
      "  ROUGE ì ìˆ˜:\n",
      "    ROUGE1: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGE2: P=0.0000, R=0.0000, F1=0.0000\n",
      "    ROUGEL: P=0.0000, R=0.0000, F1=0.0000\n",
      "\n",
      "\n",
      "--- ğŸ“‰ ì „ì²´ ìƒ˜í”Œ í‰ê·  ROUGE ìŠ¤ì½”ì–´ ---\n",
      "  í‰ê·  ROUGE1: P=0.0500, R=0.0833, F1=0.0625\n",
      "  í‰ê·  ROUGE2: P=0.0000, R=0.0000, F1=0.0000\n",
      "  í‰ê·  ROUGEL: P=0.0500, R=0.0833, F1=0.0625\n",
      "\n",
      "âœ… ROUGE ì ìˆ˜ ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# (ì œê³µí•´ì£¼ì‹  ì½”ë“œ ë¶€ë¶„)\n",
    "# generator = pipeline(...)\n",
    "# generation_args = dict(...)\n",
    "# PROMPT_DICT = {...}\n",
    "# list_prompt = [...] # í¬ë§·íŒ…ëœ í”„ë¡¬í”„íŠ¸\n",
    "# list_result = generator(list_prompt, **generation_args)\n",
    "# for prompt, result in zip(list_prompt, list_result):\n",
    "# Â  Â  print()\n",
    "# Â  Â  print((result[0]['generated_text']))\n",
    "\n",
    "generator = pipeline('text-generation', model='/KoChatGPT/output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(ëª…ë ¹ì–´):\\n{prompt}\\n\\n### Response(ì‘ë‹µ):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = ['ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì—ìš”?',\n",
    "               'ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì´ 43ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•œ ë…„ë„ëŠ”?',\n",
    "               'ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ì–´ë””ì— ìˆì–´?',\n",
    "               'ì˜¤ëŠ˜ ë¯¸ì„¸ë¨¼ì§€ ì–´ë•Œ?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "list_result = generator(list_prompt, **generation_args)   \n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))\n",
    "\n",
    "# --- ğŸ‘‡ ROUGE í•¨ìˆ˜ í˜¸ì¶œì„ ìœ„í•œ ì¶”ê°€ ì½”ë“œ ---\n",
    "\n",
    "# 1. ëª¨ë¸ì´ ìƒì„±í•œ \"ì‘ë‹µ\" ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ê¸°\n",
    "list_generated_responses = []\n",
    "response_marker = PROMPT_DICT[\"prompt_input\"].split(\"{prompt}\")[1].split(\"### Response(ì‘ë‹µ):\")[0] + \"### Response(ì‘ë‹µ):\" # \"### Response(ì‘ë‹µ):\" ë§ˆì»¤\n",
    "\n",
    "# ì›ë³¸ ì§ˆë¬¸ (ì°¸ì¡° í…ìŠ¤íŠ¸ì™€ ë§¤ì¹­í•˜ê¸° ìœ„í•¨)\n",
    "list_prompt_original = ['ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì—ìš”?',\n",
    "                       'ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì´ 43ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•œ ë…„ë„ëŠ”?',\n",
    "                       'ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ì–´ë””ì— ìˆì–´?',\n",
    "                       'ì˜¤ëŠ˜ ë¯¸ì„¸ë¨¼ì§€ ì–´ë•Œ?']\n",
    "\n",
    "print(\"\\nExtracting generated responses...\")\n",
    "for i, single_result_list in enumerate(list_result):\n",
    "    full_generated_text = single_result_list[0]['generated_text']\n",
    "    \n",
    "    # \"### Response(ì‘ë‹µ):\" ë§ˆì»¤ ì´í›„ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ\n",
    "    # rfindë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì™€ ì‘ë‹µ ì‚¬ì´ì— ë§ˆì»¤ê°€ ì—¬ëŸ¬ ë²ˆ ë‚˜ì˜¤ëŠ” ê²½ìš°, ë§ˆì§€ë§‰ ë§ˆì»¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•¨\n",
    "    marker_position = full_generated_text.rfind(response_marker)\n",
    "    \n",
    "    if marker_position != -1:\n",
    "        # ë§ˆì»¤ ë‹¤ìŒë¶€í„° í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        response_only = full_generated_text[marker_position + len(response_marker):].strip()\n",
    "    else:\n",
    "        # ë§ˆì»¤ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°, í¬ë§·íŒ…ëœ í”„ë¡¬í”„íŠ¸(list_prompt[i]) ì´í›„ì˜ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ë ¤ëŠ” ì‹œë„\n",
    "        # ì´ ë°©ë²•ì€ ëª¨ë¸ì´ í”„ë¡¬í”„íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë°˜ë³µí•˜ì§€ ì•Šìœ¼ë©´ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        try:\n",
    "            response_only = full_generated_text.split(list_prompt[i])[1].strip()\n",
    "        except IndexError:\n",
    "            print(f\"âš ï¸ Warning: ì‘ë‹µ ë§ˆì»¤ ë° í”„ë¡¬í”„íŠ¸ ë¶„ë¦¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìƒ˜í”Œ {i}ëŠ” ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
    "            response_only = full_generated_text # ìµœí›„ì˜ ìˆ˜ë‹¨ (ê°œì„  í•„ìš”)\n",
    "\n",
    "    # eos_token (ì˜ˆ: '\\n' ë˜ëŠ” tokenizer.eos_token) ì •ë¦¬\n",
    "    # generation_argsì˜ eos_token_idê°€ 375 ('\\n')ë¡œ ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì²˜ë¦¬\n",
    "    # tokenizer.eos_token (ì˜ˆ: '</s>')ë„ í•¨ê»˜ ê³ ë ¤í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "    if tokenizer.eos_token: # tokenizer ë³€ìˆ˜ê°€ ì‚¬ìš© ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "         response_only = response_only.replace(tokenizer.eos_token, \"\")\n",
    "    \n",
    "    # eos_token_id=375ê°€ '\\n'ì´ë¼ê³  ê°€ì •í•˜ê³ , ì²« ì¤„ë°”ê¿ˆ ì´ì „ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•˜ê±°ë‚˜ ë¶ˆí•„ìš”í•œ ì¤„ë°”ê¿ˆ ì œê±°\n",
    "    response_only = response_only.split('\\n')[0].strip()\n",
    "    \n",
    "    list_generated_responses.append(response_only)\n",
    "    # print(f\"  Q: {list_prompt_original[i]}\") # ë””ë²„ê¹…ìš©\n",
    "    # print(f\"  Extracted A: {response_only}\") # ë””ë²„ê¹…ìš©\n",
    "\n",
    "# 2. ì°¸ì¡° (ì •ë‹µ) í…ìŠ¤íŠ¸ ì¤€ë¹„\n",
    "#    list_prompt_originalì˜ ê° ì§ˆë¬¸ì— ëŒ€í•œ ì´ìƒì ì¸ ë‹µë³€ì„ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "#    ì´ ëª©ë¡ì€ ëª¨ë¸ì˜ ë‹µë³€ê³¼ ë¹„êµë  \"ì •ë‹µì§€\" ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "list_references = [\n",
    "    \"ì¼ë°˜ì ìœ¼ë¡œ ë¶ˆê³ ê¸°ìš© ê³ ê¸°ëŠ” í•œìš°ë¥¼ í¬í•¨í•˜ì—¬ ë‹¤ì–‘í•œ ì¢…ë¥˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš”ë¦¬ì˜ ì¢…ë¥˜ë‚˜ ê°œì¸ì˜ ì·¨í–¥ì— ë”°ë¼ ì„ íƒí•˜ì‹œë©´ ë©ë‹ˆë‹¤.\",\n",
    "    \"ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 1953ë…„ë¶€í„° 1961ë…„ê¹Œì§€ ë¯¸êµ­ì˜ ì œ36ëŒ€ ë¶€í†µë ¹ìœ¼ë¡œ ì¬ì„í–ˆìŠµë‹ˆë‹¤.\", # 43ëŒ€ê°€ ì•„ë‹Œ 36ëŒ€ì…ë‹ˆë‹¤.\n",
    "    \"ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ë¯¸êµ­ ì¼ë¦¬ë…¸ì´ ì£¼ ì‹œì¹´ê³ ì— ìœ„ì¹˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.\",\n",
    "    \"ì˜¤ëŠ˜ì˜ ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ë³€ë™ë˜ë¯€ë¡œ, ê¸°ìƒì²­ ì›¹ì‚¬ì´íŠ¸ë‚˜ ê´€ë ¨ ì•±ì„ í†µí•´ í˜„ì¬ ê³„ì‹  ì§€ì—­ì˜ ì •ë³´ë¥¼ í™•ì¸í•˜ì‹œëŠ” ê²ƒì´ ê°€ì¥ ì •í™•í•©ë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "# ìƒì„±ëœ ì‘ë‹µê³¼ ì°¸ì¡° í…ìŠ¤íŠ¸ì˜ ê°œìˆ˜ê°€ ê°™ì€ì§€ í™•ì¸\n",
    "if len(list_generated_responses) != len(list_references):\n",
    "    print(f\"âš ï¸ ê²½ê³ : ìƒì„±ëœ ì‘ë‹µì˜ ìˆ˜({len(list_generated_responses)})ì™€ ì°¸ì¡° í…ìŠ¤íŠ¸ì˜ ìˆ˜({len(list_references)})ê°€ ë‹¤ë¦…ë‹ˆë‹¤.\")\n",
    "    print(\"    ROUGE ìŠ¤ì½”ì–´ ê³„ì‚°ì„ ìœ„í•´ ì°¸ì¡° í…ìŠ¤íŠ¸ ëª©ë¡ì„ í™•ì¸í•˜ê³  ì¡°ì •í•´ì£¼ì„¸ìš”.\")\n",
    "else:\n",
    "    # 3. ì´ì „ì— ì •ì˜í•œ ROUGE ìŠ¤ì½”ì–´ í•¨ìˆ˜ í˜¸ì¶œ\n",
    "    #    (calculate_and_print_rouge_scores í•¨ìˆ˜ê°€ ì´ì „ì— ë…¸íŠ¸ë¶ì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤)\n",
    "    print(\"\\nâœ¨ ROUGE ìŠ¤ì½”ì–´ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # calculate_and_print_rouge_scores í•¨ìˆ˜ê°€ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•˜ê³  í˜¸ì¶œ\n",
    "    # from rouge_score import rouge_scorer # í•¨ìˆ˜ ë‚´ì— ìˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œ ë‹¤ì‹œ ì„í¬íŠ¸í•  í•„ìš”ëŠ” ì—†ìŒ\n",
    "    \n",
    "    average_rouge_scores = calculate_and_print_rouge_scores(\n",
    "        generated_texts=list_generated_responses,\n",
    "        reference_texts=list_references,\n",
    "        use_stemmer=False,  # í•œêµ­ì–´ì˜ ê²½ìš° Trueë¡œ ì„¤ì •í•˜ê³  ì ì ˆí•œ í™˜ê²½ êµ¬ì„± í•„ìš”\n",
    "        print_individual_scores=True # ê° ìƒ˜í”Œë³„ ì ìˆ˜ ì¶œë ¥ ì—¬ë¶€\n",
    "    )\n",
    "\n",
    "    if average_rouge_scores:\n",
    "        print(\"\\nâœ… ROUGE ì ìˆ˜ ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        # print(\"\\në°˜í™˜ëœ í‰ê·  ì ìˆ˜ ë”•ì…”ë„ˆë¦¬ (F1 ê¸°ì¤€):\", average_rouge_scores) # ìƒì„¸ ê²°ê³¼ í™•ì¸ìš©\n",
    "    else:\n",
    "        print(\"âŒ ROUGE ì ìˆ˜ ê³„ì‚°ì— ì‹¤íŒ¨í–ˆê±°ë‚˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f27cd31",
   "metadata": {},
   "source": [
    "## ROUGE ìŠ¤ì½”ì–´ì™€ ë¹„êµ í‰ê°€\n",
    "ê° ì§ˆë¬¸ë“¤ì— ëŒ€í•´ ì œë¯¸ë‚˜ì´ê°€ ì˜ˆì¸¡í•œ ë¬¸ìì—´ê³¼ ë¹„êµí•˜ì—¬ ROUGE í‰ê°€ë¥¼ ì§„í–‰í•˜ì˜€ë‹¤.\n",
    "\n",
    "ì œë¯¸ë‚˜ì´ê°€ ìƒì„±í•´ ë‚¸ ë°ì´í„°ë“¤ì´ í™•ì¸ê²°ê³¼ íŒ©íŠ¸ì— ê°€ê¹Œì› ë‹¤.\n",
    "\n",
    "ex) ì‹œì¹´ê³ ì˜¤ êµ­ì œê³µí•­ì˜ ìœ„ì¹˜ ë“±ë“±..\n",
    "\n",
    "n-gramì„ 1ë¡œ ì¡ì•˜ì„ ë•ŒëŠ” ìŠ¤ì½”ì–´ê°€ ì–´ëŠ ì •ë„ ë‚˜ì™”ìœ¼ë‚˜ \n",
    "\n",
    "n-gramì´ 2ë§Œ ë˜ì–´ë„ ë¹„ìŠ·í•œ í…ìŠ¤íŠ¸ê°€ ì „í˜€ ê²¹ì¹˜ì§€ ì•Šì„ê±¸ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤.\n",
    "\n",
    "ì¦‰, ë‹¨ì¼ ë‹¨ì–´ ìˆ˜ì¤€ì—ì„œ ë¹„ìŠ·í•˜ë‚˜ ë¹„ìŠ·í•œ ë¬¸ì¥ì€ ìƒì„±í•´ë‚´ì§€ ëª»í•˜ëŠ” ê²ƒì´ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c5c35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e521a85",
   "metadata": {},
   "source": [
    "## RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0432bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# colossalai_ChatGPT_230319 ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë£¨íŠ¸ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€\n",
    "# í˜„ì¬ íŒŒì¼ì˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œë¥¼ ê³„ì‚°í•˜ê±°ë‚˜, ì ˆëŒ€ ê²½ë¡œë¥¼ ì§ì ‘ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "# ì•„ë˜ëŠ” ì˜ˆì‹œì´ë©°, ì‹¤ì œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "library_root_path = '/workspace/userdisk/KoChatGPT/colossalai_ChatGPT_230319'\n",
    "\n",
    "if library_root_path not in sys.path:\n",
    "    sys.path.insert(0, library_root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "951eaff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from colossalai_ChatGPT_230319.chatgpt.dataset import RewardDataset\n",
    "from colossalai_ChatGPT_230319.chatgpt.models.base import RewardModel\n",
    "from colossalai_ChatGPT_230319.chatgpt.trainer import RewardModelTrainer\n",
    "from colossalai_ChatGPT_230319.chatgpt.trainer.strategies import NaiveStrategy\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dcb44107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ed761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "with NaiveStrategy().model_init_context():\n",
    "        model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17fd0cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data num: 10220\n",
      "after  data num: 30660\n",
      "data example: \n",
      "{'prompt': 'ì• í”Œì€ ë¦¬ì‚¬ë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í–ˆì–´', 'chosen': 'ì• í”Œì´ ëˆ„êµ¬ì¸ì§€ ëª…í™•íˆ ì•Œ ìˆ˜ ì—†ì–´ì„œ, ë¦¬ì‚¬ê°€ ëˆ„êµ¬ì¸ì§€ì™€ ì–´ë–¤ ìƒí™©ì—ì„œ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ì— ëŒ€í•œ ì¶”ê°€ì ì¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, ë³´ë‹¤ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'rejected': 'ì• í”Œì€ ë¦¬ì‚¬ë¥¼ ìœ„í•´ ê³ ê° ì„œë¹„ìŠ¤ ë¶€ì„œì—ì„œ ê³ ê° ë‹¤ì–‘í•œ ì»´í“¨í„° ê´€ë ¨ ë¬¸ì œì— ëŒ€í•´ ì‘ë‹µí•˜ëŠ” ë° í•„ìš”í•œ ëª¨ë“  ì§€ì›ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìê°€ í•˜ë“œì›¨ì–´ ë¬¸ì œë¥¼ ê²½í—˜í•  ë•Œ, ì „ë¬¸ê°€ë“¤ì€ í•„ìš”í•œ ìˆ˜ë¦¬(ìˆ˜ë¦¬, ì¶”ê°€ ë¶€í’ˆ ì œê³µ, ì†Œí”„íŠ¸ì›¨ì–´ ì—…ê·¸ë ˆì´ë“œ ë“±)ì„ ì œê³µí•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì‚¬ìš©ìê°€ ì‚¬ìš© ë°©ë²• ë¬¸ì œë‚˜ ê¸°íƒ€ ë¬¸ì œë¥¼ ê²½í—˜í•  ë•Œ, ëŒ€í™” ìƒëŒ€ë¡œ ì‚¬ìš©ìë¥¼ ì§€ì›í•  ìˆ˜ ìˆëŠ” ì „ë¬¸ ê³ ê° ì„œë¹„ìŠ¤ ì§ì›ë“¤ì´ ì‚¬ìš©ìì—ê²Œ ìƒë‹´í•˜ê³  ë„ì›€ì„ ì£¼ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë˜í•œ, ì¸í„°ë„·ì—ì„œ ì œê³µë˜ëŠ” ì •ë³´ë¥¼ í†µí•´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê±°ë‚˜ ê³ ê° ì„œë¹„ìŠ¤ ì›¹ ì‚¬ì´íŠ¸ë¥¼ í†µí•´ ìì‹ ì˜ ë¬¸ì œë¥¼ ì§„ë‹¨í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë“± ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ë¦¬ì‚¬ë¥¼ ì²˜ë¦¬í•´ ì™”ìŠµë‹ˆë‹¤.'}\n"
     ]
    }
   ],
   "source": [
    "with open('./data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7396ff3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'ìœ ì•„ì¸ì´ ë¥˜ìŠ¹ì™„ ê°ë…ì„ ë§Œë‚˜ ì˜í™” ë² í…Œë‘ì˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë°›ì•˜ë˜ ê³³ì€?', 'chosen': 'ìœ ì•„ì¸ì´ ë¥˜ìŠ¹ì™„ ê°ë…ì„ ë§Œë‚˜ ì˜í™” ë² í…Œë‘ì˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë°›ì•˜ë˜ ê³³ì€ ë¥˜ìŠ¹ì™„ì˜ ì‚¬ë¬´ì‹¤ì…ë‹ˆë‹¤.', 'rejected': 'ëŒ€êµ¬ ì˜í™”ì‚¬ì˜¥'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(230319)\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e33fa8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 1266.74it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 1134.51it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c73fee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=4,\n",
    "                             max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a87388cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Train epoch:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:00<03:56,  1.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:00<03:56,  1.05it/s, loss=0.335]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:01<03:54,  1.06it/s, loss=0.335]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:01<03:54,  1.06it/s, loss=0.248]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:02<03:54,  1.06it/s, loss=0.248]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:02<03:54,  1.06it/s, loss=0.817]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   2%|â–         | 4/250 [00:03<03:53,  1.05it/s, loss=0.817]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   2%|â–         | 4/250 [00:03<03:53,  1.05it/s, loss=0.794]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   2%|â–         | 5/250 [00:04<03:52,  1.05it/s, loss=0.794]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   2%|â–         | 5/250 [00:04<03:52,  1.05it/s, loss=0.409]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   2%|â–         | 6/250 [00:05<03:52,  1.05it/s, loss=0.409]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   2%|â–         | 6/250 [00:05<03:52,  1.05it/s, loss=0.227]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   3%|â–         | 7/250 [00:06<03:52,  1.04it/s, loss=0.227]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   3%|â–         | 7/250 [00:06<03:52,  1.04it/s, loss=0.32] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   3%|â–         | 8/250 [00:07<03:52,  1.04it/s, loss=0.32]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   3%|â–         | 8/250 [00:07<03:52,  1.04it/s, loss=0.447]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   4%|â–         | 9/250 [00:08<03:52,  1.04it/s, loss=0.447]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   4%|â–         | 9/250 [00:08<03:52,  1.04it/s, loss=0.351]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   4%|â–         | 10/250 [00:09<03:52,  1.03it/s, loss=0.351]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   4%|â–         | 10/250 [00:09<03:52,  1.03it/s, loss=0.399]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   4%|â–         | 11/250 [00:10<03:51,  1.03it/s, loss=0.399]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   4%|â–         | 11/250 [00:10<03:51,  1.03it/s, loss=0.315]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   5%|â–         | 12/250 [00:11<03:51,  1.03it/s, loss=0.315]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   5%|â–         | 12/250 [00:11<03:51,  1.03it/s, loss=0.383]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   5%|â–Œ         | 13/250 [00:12<03:52,  1.02it/s, loss=0.383]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   5%|â–Œ         | 13/250 [00:12<03:52,  1.02it/s, loss=0.0104]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   6%|â–Œ         | 14/250 [00:13<03:51,  1.02it/s, loss=0.0104]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   6%|â–Œ         | 14/250 [00:13<03:51,  1.02it/s, loss=3.1]   \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   6%|â–Œ         | 15/250 [00:14<03:51,  1.02it/s, loss=3.1]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   6%|â–Œ         | 15/250 [00:14<03:51,  1.02it/s, loss=0.269]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   6%|â–‹         | 16/250 [00:15<03:51,  1.01it/s, loss=0.269]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   6%|â–‹         | 16/250 [00:15<03:51,  1.01it/s, loss=1.72] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   7%|â–‹         | 17/250 [00:16<03:51,  1.01it/s, loss=1.72]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   7%|â–‹         | 17/250 [00:16<03:51,  1.01it/s, loss=0.789]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   7%|â–‹         | 18/250 [00:17<03:52,  1.00s/it, loss=0.789]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   7%|â–‹         | 18/250 [00:17<03:52,  1.00s/it, loss=0.451]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   8%|â–Š         | 19/250 [00:18<03:51,  1.00s/it, loss=0.451]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   8%|â–Š         | 19/250 [00:18<03:51,  1.00s/it, loss=0.633]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   8%|â–Š         | 20/250 [00:19<03:51,  1.01s/it, loss=0.633]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   8%|â–Š         | 20/250 [00:19<03:51,  1.01s/it, loss=0.601]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   8%|â–Š         | 21/250 [00:20<03:51,  1.01s/it, loss=0.601]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   8%|â–Š         | 21/250 [00:20<03:51,  1.01s/it, loss=0.686]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   9%|â–‰         | 22/250 [00:21<03:51,  1.02s/it, loss=0.686]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   9%|â–‰         | 22/250 [00:21<03:51,  1.02s/it, loss=0.598]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   9%|â–‰         | 23/250 [00:22<03:51,  1.02s/it, loss=0.598]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:   9%|â–‰         | 23/250 [00:22<03:51,  1.02s/it, loss=1.08] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  10%|â–‰         | 24/250 [00:23<03:51,  1.02s/it, loss=1.08]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  10%|â–‰         | 24/250 [00:23<03:51,  1.02s/it, loss=0.545]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  10%|â–ˆ         | 25/250 [00:24<03:51,  1.03s/it, loss=0.545]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  10%|â–ˆ         | 25/250 [00:24<03:51,  1.03s/it, loss=0.367]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  10%|â–ˆ         | 26/250 [00:25<03:51,  1.03s/it, loss=0.367]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  10%|â–ˆ         | 26/250 [00:25<03:51,  1.03s/it, loss=0.811]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  11%|â–ˆ         | 27/250 [00:26<03:50,  1.03s/it, loss=0.811]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  11%|â–ˆ         | 27/250 [00:26<03:50,  1.03s/it, loss=0.622]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  11%|â–ˆ         | 28/250 [00:27<03:50,  1.04s/it, loss=0.622]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  11%|â–ˆ         | 28/250 [00:27<03:50,  1.04s/it, loss=0.602]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  12%|â–ˆâ–        | 29/250 [00:28<03:50,  1.04s/it, loss=0.602]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  12%|â–ˆâ–        | 29/250 [00:28<03:50,  1.04s/it, loss=0.442]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  12%|â–ˆâ–        | 30/250 [00:29<03:50,  1.05s/it, loss=0.442]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  12%|â–ˆâ–        | 30/250 [00:29<03:50,  1.05s/it, loss=0.509]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  12%|â–ˆâ–        | 31/250 [00:31<03:50,  1.05s/it, loss=0.509]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  12%|â–ˆâ–        | 31/250 [00:31<03:50,  1.05s/it, loss=0.404]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  13%|â–ˆâ–        | 32/250 [00:32<03:50,  1.06s/it, loss=0.404]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  13%|â–ˆâ–        | 32/250 [00:32<03:50,  1.06s/it, loss=0.826]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  13%|â–ˆâ–        | 33/250 [00:33<03:49,  1.06s/it, loss=0.826]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  13%|â–ˆâ–        | 33/250 [00:33<03:49,  1.06s/it, loss=0.441]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  14%|â–ˆâ–        | 34/250 [00:34<03:49,  1.06s/it, loss=0.441]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  14%|â–ˆâ–        | 34/250 [00:34<03:49,  1.06s/it, loss=0.536]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  14%|â–ˆâ–        | 35/250 [00:35<03:49,  1.07s/it, loss=0.536]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  14%|â–ˆâ–        | 35/250 [00:35<03:49,  1.07s/it, loss=1.08] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  14%|â–ˆâ–        | 36/250 [00:36<03:48,  1.07s/it, loss=1.08]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  14%|â–ˆâ–        | 36/250 [00:36<03:48,  1.07s/it, loss=1.21]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  15%|â–ˆâ–        | 37/250 [00:37<03:48,  1.07s/it, loss=1.21]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  15%|â–ˆâ–        | 37/250 [00:37<03:48,  1.07s/it, loss=0.829]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  15%|â–ˆâ–Œ        | 38/250 [00:38<03:47,  1.07s/it, loss=0.829]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  15%|â–ˆâ–Œ        | 38/250 [00:38<03:47,  1.07s/it, loss=0.608]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  16%|â–ˆâ–Œ        | 39/250 [00:39<03:46,  1.07s/it, loss=0.608]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  16%|â–ˆâ–Œ        | 39/250 [00:39<03:46,  1.07s/it, loss=0.856]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  16%|â–ˆâ–Œ        | 40/250 [00:40<03:45,  1.08s/it, loss=0.856]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  16%|â–ˆâ–Œ        | 40/250 [00:40<03:45,  1.08s/it, loss=0.51] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  16%|â–ˆâ–‹        | 41/250 [00:41<03:44,  1.07s/it, loss=0.51]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  16%|â–ˆâ–‹        | 41/250 [00:41<03:44,  1.07s/it, loss=0.499]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  17%|â–ˆâ–‹        | 42/250 [00:42<03:43,  1.07s/it, loss=0.499]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  17%|â–ˆâ–‹        | 42/250 [00:42<03:43,  1.07s/it, loss=0.621]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  17%|â–ˆâ–‹        | 43/250 [00:43<03:42,  1.07s/it, loss=0.621]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  17%|â–ˆâ–‹        | 43/250 [00:43<03:42,  1.07s/it, loss=0.811]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  18%|â–ˆâ–Š        | 44/250 [00:44<03:40,  1.07s/it, loss=0.811]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  18%|â–ˆâ–Š        | 44/250 [00:44<03:40,  1.07s/it, loss=1.25] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  18%|â–ˆâ–Š        | 45/250 [00:46<03:39,  1.07s/it, loss=1.25]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  18%|â–ˆâ–Š        | 45/250 [00:46<03:39,  1.07s/it, loss=0.584]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  18%|â–ˆâ–Š        | 46/250 [00:47<03:37,  1.07s/it, loss=0.584]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  18%|â–ˆâ–Š        | 46/250 [00:47<03:37,  1.07s/it, loss=0.923]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  19%|â–ˆâ–‰        | 47/250 [00:48<03:35,  1.06s/it, loss=0.923]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  19%|â–ˆâ–‰        | 47/250 [00:48<03:35,  1.06s/it, loss=0.732]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  19%|â–ˆâ–‰        | 48/250 [00:49<03:33,  1.06s/it, loss=0.732]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  19%|â–ˆâ–‰        | 48/250 [00:49<03:33,  1.06s/it, loss=0.666]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  20%|â–ˆâ–‰        | 49/250 [00:50<03:31,  1.05s/it, loss=0.666]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  20%|â–ˆâ–‰        | 49/250 [00:50<03:31,  1.05s/it, loss=0.659]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  20%|â–ˆâ–ˆ        | 50/250 [00:51<03:29,  1.05s/it, loss=0.659]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  20%|â–ˆâ–ˆ        | 50/250 [00:51<03:29,  1.05s/it, loss=0.865]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  20%|â–ˆâ–ˆ        | 51/250 [00:52<03:27,  1.04s/it, loss=0.865]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  20%|â–ˆâ–ˆ        | 51/250 [00:52<03:27,  1.04s/it, loss=0.604]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  21%|â–ˆâ–ˆ        | 52/250 [00:53<03:25,  1.04s/it, loss=0.604]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  21%|â–ˆâ–ˆ        | 52/250 [00:53<03:25,  1.04s/it, loss=0.623]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  21%|â–ˆâ–ˆ        | 53/250 [00:54<03:23,  1.03s/it, loss=0.623]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  21%|â–ˆâ–ˆ        | 53/250 [00:54<03:23,  1.03s/it, loss=0.65] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 54/250 [00:55<03:22,  1.03s/it, loss=0.65]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 54/250 [00:55<03:22,  1.03s/it, loss=0.525]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 55/250 [00:56<03:20,  1.03s/it, loss=0.525]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 55/250 [00:56<03:20,  1.03s/it, loss=0.61] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 56/250 [00:57<03:19,  1.03s/it, loss=0.61]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  22%|â–ˆâ–ˆâ–       | 56/250 [00:57<03:19,  1.03s/it, loss=0.66]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  23%|â–ˆâ–ˆâ–       | 57/250 [00:58<03:17,  1.03s/it, loss=0.66]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  23%|â–ˆâ–ˆâ–       | 57/250 [00:58<03:17,  1.03s/it, loss=0.555]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  23%|â–ˆâ–ˆâ–       | 58/250 [00:59<03:16,  1.02s/it, loss=0.555]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  23%|â–ˆâ–ˆâ–       | 58/250 [00:59<03:16,  1.02s/it, loss=0.53] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  24%|â–ˆâ–ˆâ–       | 59/250 [01:00<03:15,  1.02s/it, loss=0.53]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  24%|â–ˆâ–ˆâ–       | 59/250 [01:00<03:15,  1.02s/it, loss=0.522]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  24%|â–ˆâ–ˆâ–       | 60/250 [01:01<03:13,  1.02s/it, loss=0.522]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  24%|â–ˆâ–ˆâ–       | 60/250 [01:01<03:13,  1.02s/it, loss=0.444]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  24%|â–ˆâ–ˆâ–       | 61/250 [01:02<03:12,  1.02s/it, loss=0.444]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  24%|â–ˆâ–ˆâ–       | 61/250 [01:02<03:12,  1.02s/it, loss=0.799]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  25%|â–ˆâ–ˆâ–       | 62/250 [01:03<03:10,  1.02s/it, loss=0.799]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  25%|â–ˆâ–ˆâ–       | 62/250 [01:03<03:10,  1.02s/it, loss=0.342]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 63/250 [01:04<03:09,  1.01s/it, loss=0.342]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  25%|â–ˆâ–ˆâ–Œ       | 63/250 [01:04<03:09,  1.01s/it, loss=0.756]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 64/250 [01:05<03:08,  1.01s/it, loss=0.756]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 64/250 [01:05<03:08,  1.01s/it, loss=0.352]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 65/250 [01:06<03:06,  1.01s/it, loss=0.352]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  26%|â–ˆâ–ˆâ–Œ       | 65/250 [01:06<03:06,  1.01s/it, loss=0.667]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  26%|â–ˆâ–ˆâ–‹       | 66/250 [01:07<03:05,  1.01s/it, loss=0.667]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  26%|â–ˆâ–ˆâ–‹       | 66/250 [01:07<03:05,  1.01s/it, loss=0.202]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  27%|â–ˆâ–ˆâ–‹       | 67/250 [01:08<03:04,  1.01s/it, loss=0.202]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  27%|â–ˆâ–ˆâ–‹       | 67/250 [01:08<03:04,  1.01s/it, loss=0.875]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  27%|â–ˆâ–ˆâ–‹       | 68/250 [01:09<03:03,  1.01s/it, loss=0.875]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  27%|â–ˆâ–ˆâ–‹       | 68/250 [01:09<03:03,  1.01s/it, loss=0.337]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 69/250 [01:10<03:01,  1.01s/it, loss=0.337]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 69/250 [01:10<03:01,  1.01s/it, loss=0.821]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 70/250 [01:11<03:00,  1.00s/it, loss=0.821]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 70/250 [01:11<03:00,  1.00s/it, loss=0.76] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 71/250 [01:12<02:59,  1.00s/it, loss=0.76]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  28%|â–ˆâ–ˆâ–Š       | 71/250 [01:12<02:59,  1.00s/it, loss=0.506]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  29%|â–ˆâ–ˆâ–‰       | 72/250 [01:13<02:58,  1.00s/it, loss=0.506]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  29%|â–ˆâ–ˆâ–‰       | 72/250 [01:13<02:58,  1.00s/it, loss=0.83] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  29%|â–ˆâ–ˆâ–‰       | 73/250 [01:14<02:56,  1.00it/s, loss=0.83]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  29%|â–ˆâ–ˆâ–‰       | 73/250 [01:14<02:56,  1.00it/s, loss=0.821]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  30%|â–ˆâ–ˆâ–‰       | 74/250 [01:15<02:56,  1.00s/it, loss=0.821]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  30%|â–ˆâ–ˆâ–‰       | 74/250 [01:15<02:56,  1.00s/it, loss=0.6]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 75/250 [01:16<02:54,  1.00it/s, loss=0.6]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 75/250 [01:16<02:54,  1.00it/s, loss=0.616]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 76/250 [01:17<02:53,  1.00it/s, loss=0.616]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  30%|â–ˆâ–ˆâ–ˆ       | 76/250 [01:17<02:53,  1.00it/s, loss=0.739]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 77/250 [01:18<02:52,  1.00it/s, loss=0.739]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 77/250 [01:18<02:52,  1.00it/s, loss=0.414]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 78/250 [01:19<02:51,  1.00it/s, loss=0.414]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  31%|â–ˆâ–ˆâ–ˆ       | 78/250 [01:19<02:51,  1.00it/s, loss=0.568]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 79/250 [01:20<02:50,  1.00it/s, loss=0.568]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 79/250 [01:20<02:50,  1.00it/s, loss=0.543]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 80/250 [01:21<02:49,  1.00it/s, loss=0.543]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 80/250 [01:21<02:49,  1.00it/s, loss=0.685]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 81/250 [01:22<02:48,  1.01it/s, loss=0.685]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  32%|â–ˆâ–ˆâ–ˆâ–      | 81/250 [01:22<02:48,  1.01it/s, loss=0.356]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 82/250 [01:23<02:47,  1.00it/s, loss=0.356]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 82/250 [01:23<02:47,  1.00it/s, loss=0.79] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 83/250 [01:24<02:46,  1.00it/s, loss=0.79]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  33%|â–ˆâ–ˆâ–ˆâ–      | 83/250 [01:24<02:46,  1.00it/s, loss=0.554]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 84/250 [01:25<02:45,  1.00it/s, loss=0.554]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 84/250 [01:25<02:45,  1.00it/s, loss=0.671]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 85/250 [01:26<02:44,  1.01it/s, loss=0.671]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 85/250 [01:26<02:44,  1.01it/s, loss=0.737]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 86/250 [01:27<02:43,  1.00it/s, loss=0.737]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  34%|â–ˆâ–ˆâ–ˆâ–      | 86/250 [01:27<02:43,  1.00it/s, loss=0.584]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 87/250 [01:28<02:42,  1.00it/s, loss=0.584]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–      | 87/250 [01:28<02:42,  1.00it/s, loss=0.52] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 88/250 [01:29<02:41,  1.01it/s, loss=0.52]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 88/250 [01:29<02:41,  1.01it/s, loss=0.928]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 89/250 [01:30<02:40,  1.00it/s, loss=0.928]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 89/250 [01:30<02:40,  1.00it/s, loss=0.667]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 90/250 [01:31<02:39,  1.00it/s, loss=0.667]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 90/250 [01:31<02:39,  1.00it/s, loss=0.805]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 91/250 [01:32<02:38,  1.00it/s, loss=0.805]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 91/250 [01:32<02:38,  1.00it/s, loss=0.614]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 92/250 [01:33<02:37,  1.00it/s, loss=0.614]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 92/250 [01:33<02:37,  1.00it/s, loss=0.566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 93/250 [01:34<02:36,  1.00it/s, loss=0.566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 93/250 [01:34<02:36,  1.00it/s, loss=0.954]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 94/250 [01:35<02:35,  1.00it/s, loss=0.954]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 94/250 [01:35<02:35,  1.00it/s, loss=0.691]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 95/250 [01:36<02:35,  1.00s/it, loss=0.691]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 95/250 [01:36<02:35,  1.00s/it, loss=0.507]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 96/250 [01:37<02:34,  1.00s/it, loss=0.507]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 96/250 [01:37<02:34,  1.00s/it, loss=0.658]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 97/250 [01:38<02:33,  1.00s/it, loss=0.658]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 97/250 [01:38<02:33,  1.00s/it, loss=0.702]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 98/250 [01:39<02:32,  1.01s/it, loss=0.702]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 98/250 [01:39<02:32,  1.01s/it, loss=0.683]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 99/250 [01:40<02:31,  1.01s/it, loss=0.683]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 99/250 [01:40<02:31,  1.01s/it, loss=0.528]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 100/250 [01:41<02:30,  1.01s/it, loss=0.528]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 100/250 [01:41<02:30,  1.01s/it, loss=0.584]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 101/250 [01:42<02:29,  1.00s/it, loss=0.584]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 101/250 [01:42<02:29,  1.00s/it, loss=0.665]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 102/250 [01:43<02:28,  1.00s/it, loss=0.665]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 102/250 [01:43<02:28,  1.00s/it, loss=0.643]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 103/250 [01:44<02:27,  1.01s/it, loss=0.643]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 103/250 [01:44<02:27,  1.01s/it, loss=0.691]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 104/250 [01:45<02:27,  1.01s/it, loss=0.691]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 104/250 [01:45<02:27,  1.01s/it, loss=0.807]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 105/250 [01:46<02:26,  1.01s/it, loss=0.807]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 105/250 [01:46<02:26,  1.01s/it, loss=0.73] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 106/250 [01:47<02:25,  1.01s/it, loss=0.73]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 106/250 [01:47<02:25,  1.01s/it, loss=0.645]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 107/250 [01:48<02:24,  1.01s/it, loss=0.645]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 107/250 [01:48<02:24,  1.01s/it, loss=0.832]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 108/250 [01:49<02:23,  1.01s/it, loss=0.832]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 108/250 [01:49<02:23,  1.01s/it, loss=0.566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 109/250 [01:50<02:22,  1.01s/it, loss=0.566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 109/250 [01:50<02:22,  1.01s/it, loss=0.659]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 110/250 [01:51<02:21,  1.01s/it, loss=0.659]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 110/250 [01:51<02:21,  1.01s/it, loss=0.813]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 111/250 [01:52<02:20,  1.01s/it, loss=0.813]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 111/250 [01:52<02:20,  1.01s/it, loss=0.584]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 112/250 [01:53<02:20,  1.01s/it, loss=0.584]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 112/250 [01:53<02:20,  1.01s/it, loss=0.675]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 113/250 [01:54<02:18,  1.01s/it, loss=0.675]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 113/250 [01:54<02:18,  1.01s/it, loss=0.649]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 114/250 [01:55<02:17,  1.01s/it, loss=0.649]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 114/250 [01:55<02:17,  1.01s/it, loss=0.819]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 115/250 [01:56<02:17,  1.02s/it, loss=0.819]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 115/250 [01:56<02:17,  1.02s/it, loss=0.646]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 116/250 [01:57<02:16,  1.02s/it, loss=0.646]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 116/250 [01:57<02:16,  1.02s/it, loss=0.489]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 117/250 [01:58<02:15,  1.02s/it, loss=0.489]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 117/250 [01:58<02:15,  1.02s/it, loss=0.458]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 118/250 [01:59<02:14,  1.02s/it, loss=0.458]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 118/250 [01:59<02:14,  1.02s/it, loss=0.417]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 119/250 [02:00<02:13,  1.02s/it, loss=0.417]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 119/250 [02:00<02:13,  1.02s/it, loss=0.53] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 120/250 [02:01<02:12,  1.02s/it, loss=0.53]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 120/250 [02:01<02:12,  1.02s/it, loss=1.37]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 121/250 [02:02<02:11,  1.02s/it, loss=1.37]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 121/250 [02:02<02:11,  1.02s/it, loss=0.795]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 122/250 [02:03<02:11,  1.03s/it, loss=0.795]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 122/250 [02:03<02:11,  1.03s/it, loss=0.601]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 123/250 [02:04<02:10,  1.03s/it, loss=0.601]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 123/250 [02:04<02:10,  1.03s/it, loss=0.488]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 124/250 [02:05<02:09,  1.02s/it, loss=0.488]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 124/250 [02:05<02:09,  1.02s/it, loss=0.599]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 125/250 [02:06<02:08,  1.02s/it, loss=0.599]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 125/250 [02:06<02:08,  1.02s/it, loss=0.618]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 126/250 [02:07<02:07,  1.02s/it, loss=0.618]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 126/250 [02:07<02:07,  1.02s/it, loss=0.721]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 127/250 [02:08<02:06,  1.02s/it, loss=0.721]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 127/250 [02:08<02:06,  1.02s/it, loss=0.663]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 128/250 [02:09<02:04,  1.02s/it, loss=0.663]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 128/250 [02:10<02:04,  1.02s/it, loss=0.753]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 129/250 [02:11<02:03,  1.02s/it, loss=0.753]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 129/250 [02:11<02:03,  1.02s/it, loss=0.636]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 130/250 [02:12<02:02,  1.02s/it, loss=0.636]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 130/250 [02:12<02:02,  1.02s/it, loss=0.718]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 131/250 [02:13<02:01,  1.02s/it, loss=0.718]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 131/250 [02:13<02:01,  1.02s/it, loss=0.933]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 132/250 [02:14<02:00,  1.02s/it, loss=0.933]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 132/250 [02:14<02:00,  1.02s/it, loss=0.609]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 133/250 [02:15<01:59,  1.02s/it, loss=0.609]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 133/250 [02:15<01:59,  1.02s/it, loss=0.799]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 134/250 [02:16<01:58,  1.02s/it, loss=0.799]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 134/250 [02:16<01:58,  1.02s/it, loss=0.73] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 135/250 [02:17<01:57,  1.02s/it, loss=0.73]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 135/250 [02:17<01:57,  1.02s/it, loss=0.685]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 136/250 [02:18<01:56,  1.02s/it, loss=0.685]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 136/250 [02:18<01:56,  1.02s/it, loss=0.644]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 137/250 [02:19<01:55,  1.02s/it, loss=0.644]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 137/250 [02:19<01:55,  1.02s/it, loss=0.566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 138/250 [02:20<01:54,  1.02s/it, loss=0.566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 138/250 [02:20<01:54,  1.02s/it, loss=0.587]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 139/250 [02:21<01:53,  1.02s/it, loss=0.587]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 139/250 [02:21<01:53,  1.02s/it, loss=0.533]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 140/250 [02:22<01:52,  1.02s/it, loss=0.533]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 140/250 [02:22<01:52,  1.02s/it, loss=0.503]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 141/250 [02:23<01:51,  1.02s/it, loss=0.503]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 141/250 [02:23<01:51,  1.02s/it, loss=0.632]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 142/250 [02:24<01:50,  1.02s/it, loss=0.632]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 142/250 [02:24<01:50,  1.02s/it, loss=0.836]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 143/250 [02:25<01:49,  1.02s/it, loss=0.836]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 143/250 [02:25<01:49,  1.02s/it, loss=0.62] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 144/250 [02:26<01:48,  1.02s/it, loss=0.62]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 144/250 [02:26<01:48,  1.02s/it, loss=0.482]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 145/250 [02:27<01:47,  1.02s/it, loss=0.482]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 145/250 [02:27<01:47,  1.02s/it, loss=0.646]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 146/250 [02:28<01:45,  1.02s/it, loss=0.646]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 146/250 [02:28<01:45,  1.02s/it, loss=0.571]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 147/250 [02:29<01:44,  1.02s/it, loss=0.571]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 147/250 [02:29<01:44,  1.02s/it, loss=0.387]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 148/250 [02:30<01:43,  1.02s/it, loss=0.387]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 148/250 [02:30<01:43,  1.02s/it, loss=0.675]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 149/250 [02:31<01:42,  1.02s/it, loss=0.675]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 149/250 [02:31<01:42,  1.02s/it, loss=0.607]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 150/250 [02:32<01:41,  1.02s/it, loss=0.607]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 150/250 [02:32<01:41,  1.02s/it, loss=0.504]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 151/250 [02:33<01:40,  1.01s/it, loss=0.504]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 151/250 [02:33<01:40,  1.01s/it, loss=0.348]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 152/250 [02:34<01:39,  1.01s/it, loss=0.348]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 152/250 [02:34<01:39,  1.01s/it, loss=0.618]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 153/250 [02:35<01:38,  1.01s/it, loss=0.618]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 153/250 [02:35<01:38,  1.01s/it, loss=0.788]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 154/250 [02:36<01:37,  1.01s/it, loss=0.788]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 154/250 [02:36<01:37,  1.01s/it, loss=0.848]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 155/250 [02:37<01:36,  1.01s/it, loss=0.848]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 155/250 [02:37<01:36,  1.01s/it, loss=1.05] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 156/250 [02:38<01:35,  1.01s/it, loss=1.05]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 156/250 [02:38<01:35,  1.01s/it, loss=0.419]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 157/250 [02:39<01:34,  1.01s/it, loss=0.419]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 157/250 [02:39<01:34,  1.01s/it, loss=0.607]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 158/250 [02:40<01:33,  1.01s/it, loss=0.607]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 158/250 [02:40<01:33,  1.01s/it, loss=0.71] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 159/250 [02:41<01:31,  1.01s/it, loss=0.71]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 159/250 [02:41<01:31,  1.01s/it, loss=0.792]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 160/250 [02:42<01:30,  1.01s/it, loss=0.792]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 160/250 [02:42<01:30,  1.01s/it, loss=0.36] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 161/250 [02:43<01:29,  1.01s/it, loss=0.36]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 161/250 [02:43<01:29,  1.01s/it, loss=0.694]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 162/250 [02:44<01:28,  1.01s/it, loss=0.694]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 162/250 [02:44<01:28,  1.01s/it, loss=0.488]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 163/250 [02:45<01:28,  1.01s/it, loss=0.488]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 163/250 [02:45<01:28,  1.01s/it, loss=0.373]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 164/250 [02:46<01:26,  1.01s/it, loss=0.373]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 164/250 [02:46<01:26,  1.01s/it, loss=0.493]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 165/250 [02:47<01:25,  1.01s/it, loss=0.493]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 165/250 [02:47<01:25,  1.01s/it, loss=1.07] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 166/250 [02:48<01:24,  1.01s/it, loss=1.07]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 166/250 [02:48<01:24,  1.01s/it, loss=0.351]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 167/250 [02:49<01:23,  1.01s/it, loss=0.351]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 167/250 [02:49<01:23,  1.01s/it, loss=0.378]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 168/250 [02:50<01:22,  1.01s/it, loss=0.378]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 168/250 [02:50<01:22,  1.01s/it, loss=0.576]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 169/250 [02:51<01:21,  1.01s/it, loss=0.576]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 169/250 [02:51<01:21,  1.01s/it, loss=0.414]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 170/250 [02:52<01:20,  1.01s/it, loss=0.414]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 170/250 [02:52<01:20,  1.01s/it, loss=1.02] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 171/250 [02:53<01:19,  1.01s/it, loss=1.02]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 171/250 [02:53<01:19,  1.01s/it, loss=0.648]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 172/250 [02:54<01:18,  1.01s/it, loss=0.648]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 172/250 [02:54<01:18,  1.01s/it, loss=0.811]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 173/250 [02:55<01:17,  1.01s/it, loss=0.811]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 173/250 [02:55<01:17,  1.01s/it, loss=0.372]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 174/250 [02:56<01:16,  1.01s/it, loss=0.372]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 174/250 [02:56<01:16,  1.01s/it, loss=0.431]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 175/250 [02:57<01:15,  1.01s/it, loss=0.431]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 175/250 [02:57<01:15,  1.01s/it, loss=0.566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 176/250 [02:58<01:14,  1.01s/it, loss=0.566]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 176/250 [02:58<01:14,  1.01s/it, loss=0.411]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 177/250 [02:59<01:13,  1.01s/it, loss=0.411]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 177/250 [02:59<01:13,  1.01s/it, loss=0.365]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 178/250 [03:00<01:12,  1.01s/it, loss=0.365]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 178/250 [03:00<01:12,  1.01s/it, loss=0.348]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 179/250 [03:01<01:11,  1.01s/it, loss=0.348]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 179/250 [03:01<01:11,  1.01s/it, loss=0.528]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 180/250 [03:02<01:10,  1.01s/it, loss=0.528]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 180/250 [03:02<01:10,  1.01s/it, loss=0.741]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 181/250 [03:03<01:09,  1.01s/it, loss=0.741]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 181/250 [03:03<01:09,  1.01s/it, loss=0.327]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 182/250 [03:04<01:08,  1.01s/it, loss=0.327]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 182/250 [03:04<01:08,  1.01s/it, loss=1.03] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 183/250 [03:05<01:07,  1.01s/it, loss=1.03]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 183/250 [03:05<01:07,  1.01s/it, loss=1.1] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 184/250 [03:06<01:06,  1.01s/it, loss=1.1]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 184/250 [03:06<01:06,  1.01s/it, loss=0.782]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 185/250 [03:07<01:05,  1.01s/it, loss=0.782]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 185/250 [03:07<01:05,  1.01s/it, loss=0.575]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 186/250 [03:08<01:04,  1.01s/it, loss=0.575]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 186/250 [03:08<01:04,  1.01s/it, loss=0.382]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 187/250 [03:09<01:03,  1.01s/it, loss=0.382]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 187/250 [03:09<01:03,  1.01s/it, loss=0.342]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 188/250 [03:10<01:02,  1.01s/it, loss=0.342]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 188/250 [03:10<01:02,  1.01s/it, loss=0.5]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 189/250 [03:11<01:01,  1.01s/it, loss=0.5]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 189/250 [03:11<01:01,  1.01s/it, loss=0.807]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 190/250 [03:12<01:00,  1.01s/it, loss=0.807]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 190/250 [03:12<01:00,  1.01s/it, loss=0.443]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 191/250 [03:13<00:59,  1.01s/it, loss=0.443]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 191/250 [03:13<00:59,  1.01s/it, loss=0.234]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 192/250 [03:14<00:58,  1.01s/it, loss=0.234]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 192/250 [03:14<00:58,  1.01s/it, loss=0.484]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 193/250 [03:15<00:57,  1.01s/it, loss=0.484]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 193/250 [03:15<00:57,  1.01s/it, loss=0.974]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 194/250 [03:16<00:56,  1.01s/it, loss=0.974]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 194/250 [03:16<00:56,  1.01s/it, loss=0.729]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 195/250 [03:17<00:55,  1.01s/it, loss=0.729]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 195/250 [03:17<00:55,  1.01s/it, loss=0.393]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 196/250 [03:18<00:54,  1.00s/it, loss=0.393]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 196/250 [03:18<00:54,  1.00s/it, loss=0.993]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 197/250 [03:19<00:53,  1.00s/it, loss=0.993]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 197/250 [03:19<00:53,  1.00s/it, loss=0.562]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 198/250 [03:20<00:52,  1.00s/it, loss=0.562]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 198/250 [03:20<00:52,  1.00s/it, loss=0.591]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 199/250 [03:21<00:51,  1.00s/it, loss=0.591]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 199/250 [03:21<00:51,  1.00s/it, loss=0.405]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 200/250 [03:22<00:50,  1.01s/it, loss=0.405]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 200/250 [03:22<00:50,  1.01s/it, loss=0.419]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 201/250 [03:23<00:49,  1.01s/it, loss=0.419]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 201/250 [03:23<00:49,  1.01s/it, loss=0.427]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 202/250 [03:24<00:48,  1.01s/it, loss=0.427]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 202/250 [03:24<00:48,  1.01s/it, loss=0.781]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 203/250 [03:25<00:47,  1.01s/it, loss=0.781]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 203/250 [03:25<00:47,  1.01s/it, loss=0.608]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 204/250 [03:26<00:46,  1.01s/it, loss=0.608]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 204/250 [03:26<00:46,  1.01s/it, loss=0.499]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 205/250 [03:27<00:45,  1.01s/it, loss=0.499]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 205/250 [03:27<00:45,  1.01s/it, loss=0.55] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 206/250 [03:28<00:44,  1.01s/it, loss=0.55]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 206/250 [03:28<00:44,  1.01s/it, loss=0.8] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 207/250 [03:29<00:43,  1.01s/it, loss=0.8]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 207/250 [03:29<00:43,  1.01s/it, loss=0.495]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 208/250 [03:30<00:42,  1.01s/it, loss=0.495]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 208/250 [03:30<00:42,  1.01s/it, loss=0.739]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 209/250 [03:31<00:41,  1.01s/it, loss=0.739]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 209/250 [03:31<00:41,  1.01s/it, loss=0.695]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 210/250 [03:32<00:40,  1.01s/it, loss=0.695]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 210/250 [03:32<00:40,  1.01s/it, loss=0.73] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 211/250 [03:33<00:39,  1.01s/it, loss=0.73]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 211/250 [03:33<00:39,  1.01s/it, loss=0.379]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 212/250 [03:34<00:38,  1.01s/it, loss=0.379]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 212/250 [03:34<00:38,  1.01s/it, loss=0.516]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 213/250 [03:35<00:37,  1.01s/it, loss=0.516]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 213/250 [03:35<00:37,  1.01s/it, loss=0.386]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 214/250 [03:36<00:36,  1.01s/it, loss=0.386]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 214/250 [03:36<00:36,  1.01s/it, loss=1.03] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 215/250 [03:37<00:35,  1.01s/it, loss=1.03]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 215/250 [03:37<00:35,  1.01s/it, loss=0.495]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 216/250 [03:38<00:34,  1.01s/it, loss=0.495]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 216/250 [03:38<00:34,  1.01s/it, loss=0.815]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 217/250 [03:39<00:33,  1.01s/it, loss=0.815]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 217/250 [03:39<00:33,  1.01s/it, loss=0.886]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 218/250 [03:40<00:32,  1.01s/it, loss=0.886]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 218/250 [03:40<00:32,  1.01s/it, loss=0.578]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 219/250 [03:41<00:31,  1.01s/it, loss=0.578]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 219/250 [03:41<00:31,  1.01s/it, loss=0.365]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 220/250 [03:42<00:30,  1.01s/it, loss=0.365]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 220/250 [03:42<00:30,  1.01s/it, loss=0.66] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 221/250 [03:43<00:29,  1.01s/it, loss=0.66]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 221/250 [03:44<00:29,  1.01s/it, loss=0.709]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 222/250 [03:44<00:28,  1.01s/it, loss=0.709]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 222/250 [03:45<00:28,  1.01s/it, loss=0.294]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 223/250 [03:45<00:27,  1.01s/it, loss=0.294]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 223/250 [03:46<00:27,  1.01s/it, loss=0.723]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 224/250 [03:47<00:26,  1.01s/it, loss=0.723]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 224/250 [03:47<00:26,  1.01s/it, loss=0.829]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 225/250 [03:48<00:25,  1.01s/it, loss=0.829]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 225/250 [03:48<00:25,  1.01s/it, loss=0.612]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 226/250 [03:49<00:24,  1.01s/it, loss=0.612]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 226/250 [03:49<00:24,  1.01s/it, loss=0.629]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 227/250 [03:50<00:23,  1.01s/it, loss=0.629]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 227/250 [03:50<00:23,  1.01s/it, loss=0.808]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 228/250 [03:51<00:22,  1.01s/it, loss=0.808]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 228/250 [03:51<00:22,  1.01s/it, loss=0.503]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 229/250 [03:52<00:21,  1.01s/it, loss=0.503]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 229/250 [03:52<00:21,  1.01s/it, loss=0.707]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 230/250 [03:53<00:20,  1.01s/it, loss=0.707]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 230/250 [03:53<00:20,  1.01s/it, loss=0.752]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 231/250 [03:54<00:19,  1.01s/it, loss=0.752]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 231/250 [03:54<00:19,  1.01s/it, loss=0.455]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 232/250 [03:55<00:18,  1.01s/it, loss=0.455]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 232/250 [03:55<00:18,  1.01s/it, loss=0.839]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 233/250 [03:56<00:17,  1.01s/it, loss=0.839]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 233/250 [03:56<00:17,  1.01s/it, loss=0.491]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 234/250 [03:57<00:16,  1.01s/it, loss=0.491]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 234/250 [03:57<00:16,  1.01s/it, loss=0.581]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 235/250 [03:58<00:15,  1.01s/it, loss=0.581]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 235/250 [03:58<00:15,  1.01s/it, loss=0.864]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 236/250 [03:59<00:14,  1.01s/it, loss=0.864]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 236/250 [03:59<00:14,  1.01s/it, loss=0.634]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 237/250 [04:00<00:13,  1.01s/it, loss=0.634]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 237/250 [04:00<00:13,  1.01s/it, loss=0.539]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 238/250 [04:01<00:12,  1.01s/it, loss=0.539]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 238/250 [04:01<00:12,  1.01s/it, loss=0.74] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 239/250 [04:02<00:11,  1.01s/it, loss=0.74]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 239/250 [04:02<00:11,  1.01s/it, loss=0.669]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 240/250 [04:03<00:10,  1.01s/it, loss=0.669]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 240/250 [04:03<00:10,  1.01s/it, loss=0.575]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 241/250 [04:04<00:09,  1.01s/it, loss=0.575]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 241/250 [04:04<00:09,  1.01s/it, loss=0.572]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 242/250 [04:05<00:08,  1.01s/it, loss=0.572]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 242/250 [04:05<00:08,  1.01s/it, loss=0.741]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 243/250 [04:06<00:07,  1.01s/it, loss=0.741]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 243/250 [04:06<00:07,  1.01s/it, loss=0.576]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 244/250 [04:07<00:06,  1.01s/it, loss=0.576]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 244/250 [04:07<00:06,  1.01s/it, loss=0.634]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 245/250 [04:08<00:05,  1.01s/it, loss=0.634]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 245/250 [04:08<00:05,  1.01s/it, loss=0.77] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 246/250 [04:09<00:04,  1.01s/it, loss=0.77]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 246/250 [04:09<00:04,  1.01s/it, loss=0.782]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 247/250 [04:10<00:03,  1.01s/it, loss=0.782]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 247/250 [04:10<00:03,  1.01s/it, loss=0.431]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 248/250 [04:11<00:02,  1.01s/it, loss=0.431]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 248/250 [04:11<00:02,  1.01s/it, loss=1.21] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 249/250 [04:12<00:01,  1.01s/it, loss=1.21]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 249/250 [04:12<00:01,  1.01s/it, loss=0.651]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [04:13<00:00,  1.01s/it, loss=0.651]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [04:13<00:00,  1.01s/it, loss=0.551]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Train epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train step of epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [04:30<00:00,  1.08s/it, loss=0.616, dist_mean=0.27]\u001b[A\u001b[A\u001b[A\n",
      "Train epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.28s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(use_lora=0)\n",
    "\n",
    "model.save_pretrained('/KoChatGPT/output_2_RM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "919f08b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: ëŒ€í•œë¯¼êµ­ì—ì„œ ê°€ì¥ ë†’ì€ ì‚°ì˜ ì´ë¦„ê³¼ ë†’ì´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "reward score: -1.1\n"
     ]
    }
   ],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward\n",
    "\n",
    "input_text = 'ëŒ€í•œë¯¼êµ­ì—ì„œ ê°€ì¥ ë†’ì€ ì‚°ì˜ ì´ë¦„ê³¼ ë†’ì´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?'\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ab23a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„°ì—ì„œ ìŒì„± ë° ì‘ì„±ëœ ì–¸ì–´ë¥¼ ë³´ê³  ì´í•´í•˜ê³  ë²ˆì—­í•˜ê³  ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¶”ì²œí•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬ ë‹¤ì–‘í•œ ê³ ê¸‰ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì¼ë ¨ì˜ ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
      "reward score: -0.7\n"
     ]
    }
   ],
   "source": [
    "input_text = 'ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„°ì—ì„œ ìŒì„± ë° ì‘ì„±ëœ ì–¸ì–´ë¥¼ ë³´ê³  ì´í•´í•˜ê³  ë²ˆì—­í•˜ê³  ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¶”ì²œí•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬ ë‹¤ì–‘í•œ ê³ ê¸‰ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì¼ë ¨ì˜ ê¸°ìˆ ì…ë‹ˆë‹¤.'\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f251bfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„°ì—ì„œ ìŒì„± ë° ì‘ì„±ëœ ì–¸ì–´ë¥¼ ë³´ê³  ì´í•´í•˜ê³  ë²ˆì—­í•˜ê³  ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¶”ì²œí•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬ ë‹¤ì–‘í•œ ê³ ê¸‰ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì¼ë ¨ì˜ ê¸°ìˆ ì…ë‹ˆë‹¤. AIëŠ” í˜„ëŒ€ì ì¸ ì»´í“¨íŒ… í˜ì‹ ì—ì„œ ì¤‘ì¶”ì ì¸ ì—­í• ì„ í•˜ë©° ê°œì¸ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ì˜ ê°€ì¹˜ë¥¼ ì°½ì¶œí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ê´‘í•™ ë¬¸ì ì¸ì‹(OCR)ì€ AIë¥¼ ì‚¬ìš©í•´ ì´ë¯¸ì§€ ë° ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ë° ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³ , êµ¬ì¡°í™”ë˜ì§€ ì•Šì€ ì½˜í…ì¸ ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ì— ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë§Œë“¤ê³ , ìœ ìš©í•œ ì •ë³´ë¥¼ ì°½ì¶œí•©ë‹ˆë‹¤.\n",
      "reward score: -0.5\n"
     ]
    }
   ],
   "source": [
    "input_text = \"ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„°ì—ì„œ ìŒì„± ë° ì‘ì„±ëœ ì–¸ì–´ë¥¼ ë³´ê³  ì´í•´í•˜ê³  ë²ˆì—­í•˜ê³  ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¶”ì²œí•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•˜ì—¬ ë‹¤ì–‘í•œ ê³ ê¸‰ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì¼ë ¨ì˜ ê¸°ìˆ ì…ë‹ˆë‹¤. AIëŠ” í˜„ëŒ€ì ì¸ ì»´í“¨íŒ… í˜ì‹ ì—ì„œ ì¤‘ì¶”ì ì¸ ì—­í• ì„ í•˜ë©° ê°œì¸ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ì˜ ê°€ì¹˜ë¥¼ ì°½ì¶œí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ê´‘í•™ ë¬¸ì ì¸ì‹(OCR)ì€ AIë¥¼ ì‚¬ìš©í•´ ì´ë¯¸ì§€ ë° ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ë° ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³ , êµ¬ì¡°í™”ë˜ì§€ ì•Šì€ ì½˜í…ì¸ ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ì— ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë§Œë“¤ê³ , ìœ ìš©í•œ ì •ë³´ë¥¼ ì°½ì¶œí•©ë‹ˆë‹¤.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5e845e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: ì¸ê³µì§€ëŠ¥ì€ ì¼ë°˜ì ìœ¼ë¡œ ì¸ê°„ì˜ ì§€ëŠ¥ì´ í•„ìš”í•˜ê±°ë‚˜ ì¸ê°„ì´ ë¶„ì„í•  ìˆ˜ ìˆëŠ” ê²ƒë³´ë‹¤ ê·œëª¨ê°€ í° ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì¶”ë¡ , í•™ìŠµ ë° í–‰ë™í•  ìˆ˜ ìˆëŠ” ì»´í“¨í„° ë° ê¸°ê³„ë¥¼ êµ¬ì¶•í•˜ëŠ” ê²ƒê³¼ ê´€ë ¨ëœ ê³¼í•™ ë¶„ì•¼ì…ë‹ˆë‹¤. AIëŠ” ì»´í“¨í„° ê³µí•™, ë°ì´í„° ë¶„ì„ ë° í†µê³„, í•˜ë“œì›¨ì–´ ë° ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§, ì–¸ì–´í•™, ì‹ ê²½ ê³¼í•™ì€ ë¬¼ë¡  ì² í•™ê³¼ ì‹¬ë¦¬í•™ì„ í¬í•¨í•˜ì—¬ ì—¬ëŸ¬ í•™ë¬¸ì„ í¬ê´„í•˜ëŠ” ê´‘ë²”ìœ„í•œ ë¶„ì•¼ì…ë‹ˆë‹¤. ë¹„ì¦ˆë‹ˆìŠ¤ì˜ ìš´ì˜ ìˆ˜ì¤€ì—ì„œ AIëŠ” ì£¼ë¡œ ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ ëŸ¬ë‹ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ê¸°ìˆ  ëª¨ìŒìœ¼ë¡œ, ë°ì´í„° ë¶„ì„, ì˜ˆìƒ ë° ì˜ˆì¸¡, ê°ì²´ ë¶„ë¥˜, ìì—°ì–´ ì²˜ë¦¬, ì¶”ì²œ, ì§€ëŠ¥í˜• ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ë“±ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "reward score: -0.4\n"
     ]
    }
   ],
   "source": [
    "input_text = \"ì¸ê³µì§€ëŠ¥ì€ ì¼ë°˜ì ìœ¼ë¡œ ì¸ê°„ì˜ ì§€ëŠ¥ì´ í•„ìš”í•˜ê±°ë‚˜ ì¸ê°„ì´ ë¶„ì„í•  ìˆ˜ ìˆëŠ” ê²ƒë³´ë‹¤ ê·œëª¨ê°€ í° ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì¶”ë¡ , í•™ìŠµ ë° í–‰ë™í•  ìˆ˜ ìˆëŠ” ì»´í“¨í„° ë° ê¸°ê³„ë¥¼ êµ¬ì¶•í•˜ëŠ” ê²ƒê³¼ ê´€ë ¨ëœ ê³¼í•™ ë¶„ì•¼ì…ë‹ˆë‹¤. AIëŠ” ì»´í“¨í„° ê³µí•™, ë°ì´í„° ë¶„ì„ ë° í†µê³„, í•˜ë“œì›¨ì–´ ë° ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§, ì–¸ì–´í•™, ì‹ ê²½ ê³¼í•™ì€ ë¬¼ë¡  ì² í•™ê³¼ ì‹¬ë¦¬í•™ì„ í¬í•¨í•˜ì—¬ ì—¬ëŸ¬ í•™ë¬¸ì„ í¬ê´„í•˜ëŠ” ê´‘ë²”ìœ„í•œ ë¶„ì•¼ì…ë‹ˆë‹¤. ë¹„ì¦ˆë‹ˆìŠ¤ì˜ ìš´ì˜ ìˆ˜ì¤€ì—ì„œ AIëŠ” ì£¼ë¡œ ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ ëŸ¬ë‹ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ê¸°ìˆ  ëª¨ìŒìœ¼ë¡œ, ë°ì´í„° ë¶„ì„, ì˜ˆìƒ ë° ì˜ˆì¸¡, ê°ì²´ ë¶„ë¥˜, ìì—°ì–´ ì²˜ë¦¬, ì¶”ì²œ, ì§€ëŠ¥í˜• ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ë“±ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15c7067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43669689",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='/KoChatGPT/output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='/KoChatGPT/output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0425844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7217485",
   "metadata": {},
   "outputs": [],
   "source": [
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8af8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "84e40f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=1,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4bdfcef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Episode [1/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [1/10]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:06<00:13,  6.89s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [1/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:13<00:06,  6.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.000338]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.61it/s, actor_loss=0, critic_loss=0.000338]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:01,  1.61it/s, actor_loss=0, critic_loss=0.164]   \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.68it/s, actor_loss=0, critic_loss=0.164]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.68it/s, actor_loss=0, critic_loss=0.0113]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.69it/s, actor_loss=0, critic_loss=0.0113]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [1/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [2/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [2/10]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:07<00:14,  7.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [2/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:14<00:07,  7.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.206, critic_loss=0.0406]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.59it/s, actor_loss=0.206, critic_loss=0.0406]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:01,  1.59it/s, actor_loss=0.295, critic_loss=0.0926]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.59it/s, actor_loss=0.295, critic_loss=0.0926]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.59it/s, actor_loss=0.198, critic_loss=0.0672]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.59it/s, actor_loss=0.198, critic_loss=0.0672]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [2/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  7.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [3/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [3/10]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:07<00:14,  7.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [3/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:14<00:07,  7.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.13, critic_loss=0.019]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.65it/s, actor_loss=0.13, critic_loss=0.019]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:01,  1.65it/s, actor_loss=0.117, critic_loss=0.00108]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.67it/s, actor_loss=0.117, critic_loss=0.00108]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.67it/s, actor_loss=0.13, critic_loss=0.022]   \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.67it/s, actor_loss=0.13, critic_loss=0.022]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [3/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  7.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [4/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [4/10]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:07<00:14,  7.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [4/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:14<00:07,  7.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.19, critic_loss=0.0413]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.64it/s, actor_loss=-.19, critic_loss=0.0413]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:01,  1.64it/s, actor_loss=-.194, critic_loss=0.041]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.66it/s, actor_loss=-.194, critic_loss=0.041]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.66it/s, actor_loss=-.208, critic_loss=0.0238]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.67it/s, actor_loss=-.208, critic_loss=0.0238]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [4/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [5/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [5/10]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:06<00:13,  6.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [5/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:13<00:06,  6.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0578, critic_loss=0.00362]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.65it/s, actor_loss=-.0578, critic_loss=0.00362]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:01,  1.65it/s, actor_loss=-.0507, critic_loss=0.00304]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.65it/s, actor_loss=-.0507, critic_loss=0.00304]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.65it/s, actor_loss=-.0483, critic_loss=0.0198] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.65it/s, actor_loss=-.0483, critic_loss=0.0198]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [5/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [6/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [6/10]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:07<00:14,  7.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [6/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:14<00:07,  7.08s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.16, critic_loss=0.0234]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.63it/s, actor_loss=0.16, critic_loss=0.0234]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:01,  1.63it/s, actor_loss=0.172, critic_loss=0.0279]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.63it/s, actor_loss=0.172, critic_loss=0.0279]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.63it/s, actor_loss=0.162, critic_loss=0.0124]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.64it/s, actor_loss=0.162, critic_loss=0.0124]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [6/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  7.74s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [7/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [7/10]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:07<00:14,  7.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [7/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:14<00:07,  7.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0134, critic_loss=0.00229]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.65it/s, actor_loss=0.0134, critic_loss=0.00229]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:01,  1.65it/s, actor_loss=0.00472, critic_loss=0.00411]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.66it/s, actor_loss=0.00472, critic_loss=0.00411]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.66it/s, actor_loss=0.0122, critic_loss=0.0125]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.66it/s, actor_loss=0.0122, critic_loss=0.0125]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [7/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:23<00:00,  7.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [8/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [8/10]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:06<00:13,  6.88s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [8/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:13<00:06,  6.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.108, critic_loss=0.00957]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.64it/s, actor_loss=-.108, critic_loss=0.00957]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:01,  1.64it/s, actor_loss=-.127, critic_loss=0.0132] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.66it/s, actor_loss=-.127, critic_loss=0.0132]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.66it/s, actor_loss=-.116, critic_loss=0.00929]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.66it/s, actor_loss=-.116, critic_loss=0.00929]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [8/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [9/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [9/10]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:07<00:14,  7.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [9/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:12<00:06,  6.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0279, critic_loss=0.00136]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.66it/s, actor_loss=-.0279, critic_loss=0.00136]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:01,  1.66it/s, actor_loss=-.0236, critic_loss=0.00178]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.67it/s, actor_loss=-.0236, critic_loss=0.00178]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.67it/s, actor_loss=-.017, critic_loss=0.0102]  \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.67it/s, actor_loss=-.017, critic_loss=0.0102]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [9/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:21<00:00,  7.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [10/10]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Episode [10/10]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:06<00:13,  6.98s/it]\u001b[A\u001b[A\n",
      "\n",
      "Episode [10/10]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:13<00:07,  7.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0972, critic_loss=0.0129]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:00<00:01,  1.66it/s, actor_loss=0.0972, critic_loss=0.0129]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:01<00:01,  1.66it/s, actor_loss=0.0952, critic_loss=0.00798]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.67it/s, actor_loss=0.0952, critic_loss=0.00798]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.67it/s, actor_loss=0.0928, critic_loss=0.00192]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Train epoch [1/1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.67it/s, actor_loss=0.0928, critic_loss=0.00192]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Episode [10/10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:20<00:00,  7.00s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "model.save_pretrained('/KoChatGPT/output_3_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5bbc20a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(ëª…ë ¹ì–´):\n",
      "ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì—ìš”?\n",
      "\n",
      "### Response(ì‘ë‹µ):'ì£„ì†¡í•©ë‹ˆë‹¤, ì œê°€ ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì´ë¯€ë¡œ ì´ì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œì§€ ëª»í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ \"ë¶ˆê³ ê¸°\"ê°€ ì–´ëŠ ì§€ì—­ì¸ì§€ ì•Œë ¤ì£¼ì‹œë©´ ë” ìì„¸í•œ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. ç¥æ–‡å­—ã€Œå®—æ›¸ã€ì…ë‹ˆë‹¤. è‡£è¡†æ›¸ ã€æ±]ì…ë‹ˆë‹¤. \"ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì— ê´€í•œ í•œìš°(éŸ“ç‰›)ë¼ëŠ” ë§ì´ ìˆìŠµë‹ˆë‹¤. \"ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ëŠ” ìš°ë¦¬ê°€ ì•Œê³  ìˆëŠ” í•œìš°(éŸ“ç‰›)ë¼ëŠ” ëœ»ìœ¼ë¡œ, ë§ì€ ì§€ì—­ì—ì„œ ìë¼ëŠ” ì‡ ê³ ê¸°ì˜ í•œìš°ë¥¼ ì¼ì»«ëŠ” ë§ì…ë‹ˆë‹¤. ç¥æ–‡å­— ã€Œè‡ªã€(ë˜ëŠ”)ì…ë‹ˆë‹¤. é«˜æ›¸ã€ì…ë‹ˆë‹¤. é«˜ æ›¸ ã€ç¥æ–‡å­—ã€Œè‡ªã€ì…ë‹ˆë‹¤. ç¥æ–‡å­—ã€Œè‡ªã€ê»˜ì„œ \"ë¶ˆê³ ê¸°ìš© í•œìš°ëŠ” ìš°ë¦¬ê°€ ì•Œê³  ìˆëŠ” í•œìš°ë¥¼ ë§í•˜ëŠ” ë§ì…ë‹ˆë‹¤. ç¥æ›¸ã€Œè‡ªã€ì˜ ëœ»ì´ \"ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì˜ í•œìš°(éŸ“ç‰›)ë¼ê³  í•˜ì˜€ìŠµë‹ˆë‹¤.\", 'token': 174} ä¿¡æ–‡è€…ã€Œè‡ªã€ \"ç¥æ›¸ ã€Šä¸å­¤é«˜ç‰›\" å­éš†ä¹‹æ³•( å­æ³•åˆ¶ç„¡åŠ©æ\n",
      "\n",
      "### Instruction(ëª…ë ¹ì–´):\n",
      "ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì´ 43ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•œ ë…„ë„ëŠ”?\n",
      "\n",
      "### Response(ì‘ë‹µ):'ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 55ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. 1952ë…„ 12ì›” 10ì¼, ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 32ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. 1952ë…„ 1ì›” 11ì¼: ê·¸ëŠ” ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 50ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 50ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 35ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 50ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 35ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 43ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 53ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 39ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 41ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 30ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 50ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 30ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 30ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 31ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 30ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 40ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰\n",
      "\n",
      "### Instruction(ëª…ë ¹ì–´):\n",
      "ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ì–´ë””ì— ìˆì–´\n",
      "\n",
      "### Response(ì‘ë‹µ):'ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ë¯¸êµ­ ë¯¸ë„¤ì†Œíƒ€ì£¼ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤.è‹±å¯©åœ‹éš› êµ­ì œê³µí•­ì´ë¼ê³ ë„ ë¶ˆë¦½ë‹ˆë‹¤.è‹±å¯©åœ‹éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ë¯¸ë„¤ì†Œíƒ€ì£¼ ì‹œì¹´ê³ ì˜ êµ­ì œê³µí•­ìœ¼ë¡œ, í˜„ì¬ëŠ” ë¯¸êµ­ ì¤‘ì„œë¶€ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤.è‹±åœ‹éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ë¯¸ë„¤ì†Œíƒ€ì£¼ì˜ ì„¸ì¸íŠ¸ë£¨ì´ìŠ¤ ì£¼ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤.è‹±åœ‹éš› êµ­ì œê³µí•­ì€ 1869ë…„ 3ì›” 15ì¼ì— ì„¤ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤.è‹±å›½éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ë¯¸ë„¤ì†Œíƒ€ì£¼ ì•Œë¡ ì‹œì•„ë‚˜ì—ê²Œ ìœ„ì¹˜í•´ ìˆìœ¼ë©°, í˜„ì¬ëŠ” êµ­ì œê³µí•­ìœ¼ë¡œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.è‹±åœ‹éš› êµ­ì œê³µí•­ì€ í˜„ì¬ê¹Œì§€ë„ ë¯¸êµ­ ì¤‘ì„œë¶€ì—ì„œ ë§¤ìš° ì¸ê¸°ìˆëŠ” ë„ì‹œ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.è‹±å›½éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ì¤‘ì„œë¶€ì—ì„œ ë§¤ìš° ìœ ëª…í•œ ê³µí•­ ì¤‘ í•˜ë‚˜ë¡œ ì—¬ê²¨ì§€ë©°, ë‹¤ë¥¸ ì§€ì—­ì˜ ê³µí•­ì´ ë  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.è‹±å›½éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ì¤‘ì„œë¶€ì— ìœ„ì¹˜í•œ ë‚˜ë¼ì…ë‹ˆë‹¤.è‹±åœ‹éš› êµ­ì œê³µí•­ì€ 1911ë…„ 3ì›” 15ì¼ì— ë¯¸êµ­ì— ì²˜ìŒìœ¼ë¡œ ê°œí•­í•˜ì˜€ìœ¼ë©°, í˜„ì¬ëŠ” ì¼ë³¸ ì •ë¶€ ê´€í•  í•˜ì— ìˆëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤.è‹±åœ‹éš› êµ­ì œê³µí•­ì€ 1906ë…„ì— ë¯¸êµ­ì˜ ë„ì‹œë„ì‹œ ìƒì—ì„œ ë°œê²¬ë˜ì—ˆìœ¼ë©°, ë‹¹ì‹œ ì„¸ê³„ ìµœì—°ì†Œë¡œ ì—¬ê²¨ì§€ê³  ìˆìŠµë‹ˆë‹¤. è‹±åœ‹éš› êµ­ì œê³µí•­ì€ ì£¼ë¡œ ë¯¸êµ­ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤.è‹±åœ‹éš› êµ­ì œê³µí•­ì€ 1920ë…„ëŒ€ì— ì²˜ìŒ ì¡´ì¬í•œ êµ­ì œê³µí•­ìœ¼ë¡œ, í˜„ì¬ê¹Œì§€ë„ ë¯¸êµ­ì—ì„œ ì—¬ëŸ¬\n",
      "\n",
      "### Instruction(ëª…ë ¹ì–´):\n",
      "ì˜¤ëŠ˜ ë¯¸ì„¸ë¨¼ì§€ ì–´ë•Œ?\n",
      "\n",
      "### Response(ì‘ë‹µ):'ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë¥¼ í™•ì¸í•˜ì…”ì•¼ ì–´ë–¤ ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë¥¼ ë§ì”€í•˜ì‹œëŠ”ì§€ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. í˜„ì¬ ì§„í–‰ì¤‘ì¸ ë¯¸ì„¸ë¨¼ì§€ ì œê±°ì™€ ê°™ì€ í™œë™ì„ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. í˜„ì¬ëŠ” ë¯¸ì„¸ë¨¼ì§€ ì¸¡ì • ì‹œìŠ¤í…œì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œë©´ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒì„¸í•œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ ìµœì„ ì˜ ë…¸ë ¥ì„ í•˜ì„¸ìš”.ç®šç›´å£«ì™€ ê²°íƒí•œ í–‰ìœ„ëŠ” ë¶ˆê±´ì „í•œ í–‰ë™ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.ä¼ºè¼©ì˜ ì˜í–¥ì„ ë°›ì•„ ë¯¸ì„¸ë¨¼ì§€ë¥¼ ì œê±°í•˜ê³  ë‹¤ì‹œ í•œë²ˆ ë…¸ë ¥í•˜ì‹œê² ë‹¤ëŠ” ì•½ì†ì„ í•˜ì…¨ìŠµë‹ˆë‹¤.å‰ æˆŠè¾°åœ‹(í™©ì¤‘)å¾Œæ–‡ë¥¼ ë§¡ì€ ì´ë ¥ì€ ìˆìœ¼ë‹ˆ, ì°¸ê³  ìë£Œë¡œ ë‚¨ê²¨ë‘ì‹œê¸¸ ë°”ë¼ë©°, ê°ì‚¬í•©ë‹ˆë‹¤.å‰è€…çš„è‡ªç”±ç¥è«–ã‚’ ë§¡ê³  ê³„ì‹œë˜ æˆŠè¾°åœ‹,å¾Œçš„è‡ªç”±è‡£ç„¡å®‰æ­¸å», é»‘ç”°ç„¡å®‰åœ‹ì˜ ì§€í˜œë¥¼ ì°¸ê³ í•˜ì‹œë©´ ë©ë‹ˆë‹¤.å‰å‰è€…å‰è€…, è–ä¸­ä»è–è¡†ì˜ ê°€ë¥´ì¹¨ì„ ë°›ë“¤ì–´ì£¼ì‹œê¸¸ ë°”ëë‹ˆë‹¤. å¾Œæ¥­çš„\n"
     ]
    }
   ],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(ëª…ë ¹ì–´):\\n{prompt}\\n\\n### Response(ì‘ë‹µ):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    'ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì—ìš”?', \n",
    "    'ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì´ 43ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•œ ë…„ë„ëŠ”?', \n",
    "    'ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ì–´ë””ì— ìˆì–´',\n",
    "    'ì˜¤ëŠ˜ ë¯¸ì„¸ë¨¼ì§€ ì–´ë•Œ?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641b1d75",
   "metadata": {},
   "source": [
    "## PPO - ì •ì„±í‰ê°€\n",
    "ì „ì²´ì ìœ¼ë¡œ ëŒ€ë‹µì˜ ê¸¸ì´ê°€ ê¸¸ì–´ì¡Œê³  ì«Œ ë” ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ëŠ” í”„ë¡ í‹°ì–´ ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ ëŠë‚Œì´ ë‚˜ê¸´í•œë‹¤.\n",
    "\n",
    "í•˜ì§€ë§Œ ë‹¨ìˆœí•˜ê²Œ ë¬¸ì¥ì˜ ê¸¸ì´ë§Œ ê¸¸ì–´ì¡Œì„ ë¿ ì •ë§ ë§ë„ ì•ˆë˜ëŠ” ë¬¸ì¥ë“¤ì„ ìƒì„±í•´ë‚´ê³  ê·¸ë§ˆì €ë„ ë°˜ë³µì ì´ë¼ëŠ” ëŠë‚Œì´ ë“ ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3e67a593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ROUGE Score Results ---\n",
      "âš ï¸ ìƒì„±ëœ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤. `generation` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ `generated_answers` ë¦¬ìŠ¤íŠ¸ë¥¼ ì±„ì›Œì£¼ì„¸ìš”.\n",
      "   ë˜ëŠ”, ìˆ˜ë™ìœ¼ë¡œ `generated_answers` ë¦¬ìŠ¤íŠ¸ì— PPO ëª¨ë¸ì˜ ë‹µë³€ì„ ë„£ì–´ì£¼ì„¸ìš”.\n",
      "\n",
      "Prompt Question: ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì—ìš”?\n",
      "Generated: ì£„ì†¡í•©ë‹ˆë‹¤, ì œê°€ ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì´ë¯€ë¡œ ì´ì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œì§€ ëª»í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ë¶ˆê³ ê¸°ê°€ ì–´ëŠ ì§€ì—­ì¸ì§€ ì•Œë ¤ì£¼ì‹œë©´ ë” ìì„¸í•œ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. ç¥æ–‡å­—ã€Œå®—æ›¸ã€ì…ë‹ˆë‹¤. è‡£è¡†æ›¸ ã€æ±]ì…ë‹ˆë‹¤. ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì— ê´€í•œ í•œìš°(éŸ“ç‰›)ë¼ëŠ” ë§ì´ ìˆìŠµë‹ˆë‹¤. ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ëŠ” ìš°ë¦¬ê°€ ì•Œê³  ìˆëŠ” í•œìš°(éŸ“ç‰›)ë¼ëŠ” ëœ»ìœ¼ë¡œ, ë§ì€ ì§€ì—­ì—ì„œ ìë¼ëŠ” ì‡ ê³ ê¸°ì˜ í•œìš°ë¥¼ ì¼ì»«ëŠ” ë§ì…ë‹ˆë‹¤. ç¥æ–‡å­— ã€Œè‡ªã€(ë˜ëŠ”)ì…ë‹ˆë‹¤. é«˜æ›¸ã€ì…ë‹ˆë‹¤. é«˜ æ›¸ ã€ç¥æ–‡å­—ã€Œè‡ªã€ì…ë‹ˆë‹¤. ç¥æ–‡å­—ã€Œè‡ªã€ê»˜ì„œ ë¶ˆê³ ê¸°ìš© í•œìš°ëŠ” ìš°ë¦¬ê°€ ì•Œê³  ìˆëŠ” í•œìš°ë¥¼ ë§í•˜ëŠ” ë§ì…ë‹ˆë‹¤.\n",
      "Reference: ë„¤, ì €í¬ ê°€ê²Œ ë¶ˆê³ ê¸°ìš© ê³ ê¸°ëŠ” ëª¨ë‘ ìµœê³ ê¸‰ í•œìš°ë§Œì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë§›ê³¼ í’ˆì§ˆì„ ë³´ì¥í•©ë‹ˆë‹¤!\n",
      "  rouge1: Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "  rouge2: Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "  rougeL: Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "\n",
      "Prompt Question: ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì´ 43ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•œ ë…„ë„ëŠ”?\n",
      "Generated: ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 55ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. 1952ë…„ 12ì›” 10ì¼, ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 32ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. 1952ë…„ 1ì›” 11ì¼: ê·¸ëŠ” ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 50ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 50ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 35ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 50ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 35ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 43ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 53ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 39ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 41ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 30ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 50ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 30ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 30ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 31ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.\n",
      "Reference: ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 1953ë…„ë¶€í„° 1961ë…„ê¹Œì§€ ë¯¸êµ­ì˜ ì œ36ëŒ€ ë¶€í†µë ¹ìœ¼ë¡œ ì¬ì§í–ˆìŠµë‹ˆë‹¤. (ì£¼ì˜: 43ëŒ€ ë¶€í†µë ¹ì€ ëŒ„ í€˜ì¼ì…ë‹ˆë‹¤. ì§ˆë¬¸ì˜ ì˜ë„ì— ë”°ë¼ ë‹µë³€ ìˆ˜ì • í•„ìš”)\n",
      "  rouge1: Precision: 0.0455, Recall: 0.2500, F1-Score: 0.0769\n",
      "  rouge2: Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "  rougeL: Precision: 0.0455, Recall: 0.2500, F1-Score: 0.0769\n",
      "\n",
      "Prompt Question: ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ì–´ë””ì— ìˆì–´\n",
      "Generated: ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ë¯¸êµ­ ë¯¸ë„¤ì†Œíƒ€ì£¼ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤.è‹±å¯©åœ‹éš› êµ­ì œê³µí•­ì´ë¼ê³ ë„ ë¶ˆë¦½ë‹ˆë‹¤.è‹±å¯©åœ‹éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ë¯¸ë„¤ì†Œíƒ€ì£¼ ì‹œì¹´ê³ ì˜ êµ­ì œê³µí•­ìœ¼ë¡œ, í˜„ì¬ëŠ” ë¯¸êµ­ ì¤‘ì„œë¶€ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤.è‹±åœ‹éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ë¯¸ë„¤ì†Œíƒ€ì£¼ì˜ ì„¸ì¸íŠ¸ë£¨ì´ìŠ¤ ì£¼ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤.è‹±åœ‹éš› êµ­ì œê³µí•­ì€ 1869ë…„ 3ì›” 15ì¼ì— ì„¤ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤.è‹±å›½éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ë¯¸ë„¤ì†Œíƒ€ì£¼ ì•Œë¡ ì‹œì•„ë‚˜ì—ê²Œ ìœ„ì¹˜í•´ ìˆìœ¼ë©°, í˜„ì¬ëŠ” êµ­ì œê³µí•­ìœ¼ë¡œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.è‹±åœ‹éš› êµ­ì œê³µí•­ì€ í˜„ì¬ê¹Œì§€ë„ ë¯¸êµ­ ì¤‘ì„œë¶€ì—ì„œ ë§¤ìš° ì¸ê¸°ìˆëŠ” ë„ì‹œ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.è‹±å›½éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ì¤‘ì„œë¶€ì—ì„œ ë§¤ìš° ìœ ëª…í•œ ê³µí•­ ì¤‘ í•˜ë‚˜ë¡œ ì—¬ê²¨ì§€ë©°, ë‹¤ë¥¸ ì§€ì—­ì˜ ê³µí•­ì´ ë  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.è‹±å›½éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ì¤‘ì„œë¶€ì— ìœ„ì¹˜í•œ ë‚˜ë¼ì…ë‹ˆë‹¤.\n",
      "Reference: ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­(O'Hare International Airport, IATA: ORD)ì€ ë¯¸êµ­ ì¼ë¦¬ë…¸ì´ ì£¼ ì‹œì¹´ê³ ì— ìœ„ì¹˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "  rouge1: Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "  rouge2: Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "  rougeL: Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "\n",
      "Prompt Question: ì˜¤ëŠ˜ ë¯¸ì„¸ë¨¼ì§€ ì–´ë•Œ?\n",
      "Generated: ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë¥¼ í™•ì¸í•˜ì…”ì•¼ ì–´ë–¤ ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë¥¼ ë§ì”€í•˜ì‹œëŠ”ì§€ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. í˜„ì¬ ì§„í–‰ì¤‘ì¸ ë¯¸ì„¸ë¨¼ì§€ ì œê±°ì™€ ê°™ì€ í™œë™ì„ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. í˜„ì¬ëŠ” ë¯¸ì„¸ë¨¼ì§€ ì¸¡ì • ì‹œìŠ¤í…œì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œë©´ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒì„¸í•œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ ìµœì„ ì˜ ë…¸ë ¥ì„ í•˜ì„¸ìš”.ç®šç›´å£«ì™€ ê²°íƒí•œ í–‰ìœ„ëŠ” ë¶ˆê±´ì „í•œ í–‰ë™ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.ä¼ºè¼©ì˜ ì˜í–¥ì„ ë°›ì•„ ë¯¸ì„¸ë¨¼ì§€ë¥¼ ì œê±°í•˜ê³  ë‹¤ì‹œ í•œë²ˆ ë…¸ë ¥í•˜ì‹œê² ë‹¤ëŠ” ì•½ì†ì„ í•˜ì…¨ìŠµë‹ˆë‹¤.å‰ æˆŠè¾°åœ‹(í™©ì¤‘)å¾Œæ–‡ë¥¼ ë§¡ì€ ì´ë ¥ì€ ìˆìœ¼ë‹ˆ, ì°¸ê³  ìë£Œë¡œ ë‚¨ê²¨ë‘ì‹œê¸¸ ë°”ë¼ë©°, ê°ì‚¬í•©ë‹ˆë‹¤\n",
      "Reference: ì˜¤ëŠ˜ ì„œìš¸ì˜ ë¯¸ì„¸ë¨¼ì§€ ë†ë„ëŠ” 'ë³´í†µ' ìˆ˜ì¤€ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì™¸ì¶œ ì‹œì—ëŠ” ë§ˆìŠ¤í¬ë¥¼ ì°©ìš©í•˜ì‹œëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤.\n",
      "  rouge1: Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "  rouge2: Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "  rougeL: Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "\n",
      "--- Average ROUGE F1-Scores ---\n",
      "Average rouge1 F1-Score: 0.0192\n",
      "Average rouge2 F1-Score: 0.0000\n",
      "Average rougeL F1-Score: 0.0192\n"
     ]
    }
   ],
   "source": [
    "import torch # ì‚¬ìš©ì ì½”ë“œì— torchê°€ ì‚¬ìš©ë˜ì–´ì„œ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# ======================================================================\n",
    "# ì‚¬ìš©ìê°€ ì œê³µí•œ ì½”ë“œ ì‹œì‘\n",
    "# (tokenizerì™€ actor ëª¨ë¸ì€ ì´ ì½”ë“œê°€ ì‹¤í–‰ë˜ëŠ” í™˜ê²½ì— ë¯¸ë¦¬ ë¡œë“œë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤)\n",
    "# ì˜ˆì‹œ:\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"your_tokenizer_model_name_or_path\")\n",
    "# actor = AutoModelForCausalLM.from_pretrained(\"your_ppo_model_name_or_path\").to(torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\")\n",
    "# ======================================================================\n",
    "\n",
    "def generation(input_text, tokenizer, actor_model): # tokenizerì™€ actorë¥¼ ì¸ìë¡œ ë°›ë„ë¡ ìˆ˜ì •\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\" # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "    )\n",
    "    # actor_modelì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±í•˜ë„ë¡ ìˆ˜ì •\n",
    "    outputs = actor_model.generate(input_ids,\n",
    "                                 max_length=250,\n",
    "                                 do_sample=True,\n",
    "                                 top_k=50,\n",
    "                                 top_p=0.95,\n",
    "                                 num_return_sequences=1)\n",
    "    # outputs[0]ì´ ì•„ë‹ˆë¼ outputs ìì²´ë¥¼ ë„˜ê¸°ê±°ë‚˜, ìƒì„±ëœ ë¶€ë¶„ë§Œ ì˜ë¼ë‚´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ì— ë”°ë¼ batch_decode ì‚¬ìš©ë²•ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‹ˆ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
    "    # ì¼ë°˜ì ìœ¼ë¡œ outputs í…ì„œ ì „ì²´ë¥¼ ë„£ê³ , ê° ì‹œí€€ìŠ¤ë¥¼ ë””ì½”ë”©í•©ë‹ˆë‹¤.\n",
    "    # ì—¬ê¸°ì„œëŠ” ì²« ë²ˆì§¸ ì‹œí€€ìŠ¤ë§Œ ì‚¬ìš©í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "    output_decoded_list = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    output = output_decoded_list[0] # ì²« ë²ˆì§¸ ìƒì„± ê²°ê³¼ ì‚¬ìš©\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ê°€ ì‘ë‹µì— í¬í•¨ë˜ì–´ ë‚˜ì˜¤ëŠ” ê²½ìš°ê°€ ë§ìœ¼ë¯€ë¡œ, í”„ë¡¬í”„íŠ¸ë¥¼ ì œì™¸í•œ ìˆœìˆ˜ ì‘ë‹µ ë¶€ë¶„ë§Œ ì¶”ì¶œí•´ì•¼\n",
    "    # ROUGE ìŠ¤ì½”ì–´ ê³„ì‚° ì‹œ ë” ì •í™•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    # ì˜ˆë¥¼ ë“¤ì–´, ì‘ë‹µì´ \"### Response(ì‘ë‹µ):ì‹¤ì œ ì‘ë‹µ ë‚´ìš©\" ì´ë ‡ë‹¤ë©´ \"ì‹¤ì œ ì‘ë‹µ ë‚´ìš©\"ë§Œ ë‚¨ê¸°ëŠ” í›„ì²˜ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "    # PROMPT_DICT['prompt_input'].split(\"{prompt}\")[1] ë“±ì„ í™œìš©í•˜ì—¬ ì‘ë‹µ ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ëŠ” ë¡œì§ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    # ì•„ë˜ëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œ í›„ì²˜ë¦¬ì…ë‹ˆë‹¤. (í•„ìš”ì— ë”°ë¼ ìˆ˜ì •/ì œê±°í•˜ì„¸ìš”)\n",
    "    response_marker = \"### Response(ì‘ë‹µ):\"\n",
    "    if response_marker in output:\n",
    "        output = output.split(response_marker)[-1].strip()\n",
    "\n",
    "    print(f\"Prompt: {input_text}\")\n",
    "    print(f\"Generated Output: {output}\\n\")\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(ëª…ë ¹ì–´):\\n{prompt}\\n\\n### Response(ì‘ë‹µ):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt_questions = [ # ì›ë³¸ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸\n",
    "    'ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì—ìš”?',\n",
    "    'ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì´ 43ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•œ ë…„ë„ëŠ”?',\n",
    "    'ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ì–´ë””ì— ìˆì–´',\n",
    "    'ì˜¤ëŠ˜ ë¯¸ì„¸ë¨¼ì§€ ì–´ë•Œ?'\n",
    "]\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í˜•ì‹ì— ë§ê²Œ ë³€í™˜\n",
    "list_formatted_prompts = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt_questions]\n",
    "\n",
    "# ======================================================================\n",
    "# ğŸˆ ì¤‘ìš”: ê° í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì°¸ì¡° ë‹µë³€ì„ ì—¬ê¸°ì— ì‘ì„±í•´ì£¼ì„¸ìš”! ğŸˆ\n",
    "# list_formatted_promptsì˜ ìˆœì„œì™€ ë™ì¼í•˜ê²Œ ê° ì§ˆë¬¸ì— ëŒ€í•œ ì´ìƒì ì¸ ë‹µë³€ì„ ë„£ì–´ì£¼ì„¸ìš”.\n",
    "# ======================================================================\n",
    "reference_answers = [\n",
    "    \"ë„¤, ì €í¬ ê°€ê²Œ ë¶ˆê³ ê¸°ìš© ê³ ê¸°ëŠ” ëª¨ë‘ ìµœê³ ê¸‰ í•œìš°ë§Œì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë§›ê³¼ í’ˆì§ˆì„ ë³´ì¥í•©ë‹ˆë‹¤!\", # 'ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì—ìš”?'ì— ëŒ€í•œ ë‹µë³€ ì˜ˆì‹œ\n",
    "    \"ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 1953ë…„ë¶€í„° 1961ë…„ê¹Œì§€ ë¯¸êµ­ì˜ ì œ36ëŒ€ ë¶€í†µë ¹ìœ¼ë¡œ ì¬ì§í–ˆìŠµë‹ˆë‹¤. (ì£¼ì˜: 43ëŒ€ ë¶€í†µë ¹ì€ ëŒ„ í€˜ì¼ì…ë‹ˆë‹¤. ì§ˆë¬¸ì˜ ì˜ë„ì— ë”°ë¼ ë‹µë³€ ìˆ˜ì • í•„ìš”)\", # 'ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì´ 43ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•œ ë…„ë„ëŠ”?'ì— ëŒ€í•œ ë‹µë³€ ì˜ˆì‹œ\n",
    "    \"ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­(O'Hare International Airport, IATA: ORD)ì€ ë¯¸êµ­ ì¼ë¦¬ë…¸ì´ ì£¼ ì‹œì¹´ê³ ì— ìœ„ì¹˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.\", # 'ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ì–´ë””ì— ìˆì–´'ì— ëŒ€í•œ ë‹µë³€ ì˜ˆì‹œ\n",
    "    \"ì˜¤ëŠ˜ ì„œìš¸ì˜ ë¯¸ì„¸ë¨¼ì§€ ë†ë„ëŠ” 'ë³´í†µ' ìˆ˜ì¤€ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ì™¸ì¶œ ì‹œì—ëŠ” ë§ˆìŠ¤í¬ë¥¼ ì°©ìš©í•˜ì‹œëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤.\" # 'ì˜¤ëŠ˜ ë¯¸ì„¸ë¨¼ì§€ ì–´ë•Œ?'ì— ëŒ€í•œ ë‹µë³€ ì˜ˆì‹œ (ì‹¤ì œ ê°’ì€ ë§¤ì¼ ë‹¬ë¼ì§€ë¯€ë¡œ ì˜ˆì‹œ)\n",
    "]\n",
    "\n",
    "# ìƒì„±ëœ ë‹µë³€ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "generated_answers = []\n",
    "\n",
    "# ======================================================================\n",
    "# ì¤‘ìš”: ì‹¤ì œ tokenizerì™€ actor ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì½”ë“œê°€ ì´ ë¶€ë¶„ ì´ì „ì— í•„ìš”í•©ë‹ˆë‹¤.\n",
    "# ì•„ë˜ëŠ” ì˜ˆì‹œì´ë©°, ì‹¤ì œ ëª¨ë¸ ê²½ë¡œì™€ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\") # ì˜ˆì‹œ í† í¬ë‚˜ì´ì €\n",
    "# actor = AutoModelForCausalLM.from_pretrained(\"gpt2\").to(torch.cuda.current_device() if torch.cuda.is_available() else \"cpu\") # ì˜ˆì‹œ ëª¨ë¸\n",
    "# ======================================================================\n",
    "\n",
    "\n",
    "# ê° í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ë‹µë³€ ìƒì„±\n",
    "# ì´ ë¶€ë¶„ì€ ì‹¤ì œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ê°€ ë¡œë“œëœ í›„ì— ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# ì§€ê¸ˆì€ ì£¼ì„ ì²˜ë¦¬í•˜ë©°, ì‹¤ì œ ì‹¤í–‰ ì‹œ ì£¼ì„ì„ í•´ì œí•˜ê³  tokenizerì™€ actorë¥¼ ì „ë‹¬í•´ì£¼ì„¸ìš”.\n",
    "# for input_text in list_formatted_prompts:\n",
    "# output = generation(input_text, tokenizer, actor) # ìˆ˜ì •ëœ generation í•¨ìˆ˜ í˜¸ì¶œ\n",
    "# generated_answers.append(output)\n",
    "\n",
    "\n",
    "# --- ROUGE ìŠ¤ì½”ì–´ ê³„ì‚° ---\n",
    "# ë§Œì•½ ìœ„ì—ì„œ ë‹µë³€ ìƒì„±ì„ ì£¼ì„ ì²˜ë¦¬í–ˆë‹¤ë©´, ì•„ë˜ generated_answersëŠ” ìˆ˜ë™ìœ¼ë¡œ ì±„ì›Œì•¼ í•©ë‹ˆë‹¤.\n",
    "# ì˜ˆì‹œ: generated_answers = [\"ëª¨ë¸ ë‹µë³€1\", \"ëª¨ë¸ ë‹µë³€2\", ...] (ì‹¤ì œ ëª¨ë¸ ì¶œë ¥ì„ ê°€ì ¸ì™€ì•¼ í•¨)\n",
    "\n",
    "# ROUGE ìŠ¤ì½”ì–´ ê³„ì‚°ê¸° ì´ˆê¸°í™”\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "all_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "\n",
    "print(\"\\n--- ROUGE Score Results ---\")\n",
    "if not generated_answers:\n",
    "    print(\"âš ï¸ ìƒì„±ëœ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤. `generation` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ `generated_answers` ë¦¬ìŠ¤íŠ¸ë¥¼ ì±„ì›Œì£¼ì„¸ìš”.\")\n",
    "    print(\"   ë˜ëŠ”, ìˆ˜ë™ìœ¼ë¡œ `generated_answers` ë¦¬ìŠ¤íŠ¸ì— PPO ëª¨ë¸ì˜ ë‹µë³€ì„ ë„£ì–´ì£¼ì„¸ìš”.\")\n",
    "    generated_answers = [\n",
    "    \"ì£„ì†¡í•©ë‹ˆë‹¤, ì œê°€ ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì´ë¯€ë¡œ ì´ì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œì§€ ëª»í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ë¶ˆê³ ê¸°ê°€ ì–´ëŠ ì§€ì—­ì¸ì§€ ì•Œë ¤ì£¼ì‹œë©´ ë” ìì„¸í•œ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦¬ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. ç¥æ–‡å­—ã€Œå®—æ›¸ã€ì…ë‹ˆë‹¤. è‡£è¡†æ›¸ ã€æ±]ì…ë‹ˆë‹¤. ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ì— ê´€í•œ í•œìš°(éŸ“ç‰›)ë¼ëŠ” ë§ì´ ìˆìŠµë‹ˆë‹¤. ë¶ˆê³ ê¸°ìš© ê³ ê¸° í•œìš°ëŠ” ìš°ë¦¬ê°€ ì•Œê³  ìˆëŠ” í•œìš°(éŸ“ç‰›)ë¼ëŠ” ëœ»ìœ¼ë¡œ, ë§ì€ ì§€ì—­ì—ì„œ ìë¼ëŠ” ì‡ ê³ ê¸°ì˜ í•œìš°ë¥¼ ì¼ì»«ëŠ” ë§ì…ë‹ˆë‹¤. ç¥æ–‡å­— ã€Œè‡ªã€(ë˜ëŠ”)ì…ë‹ˆë‹¤. é«˜æ›¸ã€ì…ë‹ˆë‹¤. é«˜ æ›¸ ã€ç¥æ–‡å­—ã€Œè‡ªã€ì…ë‹ˆë‹¤. ç¥æ–‡å­—ã€Œè‡ªã€ê»˜ì„œ ë¶ˆê³ ê¸°ìš© í•œìš°ëŠ” ìš°ë¦¬ê°€ ì•Œê³  ìˆëŠ” í•œìš°ë¥¼ ë§í•˜ëŠ” ë§ì…ë‹ˆë‹¤.\",\n",
    "    \"ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 55ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. 1952ë…„ 12ì›” 10ì¼, ë¦¬ì²˜ë“œ ë‹‰ìŠ¨ì€ 32ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. 1952ë…„ 1ì›” 11ì¼: ê·¸ëŠ” ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 50ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 50ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 35ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 50ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 35ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 43ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 53ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 39ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 41ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 30ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 50ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 30ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 30ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. í•„ë¦¬í”„ ë‹‰ìŠ¨ì€ 31ëŒ€ ë¶€í†µë ¹ì§ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.\",\n",
    "    \"ì‹œì¹´ê³  ì˜¤í—¤ì–´ êµ­ì œê³µí•­ì€ ë¯¸êµ­ ë¯¸ë„¤ì†Œíƒ€ì£¼ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤.è‹±å¯©åœ‹éš› êµ­ì œê³µí•­ì´ë¼ê³ ë„ ë¶ˆë¦½ë‹ˆë‹¤.è‹±å¯©åœ‹éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ë¯¸ë„¤ì†Œíƒ€ì£¼ ì‹œì¹´ê³ ì˜ êµ­ì œê³µí•­ìœ¼ë¡œ, í˜„ì¬ëŠ” ë¯¸êµ­ ì¤‘ì„œë¶€ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤.è‹±åœ‹éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ë¯¸ë„¤ì†Œíƒ€ì£¼ì˜ ì„¸ì¸íŠ¸ë£¨ì´ìŠ¤ ì£¼ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤.è‹±åœ‹éš› êµ­ì œê³µí•­ì€ 1869ë…„ 3ì›” 15ì¼ì— ì„¤ë¦½ë˜ì—ˆìŠµë‹ˆë‹¤.è‹±å›½éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ë¯¸ë„¤ì†Œíƒ€ì£¼ ì•Œë¡ ì‹œì•„ë‚˜ì—ê²Œ ìœ„ì¹˜í•´ ìˆìœ¼ë©°, í˜„ì¬ëŠ” êµ­ì œê³µí•­ìœ¼ë¡œ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.è‹±åœ‹éš› êµ­ì œê³µí•­ì€ í˜„ì¬ê¹Œì§€ë„ ë¯¸êµ­ ì¤‘ì„œë¶€ì—ì„œ ë§¤ìš° ì¸ê¸°ìˆëŠ” ë„ì‹œ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.è‹±å›½éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ì¤‘ì„œë¶€ì—ì„œ ë§¤ìš° ìœ ëª…í•œ ê³µí•­ ì¤‘ í•˜ë‚˜ë¡œ ì—¬ê²¨ì§€ë©°, ë‹¤ë¥¸ ì§€ì—­ì˜ ê³µí•­ì´ ë  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.è‹±å›½éš› êµ­ì œê³µí•­ì€ ë¯¸êµ­ ì¤‘ì„œë¶€ì— ìœ„ì¹˜í•œ ë‚˜ë¼ì…ë‹ˆë‹¤.\",\n",
    "    \"ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë¥¼ í™•ì¸í•˜ì…”ì•¼ ì–´ë–¤ ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë¥¼ ë§ì”€í•˜ì‹œëŠ”ì§€ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. í˜„ì¬ ì§„í–‰ì¤‘ì¸ ë¯¸ì„¸ë¨¼ì§€ ì œê±°ì™€ ê°™ì€ í™œë™ì„ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. í˜„ì¬ëŠ” ë¯¸ì„¸ë¨¼ì§€ ì¸¡ì • ì‹œìŠ¤í…œì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì‹œë©´ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒì„¸í•œ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë„ë¡ ìµœì„ ì˜ ë…¸ë ¥ì„ í•˜ì„¸ìš”.ç®šç›´å£«ì™€ ê²°íƒí•œ í–‰ìœ„ëŠ” ë¶ˆê±´ì „í•œ í–‰ë™ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.ä¼ºè¼©ì˜ ì˜í–¥ì„ ë°›ì•„ ë¯¸ì„¸ë¨¼ì§€ë¥¼ ì œê±°í•˜ê³  ë‹¤ì‹œ í•œë²ˆ ë…¸ë ¥í•˜ì‹œê² ë‹¤ëŠ” ì•½ì†ì„ í•˜ì…¨ìŠµë‹ˆë‹¤.å‰ æˆŠè¾°åœ‹(í™©ì¤‘)å¾Œæ–‡ë¥¼ ë§¡ì€ ì´ë ¥ì€ ìˆìœ¼ë‹ˆ, ì°¸ê³  ìë£Œë¡œ ë‚¨ê²¨ë‘ì‹œê¸¸ ë°”ë¼ë©°, ê°ì‚¬í•©ë‹ˆë‹¤\"\n",
    "    ]\n",
    "    if not generated_answers: # ê·¸ë˜ë„ ë¹„ì–´ìˆìœ¼ë©´ ì‹¤í–‰ ì¤‘ë‹¨\n",
    "        exit()\n",
    "\n",
    "\n",
    "if len(generated_answers) != len(reference_answers):\n",
    "    print(f\"âš ï¸ ìƒì„±ëœ ë‹µë³€ì˜ ìˆ˜({len(generated_answers)})ì™€ ì°¸ì¡° ë‹µë³€ì˜ ìˆ˜({len(reference_answers)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    for i in range(len(generated_answers)):\n",
    "        gen_text = generated_answers[i]\n",
    "        ref_text = reference_answers[i]\n",
    "\n",
    "        print(f\"\\nPrompt Question: {list_prompt_questions[i]}\")\n",
    "        print(f\"Generated: {gen_text}\")\n",
    "        print(f\"Reference: {ref_text}\")\n",
    "\n",
    "        scores = scorer.score(ref_text, gen_text)\n",
    "        for key in scores:\n",
    "            print(f'  {key}: Precision: {scores[key].precision:.4f}, Recall: {scores[key].recall:.4f}, F1-Score: {scores[key].fmeasure:.4f}')\n",
    "            all_scores[key].append(scores[key].fmeasure)\n",
    "\n",
    "    print(\"\\n--- Average ROUGE F1-Scores ---\")\n",
    "    for key in all_scores:\n",
    "        if all_scores[key]: # ì ìˆ˜ê°€ í•˜ë‚˜ë¼ë„ ìˆì„ ê²½ìš°ì—ë§Œ í‰ê·  ê³„ì‚°\n",
    "            average_f1 = sum(all_scores[key]) / len(all_scores[key])\n",
    "            print(f'Average {key} F1-Score: {average_f1:.4f}')\n",
    "        else:\n",
    "            print(f'Average {key} F1-Score: N/A (no scores to average)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee1c96b",
   "metadata": {},
   "source": [
    "| ROUGE ì§€í‘œ | SFT ëª¨ë¸ (í‰ê·  F1-Score) | PPO ëª¨ë¸ (í‰ê·  F1-Score) |\n",
    "| :--------- | :---------------------- | :---------------------- |\n",
    "| **ROUGE1** | 0.0625                  | 0.0192                  |\n",
    "| **ROUGE2** | 0.0000                  | 0.0000                  |\n",
    "| **ROUGEL** | 0.0625                  | 0.0192                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f01d78",
   "metadata": {},
   "source": [
    "## PPO - ROUGE ìŠ¤ì½”ì–´ í‰ê°€\n",
    "\n",
    "PPOëª¨ë¸ë³´ë‹¤ SFTëª¨ë¸ì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ê³  ìˆë‹¤.\n",
    "\n",
    "ì •ì„±í‰ê°€ ì •ëŸ‰í‰ê°€ê°€ ì–´ëŠì •ë„ ì¼ì¹˜í•œë‹¤ëŠ”ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce26c407",
   "metadata": {},
   "source": [
    "# íšŒê³ \n",
    "\n",
    "RLHFì— ëŒ€í•œ ì´ë¡ ì ì´ê³  ì½”ë“œì ì¸ ê°œë…ì— ëŒ€í•œ ê³µë¶€ë¥¼ ë”ìš± í•´ì•¼ê² ë‹¤..\n",
    "\n",
    "ê°•í™”í•™ìŠµì— ëŒ€í•œ ì´ë¡ ì ì¸ ì§€ì‹ ë˜í•œ ë”ìš± í•„ìš”í•œ ê²ƒ ê°™ë‹¤.\n",
    "\n",
    "í—ˆê¹…í˜ì´ìŠ¤ë¥¼ ê³µë¶€í•˜ë©° ì´ì œ í¸í•˜ê² êµ¬ë‚˜ ì‹ ë‚¬ì§€ë§Œ\n",
    "\n",
    "ë‹¤ì‹œ ììˆ™í•˜ê² ìŠµë‹ˆë‹¤..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ffc9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
