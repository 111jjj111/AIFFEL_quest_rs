{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7e3e355b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n",
      "1.3.3\n",
      "3.4.3\n",
      "2.0.9\n",
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib\n",
    "import json\n",
    "import re\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(numpy.__version__)\n",
    "print(pandas.__version__)\n",
    "print(matplotlib.__version__)\n",
    "print(json.__version__)\n",
    "print(re.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e122baa",
   "metadata": {},
   "source": [
    "### vocab_size = 8000의 spm tokenizer 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "098e4cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아', '▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내', '▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "string_a = \"추적추적 비가 내리는 날이었어 그날은 왠지 손님이 많아 첫 번에 삼십 전 둘째번 오십 전 오랜만에 받아보는 십 전짜리 백통화 서푼에\"\n",
    "string_b = \"손바닥 위엔 기쁨의 눈물이 흘러 컬컬한 목에 모주 한잔을 적셔 몇 달 포 전부터 콜록거리는 아내 생각에 그토록 먹고 싶다던\"\n",
    "tokens_org = [\"[CLS]\"] + vocab.encode_as_pieces(string_a) + [\"[SEP]\"] + vocab.encode_as_pieces(string_b) + [\"[SEP]\"]\n",
    "print(tokens_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edabeeba",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리 (1) MASK 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a99921b",
   "metadata": {},
   "source": [
    "MLMtask 수행을 위한 마스크 생성 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "63bb5cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
    "    \"\"\"\n",
    "    마스크 생성\n",
    "    :param tokens: tokens\n",
    "    :param mask_cnt: mask 개수 (전체 tokens의 15%)\n",
    "    :param vocab_list: vocab list (random token 용)\n",
    "    :return tokens: mask된 tokens\n",
    "    :return mask_idx: mask된 token의 index\n",
    "    :return mask_label: mask된 token의 원래 값\n",
    "    \"\"\"    \n",
    "    cand_index = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        if 0 < len(cand_index) and not token.startswith(u\"\\u2581\"):\n",
    "            cand_index[-1].append(i)\n",
    "        else:\n",
    "            cand_index.append([i])\n",
    "            \n",
    "    random.shuffle(cand_index)\n",
    "        \n",
    "    mask_lms = []\n",
    "        \n",
    "    for i in cand_index:\n",
    "        if len(mask_lms) >= mask_cnt:\n",
    "            break\n",
    "        if len(mask_lms) + len(i) > mask_cnt:\n",
    "            continue\n",
    "            \n",
    "        dice = random.random()\n",
    "            \n",
    "        for index in i:\n",
    "            maked_token = None\n",
    "            if dice < 0.8:\n",
    "                masked_token = \"[MASK]\"\n",
    "            elif dice < 0.9: \n",
    "                masked_token = tokens[index]\n",
    "            else:  \n",
    "                masked_token = random.choice(vocab_list)\n",
    "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "            tokens[index] = masked_token\n",
    "                \n",
    "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "    mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "    mask_label = [p[\"label\"] for p in mask_lms]\n",
    "            \n",
    "    return tokens, mask_idx, mask_label\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec22579",
   "metadata": {},
   "source": [
    "들여쓰기 실수로 mask위치가 고정되어 있는 오류를 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "23aa20b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아', '▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내', '▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던', '[SEP]']\n",
      "tokens_org\n",
      "['[CLS]', '▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '▁그날', '은', '▁', '왠', '지', '▁손', '님이', '▁많아', '▁첫', '▁번에', '▁삼', '십', '▁전', '▁둘째', '번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '▁전', '짜리', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전부터', '▁콜', '록', '거리는', '▁아내', '▁생각에', '▁그', '토록', '▁먹고', '▁싶다', '던', '[SEP]'] \n",
      "\n",
      "tokens\n",
      "['[CLS]', '▁추적', '추', '적', '▁비가', '▁내리는', '▁날', '이었', '어', '[MASK]', '[MASK]', '▁', '왠', '지', '▁손', '님이', '▁많아', '▁첫', '[MASK]', '▁삼', '십', '▁전', '▁둘째', '번', '▁오', '십', '▁전', '▁오랜', '만에', '▁받아', '보는', '▁십', '[MASK]', '[MASK]', '▁백', '통', '화', '▁서', '푼', '에', '[SEP]', '▁손바닥', '▁위', '엔', '▁기쁨', '의', '▁눈', '물이', '▁흘러', '▁컬', '컬', '한', '▁목에', '▁모', '주', '▁한', '잔', '을', '▁적', '셔', '▁몇', '▁달', '▁포', '▁전부터', '[MASK]', '[MASK]', '[MASK]', '▁아내', '▁생각에', '[MASK]', '[MASK]', '▁먹고', '▁싶다', '던', '[SEP]'] \n",
      "\n",
      "mask_idx   : [9, 10, 18, 32, 33, 64, 65, 66, 69, 70]\n",
      "mask_label : ['▁그날', '은', '▁번에', '▁전', '짜리', '▁콜', '록', '거리는', '▁그', '토록']\n"
     ]
    }
   ],
   "source": [
    "# tokens가 mask되므로 재 실행을 위해서 넣어줌 (테스트용)\n",
    "import copy\n",
    "print(tokens_org)\n",
    "\n",
    "# 전체 token의 15% mask\n",
    "mask_cnt = int((len(tokens_org) - 3) * 0.15)\n",
    "mask_cnt\n",
    "tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "tokens, mask_idx, mask_label = create_pretrain_mask(tokens, mask_cnt, vocab_list)\n",
    "\n",
    "print(\"tokens_org\")\n",
    "print(tokens_org, \"\\n\")\n",
    "print(\"tokens\")\n",
    "print(tokens, \"\\n\")\n",
    "\n",
    "print(\"mask_idx   :\", mask_idx)\n",
    "print(\"mask_label :\", mask_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d38a5c",
   "metadata": {},
   "source": [
    "### 문장에서 _추적을 정확히 마스킹하고 몇번째 인덱스가 마스킹되었는지 잘 가르킴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec8922",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리 (2) NSP pair 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b080fd",
   "metadata": {},
   "source": [
    "문장의 길이가 max를 넘어갈 때 잘라주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ed9b2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
    "    \"\"\"\n",
    "    tokens_a, tokens_b의 길이를 줄임 최대 길이: max_seq\n",
    "    :param tokens_a: tokens A\n",
    "    :param tokens_b: tokens B\n",
    "    :param max_seq: 두 tokens 길이의 최대 값\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_seq:\n",
    "            break\n",
    "\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            del tokens_a[0]\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca0925",
   "metadata": {},
   "source": [
    "NSP 수행을 위한 pair 생성함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a760b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
    "    \"\"\"\n",
    "    doc별 pretrain 데이터 생성\n",
    "    :param vocab: 어휘 사전 (여기서는 사용되지 않음. `vocab_list`가 사용됨)\n",
    "    :param doc: 입력 문서 (문장들의 리스트)\n",
    "    :param n_seq: 최대 시퀀스 길이 (BERT 모델 입력 시퀀스의 최대 길이)\n",
    "    :param mask_prob: 마스킹할 토큰의 비율 (MLM을 위해 사용)\n",
    "    :param vocab_list: 마스킹 시 랜덤 토큰을 선택하기 위한 어휘 리스트\n",
    "    :return instances: 생성된 pretrain 인스턴스들의 리스트\n",
    "    \"\"\"\n",
    "    \n",
    "    max_seq = n_seq - 3\n",
    "    \n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i])\n",
    "        current_length += len(doc[i])\n",
    "        if 1 < len(current_chunk) and (1 == len(doc) - 1 or current_length >= max_seq):\n",
    "            a_end = 1\n",
    "            if 1 < len(current_chunk):\n",
    "                a_end = random.randrange(1,len(current_chunk))\n",
    "            tokens_a = []                      \n",
    "            for j in range(a_end):\n",
    "                tokens_a.extend(current_chunk[j])\n",
    "            tokens_b = []\n",
    "            for j in range(a_end,len(current_chunk)):\n",
    "                tokens_b.extend(current_chunk[j])\n",
    "            if random.random() < 0.5:  # 50% 확률로 swap\n",
    "                is_next = 0     #False (NotNextSentence)\n",
    "                tokens_t = tokens_a\n",
    "                tokens_a = tokens_b\n",
    "                tokens_b = tokens_t\n",
    "            else:\n",
    "                is_next = 1    #True (IsNextSentence)\n",
    "                # max_seq 보다 큰 경우 길이 조절\n",
    "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "            assert 0 < len(tokens_a)\n",
    "            assert 0 < len(tokens_b)\n",
    "\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * 0.15), vocab_list)\n",
    "\n",
    "            instance = {\n",
    "                \"tokens\": tokens,\n",
    "                \"segment\": segment,\n",
    "                \"is_next\": is_next,\n",
    "                \"mask_idx\": mask_idx,\n",
    "                \"mask_label\": mask_label\n",
    "            }\n",
    "            instances.append(instance)\n",
    "\n",
    "            # 다음 인스턴스 생성을 위해 current_chunk 초기화\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef3a28",
   "metadata": {},
   "source": [
    "## 4. 데이터 전처리 (3) 데이터셋 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ee454293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aec9e8",
   "metadata": {},
   "source": [
    "데이터 토큰화 및 마스크,페어 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f5bbea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
    "    \"\"\" pretrain 데이터 생성 \"\"\"\n",
    "    def save_pretrain_instances(out_f, doc):\n",
    "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
    "        for instance in instances:\n",
    "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
    "            out_f.write(\"\\n\")\n",
    "\n",
    "    vocab_list = []\n",
    "    for id in range(7, len(vocab)):\n",
    "        if not vocab.is_unknown(id):        # 생성되는 단어 목록이 unknown인 경우는 제거합니다. \n",
    "            vocab_list.append(vocab.id_to_piece(id))\n",
    "\n",
    "    # line count 확인\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        with open(out_file, \"w\") as out_f:\n",
    "            doc = []\n",
    "            for line in tqdm(in_f, total=line_cnt):\n",
    "                line = line.strip()\n",
    "                if line == \"\":  # line이 빈줄 일 경우 (새로운 단락)\n",
    "                    if 0 < len(doc):\n",
    "                        save_pretrain_instances(out_f, doc)\n",
    "                        doc = []\n",
    "                else:  # line이 빈줄이 아닐 경우 tokenize 해서 doc에 저장\n",
    "                    pieces = vocab.encode_as_pieces(line)\n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "            if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "                save_pretrain_instances(out_f, doc)\n",
    "                doc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9979e00e",
   "metadata": {},
   "source": [
    "라인 수 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "78fa492b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746274"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라인수\n",
    "total = 0\n",
    "with open(pretrain_json_path, \"r\") as f:\n",
    "    for line in f:  \n",
    "        total += 1\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "78a53fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 0,\n",
       " 0,\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n_seq = 128\n",
    "# [CLS], tokens_a, [SEP], tokens_b, [SEP]\n",
    "max_seq = n_seq - 3\n",
    "\n",
    "# 만약 일반적인 Numpy Array에다 데이터를 로딩한다면 이렇게 되겠지만\n",
    "# enc_tokens = np.zeros((total, n_seq), np.int32)\n",
    "# dec_tokens = np.zeros((total, n_seq), np.int32)\n",
    "# labels_nsp = np.zeros((total,), np.int32)\n",
    "# labels_mlm = np.zeros((total, n_seq), np.int32)\n",
    "\n",
    "# np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "\n",
    "enc_tokens[0], enc_tokens[-1], segments[0], segments[-1], labels_nsp[0], labels_nsp[-1], labels_mlm[0], labels_mlm[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181bfe2",
   "metadata": {},
   "source": [
    "학습에 필요한 데이터를 로딩하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7e5711ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
    "    \"\"\"\n",
    "    학습에 필요한 데이터를 로드\n",
    "    :param vocab: vocab\n",
    "    :param filename: 전처리된 json 파일\n",
    "    :param n_seq: 시퀀스 길이 (number of sequence)\n",
    "    :param count: 데이터 수 제한 (None이면 전체)\n",
    "    :return enc_tokens: encoder inputs\n",
    "    :return segments: segment inputs\n",
    "    :return labels_nsp: nsp labels\n",
    "    :return labels_mlm: mlm labels\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            # 데이터 수 제한\n",
    "            if count is not None and count <= total:\n",
    "                break\n",
    "    \n",
    "    # np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "    enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "    labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, total=total)):\n",
    "            if total <= i:\n",
    "                print(\"data load early stop\", total, i)\n",
    "                break\n",
    "            data = json.loads(line)\n",
    "            # encoder token\n",
    "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "            enc_token += [0] * (n_seq - len(enc_token))\n",
    "            # segment\n",
    "            segment = data[\"segment\"]\n",
    "            segment += [0] * (n_seq - len(segment))\n",
    "            # nsp label\n",
    "            label_nsp = data[\"is_next\"]\n",
    "            # mlm label\n",
    "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "            label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "            label_mlm[mask_idx] = mask_label\n",
    "\n",
    "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "            enc_tokens[i] = enc_token\n",
    "            segments[i] = segment\n",
    "            labels_nsp[i] = label_nsp\n",
    "            labels_mlm[i] = label_mlm\n",
    "\n",
    "    return (enc_tokens, segments), (labels_nsp, labels_mlm)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f50787b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([    5, 16415, 25250,  3324,  1042,   103, 27610, 27686, 27718,\n",
       "         25250,     6,     6,     6,     6,   131, 27662,     7, 27629,\n",
       "           203,   241, 27602,  4867,   788,   243,  5898,   796,   663,\n",
       "          1647,  4630, 27625,   203,  3008, 27625, 27616,    16, 27599,\n",
       "             4, 16415,   207,  4612,  5551, 27646,   630, 27714,  4269,\n",
       "           429,  5346, 27626, 14406,  1605, 27599,  5551, 14146, 15991,\n",
       "          8637, 27599,    13,    81,     6,  2247, 15033, 27873, 14475,\n",
       "         27813, 27873, 28196, 27636, 10185, 16285,  1232,     6,     6,\n",
       "          4777, 27625,   243,  2780,    14,  1509, 22095,   414,   165,\n",
       "          1697, 28290, 27873, 27703, 27683,   593,     6,     6,     6,\n",
       "          5540,   813,    17, 27599,     6, 16905,   103, 28313, 28290,\n",
       "         19041, 27718,    98, 27878, 15784,  2543,   309,   337,  5771,\n",
       "         27616, 27603,  4578, 27599,  3715, 27625,  5551,    37, 11234,\n",
       "          2378,  5249,     6,     6,    13, 20590,  2386,  2163,     6,\n",
       "             6,     4], dtype=int32),\n",
       " memmap([    5,  2073,   608,     6,  7772, 27751, 12905,   161,  1870,\n",
       "         27722,  2312, 27683,    82,  1346,  9356,  3452,    43, 27599,\n",
       "          2394,  3275,   155,  7297,     6,     6,  4968,  2575,     6,\n",
       "             6, 15293,  7715, 27640,   316,   860, 27676, 27711,  3391,\n",
       "         25983,  1488, 27944,  6200,  9185, 27599,   316,     6,  7772,\n",
       "         27751,   471,   778,   127,   126,  1157,  3039, 27604,   142,\n",
       "         10852, 27602,   506,  3942,  2349,  3896,  2841,  2797, 17110,\n",
       "         27599,     4,     6,     6,     6,   325,     6,     6,  5623,\n",
       "            12, 27750, 28189,  2283,  4687,     6,   119, 28189,  4081,\n",
       "          5504,   465, 27604,   881, 27621,  1820, 15293,  2211,  2394,\n",
       "          3456,  2394,  3275,  4088,   465, 27604, 18021, 15293, 15983,\n",
       "          1013, 23149, 27599,    12, 27750, 28189,  8731,     6,   119,\n",
       "         28189,  3619, 25418,  7817,   314,   886,   832, 27599,     6,\n",
       "           851,   851,   715,   159,   103, 27682, 10852,  1744, 28039,\n",
       "          1423,     4], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 1,\n",
       " 0,\n",
       " memmap([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,  7504,   416,  5708, 27625,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           429,  5346, 27626,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0, 25987,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0, 22935, 27599,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,    21, 29007,   399,\n",
       "             0,     0,     0,     0,   307,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,  9858,  3294,     0,     0,     0,     0, 27596,\n",
       "         27671,     0], dtype=int32),\n",
       " memmap([    0,     0,     0,     8,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     7,   729,     0,     0,  3391,\n",
       "           161,     0,     0,     0,     0,   860, 27676, 27711,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,  2091,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,    30, 27619, 27751,     0, 13285, 21942,     0,\n",
       "             0,     0,     0,     0,     0,  3754,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,  2977,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,  3754,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,  1677,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0], dtype=int32))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_train_inputs[0][0], pre_train_inputs[0][-1], pre_train_inputs[1][0], pre_train_inputs[1][-1], pre_train_labels[0][0], pre_train_labels[0][-1], pre_train_labels[1][0], pre_train_labels[1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ae15c",
   "metadata": {},
   "source": [
    "## 5. BERT 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4248e5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e3e2e",
   "metadata": {},
   "source": [
    "트랜스포머의 마스킹 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e89b204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    pad mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: pad mask (pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    ahead mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c92a4bc",
   "metadata": {},
   "source": [
    "활성화 함수 gelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "030fffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    gelu activation 함수\n",
    "    :param x: 입력 값\n",
    "    :return: gelu activation result\n",
    "    \"\"\"\n",
    "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
    "\n",
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    parameter initializer 생성\n",
    "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
    "    \"\"\"\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    bias initializer 생성\n",
    "    \"\"\"\n",
    "    return tf.zeros_initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35977ce",
   "metadata": {},
   "source": [
    "json 데이터 설정을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1ece63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        file에서 Config를 생성 함\n",
    "        :param file: filename\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092bb50b",
   "metadata": {},
   "source": [
    "트랜스포머의 임베딩 레이어 해당 레이어는 다른 모듈과 공유됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c482b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Weighed Shaed Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        shared weight 생성\n",
    "        :param input_shape: Tensor Shape (not used)\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :param mode: 실행 모드\n",
    "        :return: embedding or linear 실행 결과\n",
    "        \"\"\"\n",
    "        # mode가 embedding일 경우 embedding lookup 실행\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # mode가 linear일 경우 linear 실행\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # mode가 기타일 경우 오류 발생\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        embedding lookup\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        \"\"\"\n",
    "        linear 실행\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2333459b",
   "metadata": {},
   "source": [
    "포지션 임베딩 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "698fa3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :return embed: position embedding lookup 결과\n",
    "        \"\"\"\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef365ba",
   "metadata": {},
   "source": [
    "Attention 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3e0fb0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Scale Dot Product Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "043c94f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi Head Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
    "        # transpose and liner\n",
    "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
    "\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7e0a21",
   "metadata": {},
   "source": [
    "FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ee8baee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Wise Feed Forward Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: inputs\n",
    "        :return ff_val: feed forward 실행 결과\n",
    "        \"\"\"\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa55bc",
   "metadata": {},
   "source": [
    "인코더 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "90803209",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
    "        :param self_mask: enc_tokens의 pad mask\n",
    "        :return enc_out: EncoderLayer 실행 결과\n",
    "        \"\"\"\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d5b0c",
   "metadata": {},
   "source": [
    "BERT 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a296ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    BERT Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: (enc_tokens, segments)\n",
    "        :return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n",
    "        \"\"\"\n",
    "        enc_tokens, segments = inputs\n",
    "\n",
    "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        token embedding, position embedding lookup\n",
    "        :param tokens: 입력 tokens\n",
    "        :param segments: 입력 segments\n",
    "        :return embed: embedding 결과\n",
    "        \"\"\"\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2025e5c5",
   "metadata": {},
   "source": [
    "NSP task 수행을 위한 헤드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b3b05b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PooledOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    " \n",
    "    def call(self, inputs):\n",
    "        outputs = self.dense1(inputs)\n",
    "        outputs = self.dense2(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129bc4ba",
   "metadata": {},
   "source": [
    "MLM,NSP 수행 종합빌드 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "03ee8cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_pre_train(config):\n",
    "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
    "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
    "\n",
    "    bert = BERT(config)\n",
    "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
    "\n",
    "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
    "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
    "\n",
    "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
    "\n",
    "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a262c0b",
   "metadata": {},
   "source": [
    "## 6. pretrain 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "037d5ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_model': 256,\n",
       " 'n_head': 4,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 3,\n",
       " 'n_seq': 256,\n",
       " 'n_vocab': 32007,\n",
       " 'i_pad': 0}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7762749",
   "metadata": {},
   "source": [
    "로스 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b14b8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    loss 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # loss 계산\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return loss * 20  # mlm을 더 잘 학습하도록 20배 증가 시킴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7de0a",
   "metadata": {},
   "source": [
    "정확도 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bd5a44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def lm_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    acc 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # 정답 여부 확인\n",
    "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
    "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
    "    matches *= mask\n",
    "    # 정확도 계산\n",
    "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e33b30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    CosineSchedule Class\n",
    "    \"\"\"\n",
    "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param train_steps: 학습 step 총 합\n",
    "        :param warmup_steps: warmup steps\n",
    "        :param max_lr: 최대 learning rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert 0 < warmup_steps < train_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.train_steps = train_steps\n",
    "        self.max_lr = max_lr\n",
    "\n",
    "    def __call__(self, step_num):\n",
    "        \"\"\"\n",
    "        learning rate 계산\n",
    "        :param step_num: 현재 step number\n",
    "        :retrun: 계산된 learning rate\n",
    "        \"\"\"\n",
    "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
    "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
    "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
    "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
    "        return (state * lr1 + (1 - state) * lr2) * self.max_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "938f5403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
    "lrs = []\n",
    "for step_num in range(4000):\n",
    "    lrs.append(test_schedule(float(step_num)).numpy())\n",
    "\n",
    "# draw\n",
    "plt.plot(lrs, 'r-', label='learning_rate')\n",
    "plt.xlabel('Step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ed9c25f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "31ca5ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_tokens (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segments (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BERT)                     ((None, 256), (None, 10629632    enc_tokens[0][0]                 \n",
      "                                                                 segments[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooled_nsp (PooledOutput)       (None, 2)            66304       bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "nsp (Softmax)                   (None, 2)            0           pooled_nsp[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlm (Softmax)                   (None, None, 32007)  0           bert[0][1]                       \n",
      "==================================================================================================\n",
      "Total params: 10,695,936\n",
      "Trainable params: 10,695,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_train_model = build_model_pre_train(config)\n",
    "pre_train_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1002d2",
   "metadata": {},
   "source": [
    "### 모델 컴파일 및 학습 (에폭 10, 배치사이즈 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0bda05cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps: 20000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# optimizer\n",
    "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
    "print(\"train_steps:\", train_steps)\n",
    "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# compile\n",
    "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ad419536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 568s 282ms/step - loss: 23.2352 - nsp_loss: 0.6431 - mlm_loss: 22.5921 - nsp_acc: 0.6039 - mlm_lm_acc: 0.0879\n",
      "\n",
      "Epoch 00001: mlm_lm_acc improved from -inf to 0.08793, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 568s 284ms/step - loss: 20.7954 - nsp_loss: 0.6126 - mlm_loss: 20.1828 - nsp_acc: 0.6445 - mlm_lm_acc: 0.1224\n",
      "\n",
      "Epoch 00002: mlm_lm_acc improved from 0.08793 to 0.12243, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 568s 284ms/step - loss: 19.6634 - nsp_loss: 0.5860 - mlm_loss: 19.0773 - nsp_acc: 0.6895 - mlm_lm_acc: 0.1373\n",
      "\n",
      "Epoch 00003: mlm_lm_acc improved from 0.12243 to 0.13733, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 568s 284ms/step - loss: 18.5731 - nsp_loss: 0.5602 - mlm_loss: 18.0129 - nsp_acc: 0.7296 - mlm_lm_acc: 0.1525\n",
      "\n",
      "Epoch 00004: mlm_lm_acc improved from 0.13733 to 0.15253, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 568s 284ms/step - loss: 17.0491 - nsp_loss: 0.5333 - mlm_loss: 16.5158 - nsp_acc: 0.7646 - mlm_lm_acc: 0.1763\n",
      "\n",
      "Epoch 00005: mlm_lm_acc improved from 0.15253 to 0.17634, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 568s 284ms/step - loss: 15.9557 - nsp_loss: 0.5048 - mlm_loss: 15.4509 - nsp_acc: 0.7980 - mlm_lm_acc: 0.1950\n",
      "\n",
      "Epoch 00006: mlm_lm_acc improved from 0.17634 to 0.19499, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 568s 284ms/step - loss: 15.3192 - nsp_loss: 0.4806 - mlm_loss: 14.8386 - nsp_acc: 0.8258 - mlm_lm_acc: 0.2077\n",
      "\n",
      "Epoch 00007: mlm_lm_acc improved from 0.19499 to 0.20770, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 569s 284ms/step - loss: 14.9101 - nsp_loss: 0.4606 - mlm_loss: 14.4496 - nsp_acc: 0.8480 - mlm_lm_acc: 0.2162\n",
      "\n",
      "Epoch 00008: mlm_lm_acc improved from 0.20770 to 0.21616, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 569s 284ms/step - loss: 14.6701 - nsp_loss: 0.4471 - mlm_loss: 14.2230 - nsp_acc: 0.8630 - mlm_lm_acc: 0.2215\n",
      "\n",
      "Epoch 00009: mlm_lm_acc improved from 0.21616 to 0.22150, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 569s 285ms/step - loss: 14.5652 - nsp_loss: 0.4412 - mlm_loss: 14.1241 - nsp_acc: 0.8694 - mlm_lm_acc: 0.2235\n",
      "\n",
      "Epoch 00010: mlm_lm_acc improved from 0.22150 to 0.22349, saving model to /aiffel/aiffel/bert_pretrain/models/bert_pre_train.hdf5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'sava'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_69/3024008713.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 훈련된 모델 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpre_train_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msava\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{model_dir}/bert_pre_train_model.keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Trained model saved to {model_dir}/bert_pre_train_model.keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'sava'"
     ]
    }
   ],
   "source": [
    "# Q. 모델을 학습시키고, 내용을 history에 담아주세요.\n",
    "# save weights callback\n",
    "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"{model_dir}/bert_pre_train.hdf5\", monitor=\"mlm_lm_acc\", verbose=1, save_best_only=True, mode=\"max\", save_freq=\"epoch\", save_weights_only=True)\n",
    "# train\n",
    "history = pre_train_model.fit(\n",
    "    pre_train_inputs,\n",
    "    pre_train_labels,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[save_weights]\n",
    ")\n",
    "\n",
    "# 훈련된 모델 저장\n",
    "pre_train_model.sava(f\"{model_dir}/bert_pre_train_model.keras\")\n",
    "print(f\"Trained model saved to {model_dir}/bert_pre_train_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d7d74f",
   "metadata": {},
   "source": [
    "NSP,MLM 트레인 로스 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f0e49051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr8AAAEICAYAAABWPpy+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABA8UlEQVR4nO3dd3hVVdrG4d+bHkKvQggEEEGQagABERCkSVMRRZwBFB0LiKPjWEYdP2d0bOOog6LooNgGBUVQA6g4ioqFgAJSpQQSQHqHQMr6/thJCB1TTsl57uvaV84uOfvd4bh9srL2WuacQ0REREQkFIT5uwAREREREV9R+BURERGRkKHwKyIiIiIhQ+FXREREREKGwq+IiIiIhAyFXxEREREJGQq/IiKlgJn1MrMVZrbKzO45wf66ZjbbzBaZ2RdmVtsfdYqI+Jv5cpzfqlWrusTERJ+dT0SkuMyfP3+bc66av+s4ETMLB1YClwDpwDxgiHNuaYFjJgMfOecmmtnFwAjn3O9O9b66Z4tIMDvZfTvCl0UkJiaSkpLiy1OKiBQLM1vn7xpOoS2wyjm3BsDMJgEDgKUFjmkC3JH7+n/AB6d7U92zRSSYney+rW4PIiLBLx5IK7CenrutoIXA5bmvLwPKmVkVH9QmIhJQFH5FRELDn4DOZvYj0BnYAGQfe5CZ3WhmKWaWsnXrVl/XKCJS4hR+RUSC3wYgocB67dxt+ZxzG51zlzvnWgF/yd2269g3cs6Nd84lOeeSqlULyC7OIiJF4tM+vyJSsjIzM0lPTycjI8PfpQStmJgYateuTWRkpL9L+S3mAQ3NrB5e6L0auKbgAWZWFdjhnMsB7gUmFOZE+owVXpB+tkRKHYVfkVIkPT2dcuXKkZiYiJn5u5yg45xj+/btpKenU69ePX+Xc8acc1lmNgqYBYQDE5xzS8zsYSDFOTcd6AL8w8wcMAe4tTDn0mescIL1syVSGin8ipQiGRkZCiVFYGZUqVKFYOzr6pxLBpKP2fZggddTgClFPY8+Y4UTzJ8tkdJGfX5FShmFkqLRz+/09DMqHP3cRAJD4Lf8Oge//ALnnOPvSkRERESkmBzKOsTew3vZc2gPew/tPer1nkN72Ht4L3sP7eXiehfTqW6nYjtv4IffiRPhhhvg4Yfhz3+G8HB/VyQiIiIScpxzZGRl5IfSggE17/VxQfYU4TYzJ/OMzhsTERNi4bd/f5gxA+67D5KT4fXXQQ8LiISc1NRU+vbty88//+zvUkRESp0cl8OmvZtI3ZXKut3rSN2VetTrrfu3svfwXrJyss7o/cpGlaV8dHnKRZXzvkaXo2qZqsdtK/j6RPvKRpUlPKx4Gz4DP/xWrgyTJkG/fnDrrdCiBbzyCgwe7O/KRERERIJCdk42G/ZuYN2u44Nt6q5U0vakcTj78FHfU61MNRIrJtK8RnNqxNU44+AaFxVHmAXuY2WBH34BzODaa6FTJxg+HMqX93dFIgHv9tvhp5+K9z1btoRnnjn1MampqfTu3ZsLL7yQuXPnEh8fz7Rp03j55Zd58cUXiYiIoEmTJkyaNImHHnqI1atXs2rVKrZt28af//xnbrjhhtPWkZGRwc0330xKSgoRERE8/fTTdO3alSVLljBixAgOHz5MTk4O7733HrVq1WLw4MGkp6eTnZ3NAw88wFVXXVUsP49Qd/vM2/np15+K9T1bntWSZ3o9c8pjSuoztm/fPgYMGMDOnTvJzMzk73//OwMGDADg9ddf56mnnsLMaN68OW+88QabN2/mpptuYs2aNQCMGzeODh06FOvPQ+RMZeVkkb4n/Uiw3bWO1N1HXqftSTuu1fassmeRWDGRpFpJDGoyiMSKidStUJfEionUqVCHuKg4P11NyQqO8Junbl34/HMvDAM89xw0bAi9e/u3LhE5yi+//MJ///tfXn75ZQYPHsx7773HY489xtq1a4mOjmbXrl35xy5atIjvvvuO/fv306pVKy699FJq1ap1yvd//vnnMTMWL17M8uXL6dGjBytXruTFF19kzJgxDB06lMOHD5OdnU1ycjK1atXi448/BmD37t0leeniIyXxGYuJiWHq1KmUL1+ebdu2ccEFF9C/f3+WLl3K3//+d+bOnUvVqlXZsWMHALfddhudO3dm6tSpZGdns2/fPl9dvoSgrJys/FbbE3VLSN+TTo7LyT/eMGqVq0VixUTaJ7RnSIUhXriteCTcxkTE+PGK/Ce4wi8cCb6ZmfDqq17T1i23wJNPQpkyfi1NJJCcroW2JNWrV4+WLVsCcP7555Oamkrz5s0ZOnQoAwcOZODAgfnHDhgwgNjYWGJjY+natSs//PDDUftP5Ouvv2b06NEANG7cmLp167Jy5Urat2/PI488Qnp6OpdffjkNGzakWbNm3Hnnndx999307duXTp2K76GJUHe6FtqSVBKfMecc9913H3PmzCEsLIwNGzawefNmPv/8c6688kqqVq0KQOXKlQH4/PPPef311wEIDw+nQoUKJXrNEjp2HtzJos2LWLh5IQt/XcjCzQtZsnUJGVlHZlYMszBql69NYsVEOtftfFSrbWLFRBIqJBAVHuXHqwhcwRd+80RGwrffeg/C/etfMHs2vPUWnH++vysTCXnR0dH5r8PDwzl48CAff/wxc+bM4cMPP+SRRx5h8eLFwPFjnxZlLNRrrrmGdu3a8fHHH9OnTx9eeuklLr74YhYsWEBycjL3338/3bp148EHHzz9m0lAK4nP2FtvvcXWrVuZP38+kZGRJCYmahpnKVHZOdms2rGKhZsXHhV20/ak5R9TrUw1WpzVglvb3ErTak2pV6keiRUTiS8XT2S4psoujOANvwAxMfD003DppTBsmNcneN06qFbN35WJSAE5OTmkpaXRtWtXLrzwQiZNmpT/J+Jp06Zx7733sn//fr744gsee+yx075fp06deOutt7j44otZuXIl69evp1GjRqxZs4b69etz2223sX79ehYtWkTjxo2pXLky1157LRUrVuSVV14p6csVPyiOz9ju3bupXr06kZGR/O9//2PdunUAXHzxxVx22WXccccdVKlShR07dlC5cmW6devGuHHjuP322/O7Paj1V05md8buowLuoi2L+HnLzxzIPABAuIVzbrVz6VS3Ey1qtPCWs1pQI66GJkgpZsEdfvN06waLF8OXXx4Jvtu3Q5Uq/q1LRADIzs7m2muvZffu3TjnuO2226hYsSIAzZs3p2vXrmzbto0HHnjgtP19AW655RZuvvlmmjVrRkREBK+99hrR0dG8++67vPHGG0RGRnLWWWdx3333MW/ePO666y7CwsKIjIxk3LhxJXy14g/F8RkbOnQo/fr1o1mzZiQlJdG4cWMAmjZtyl/+8hc6d+5MeHg4rVq14rXXXuPZZ5/lxhtv5D//+Q/h4eGMGzeO9u3b++qSJUDluBxW71h9JOjmht11u9flH1MltgotzmrBja1vpMVZXtBtUq0J0RHRp3hnKS7mnPPZyZKSklxKSkrJn+jjj2HIEK/T44gRR/oJi5Ryy5Yt49xzz/V3GWfsoYceomzZsvzpT3/ydylHOdHP0czmO+eS/FSSX5zonq3PWNEE289PTm3vob0s2rzoqKC7ePNi9mfuB7x+uY2qNMoPuM1rNKdFjRbUKldLrbk+cLL7dulo+T1Ws2Ze39/rr4cPP4Tx49UVQkRERAptd8Zuvkv/ju/Sv8sPumt2rsnfXzGmIi1qtOD6Vtcf1ZobGxnrx6rlREpn+K1Tx3sA7l//8h6Ia9YMXnsNevXyd2UiUsBDDz103LbFixfzu9/97qht0dHRfP/99z6qSkoTfcakMJxzrN21lm/Wf8PctLl8k/YNP2/5GYfDMM6pcg7n1zyf61pelx90a5evrdbcIFE6wy9AWBjceSdccgkMHQrp6f6uSETOQLNmzfipuGfnEClAnzE51uHsw/y46Ue+SfuGb9K8wPvrvl8BKBdVjvYJ7RnUZBAdEzrSNr4t5aLL+bliKYrSG37zNG8OKSkQlTvW3XvveS3Dbdr4ty4RERHxi+0HtjM3bW5+q+68jfPyx9CtV7Ee3et3p0PtDnSs05Gm1ZoSHhbu54qlOJX+8AuQNx5kdjY88AD88gs8+CDcey9EhMaPQERKNzPrBTwLhAOvOOceO2Z/HWAiUDH3mHucc8m+rlPE15xzrNy+0mvVXf8Nc9PnsnzbcgAiwiJoXbM1NyfdTMeEjnRI6EDNcjX9XLGUtNBKfuHh8M03cOutXvhNToY334QGDfxdmYhIoZlZOPA8cAmQDswzs+nOuaUFDrsfeNc5N87MmgDJQKLPixUpYQczD5KyMSW/VXdu2ly2H9wOQKWYSnRI6MDvm/+ejnU6klQriTKRmh021IRW+AWoVAnefhv69YObb4aWLWHFCjiDsUVFRAJUW2CVc24NgJlNAgYABcOvA8rnvq4AbPRphSIl5Nd9v3pBN7dVd/7G+WTmZAJwTpVz6N+oPx0SOtAxoSONqjYizML8XLH4W+iF3zxDhsCFF8K0aUeC7+HDR/oGi0iJee2110hJSWHs2LFFep/ExERSUlKoWrVqMVUWtOKBtALr6UC7Y455CPjEzEYDcUB335TmH8X1GZPAk7orlU9Xf8pX67/im7Rv8ocbiw6PJqlWEn+84I90rNOR9rXbUy1Ow5zK8UI3/AIkJMCoUd7rlBS47DJ48UVvumQRkdJlCPCac+6fZtYeeMPMznPO5RQ8yMxuBG4EqFOnjh/KFDna3kN7+SL1C2atnsUnqz/hlx2/AFA9rjodEzpyS9ItdEjoQOuarTVDmpyR0A6/BcXGQuXK0Lcv3HQTPPUUxMX5uyqRounS5fhtgwfDLbfAgQPQp8/x+4cP95Zt22DQoKP3ffHFaU+ZmppKr169uOCCC5g7dy5t2rRhxIgR/PWvf2XLli289dZbx5xuOLGxsfz4449s2bKFCRMm8Prrr/Ptt9/Srl07XnvttTO61KeffpoJEyYAMHLkSG6//Xb279/P4MGDSU9PJzs7mwceeICrrrqKe+65h+nTpxMREUGPHj146qmnzugcAWwDkFBgvXbutoKuB3oBOOe+NbMYoCqwpeBBzrnxwHjwZng73Ym7nOAzNnjwYG655RYOHDhAnxN8xoYPH87w4cPZtm0bg475jH0RYJ+xm2++mXnz5nHw4EEGDRrE//3f/wEwb948xowZw/79+4mOjmb27NmUKVOGu+++m5kzZxIWFsYNN9zA6NGjT3s9crQcl8OCTQv4ZPUnfLL6E+amzSUzJ5MykWXoktiFW9vcSo8GPWhctbHG1ZVCOW34NbME4HWgBl6fsfHOuWfNrDLwDt4DE6nAYOfczpIrtYQ1bQo//OCNBvHUU94kGW++CW3b+rsykaCzatUqJk+ezIQJE2jTpg1vv/02X3/9NdOnT+fRRx9l4MCBRx2/c+dOvv32W6ZPn07//v355ptveOWVV2jTpg0//fQTLVu2POX55s+fz6uvvsr333+Pc4527drRuXNn1qxZQ61atfj4448B2L17N9u3b2fq1KksX74cM2PXrl0l80PwrXlAQzOrhxd6rwauOeaY9UA34DUzOxeIAbb6tMpi5KvP2COPPELlypXJzs6mW7duLFq0iMaNG3PVVVfxzjvv0KZNG/bs2UNsbCzjx48nNTWVn376iYiICHbs2FHyP4hSYsOeDV7YXfMJn67+NP8BtVZnteKO9nfQo0EPOiZ0VMuuFIszafnNAu50zi0ws3LAfDP7FBgOzHbOPWZm9wD3AHeXXKk+EB0NTzzhtYb9/vcwY4YXfvftgz179FCcBJ9TtaKVKXPq/VWrnlFL74nUq1ePZs2aAdC0aVO6deuGmdGsWTNSU1OPO75fv375+2vUqHHU96ampp42/H799ddcdtllxOX+tebyyy/nq6++olevXtx5553cfffd9O3bl06dOpGVlUVMTAzXX389ffv2pW/fvoW6xkDinMsys1HALLxhzCY455aY2cNAinNuOnAn8LKZ/RGvIWO4c+60Lbunc6qW2jJlypxyf9WqVc+opfdEfPUZe/fddxk/fjxZWVls2rSJpUuXYmbUrFmTNrnjxZcv7z1H+Nlnn3HTTTcRkTuEZuXKlQt1baHgYOZB5qybwyerP2HW6lks2boEgLPKnsWl51xKj/o96F6/OzXK1vBzpVIanTb8Ouc2AZtyX+81s2V4D1cMALrkHjYR+IJgD795unSBxYuPdHt47z3vz8AdOsDll3tLvXr+rFAkoEVHH2mdCQsLy18PCwsjKyvrpMcXPPZUx5+pc845hwULFpCcnMz9999Pt27dePDBB/nhhx+YPXs2U6ZMYezYsXz++eeFPkegyB2zN/mYbQ8WeL0U6OjrukqKLz5ja9eu5amnnmLevHlUqlSJ4cOHk5GRUZyXETKccyzesji/K8OcdXM4lH2I6PBoOtXtxPCWw+nRoAfNqjdTVwYpcb+pz6+ZJQKtgO+BGrnBGOBXvG4RJ/qe4Hx4okKFI687dYK//Q3efx/+9CdvadkS5syBcpriUMTfOnXqxPDhw7nnnntwzjF16lTeeOMNNm7cSOXKlbn22mupWLEir7zyCvv27cvvi9qxY0fq16/v7/IlQO3Zs4e4uDgqVKjA5s2bmTFjBl26dKFRo0Zs2rSJefPm0aZNG/bu3UtsbCyXXHIJL730El27ds3v9hDKrb9b9m/h09Wf8skaL/DmTRfctFpTbmlzCz0b9KRT3U4aZ1d87ozDr5mVBd4DbnfO7Sn4m5lzzpnZCf989lsfnghI9evD/fd7y9q1MHUqLFp0JPjedZc3U9wVV8D554N+axXxqdatWzN8+HDa5vbRHzlyJK1atWLWrFncddddhIWFERkZybhx49i7dy8DBgwgIyMD5xxPP/20n6uXQNWiRQtatWpF48aNSUhIoGNHr+E8KiqKd955h9GjR3Pw4EFiY2P57LPPGDlyJCtXrqR58+ZERkZyww03MCpvRKEQcCjrEHPT5uZ3Zfjx1x8BqBJbhUsaXEKP+j3o0aAH8eXj/VyphDo7ky5fZhYJfATMcs49nbttBdDFObfJzGoCXzjnGp3qfZKSklxKSkoxlB1AnPO6QXz4oTd9ckKCtz50KOT2BxPxlWXLlnHuuef6u4ygd6Kfo5nNd84l+akkvzjRPVufsaIpTT+/vGmD84Yg+yL1C/Zn7iciLIKOCR3p0cALu61rttbEEuIXJ7tvn8loDwb8B1iWF3xzTQeGAY/lfp1WTLUGFzOvJXj7dvjoI69rxIsveg8TtWnjTZzxv/9B166aQENERILa/sP7+Xzt5yT/ksyMVTNYt3sdAA0rN2REyxH0aNCDLoldKBetLoESuM6k20NH4HfAYjP7KXfbfXih910zux5YBwwukQqDRZUqMGyYt+zd64Ve8IJvr15eH+J+/bxW4Z49vXAsImekXbt2HDp06Khtb7zxRv4T+yJFpc/YieW17s5YNYPkX5L5ct2XHM4+TNmosnSv3517L7yXHg16UK+SHgKX4HEmoz18DZysE2u34i2nlCj4EFznzl6XiPff96ZSfvNNb0KNBQugcWP/1SillnOu1D0t/f333/vsXMUw+lepp89Y4QTLZ+tA5gG+SP0iv3U3b/rgJtWaMLrtaPo07MOFdS4kKlx/zZTgpBneSlpMjDdrXN++kJUFX37pjR/csKG3/667YMkSr0V4wACopnnIpfBiYmLYvn07VapUKXXhxBecc2zfvp2YmBh/lxKw9BkrnED/bK3asSo/7H6R+gUZWRmUiSxDt3rd+FP7P9G7YW8SKyb6u0yRYqHw60sREdCtm7fkqVYNli+HG26AP/zBG1Zt2DAYMcJ/dUrQql27Nunp6WzdGrQTd/ldTEwMtWvX9ncZAUufscILpM9WRlYGX6Z+mR94f9nxCwCNqjTipvNvok/DPnSq24mYiMAM6yJFofDrb3/+s9f6u3Ch1zXi/fe98YNHjPBGknjmGS8sN2umIdTktCIjI6mnCVikBOkzFrzW7lyb33f387WfczDrIDERMVxc72Jua3cbvc/uTYPKDfxdpkiJU/gNBGbepBktW8LDD0PeQxerV8Odd3ohODHR6xYxYIDXOhyhfzoRETm5Q1mH+Gr9V/mtu8u3LQegQaUGjGw9kj4N+9C5bmdiI2P9XKmIbylBBaK8qTfPPhs2bfIemJs2zRtC7dlnvemWL78cdu2C8HDNMiciIgCs27WOGatmMGPVDGavmc3+zP1Eh0fTJbFLfneGhlUa+rtMEb9S+A10NWrAyJHesm8ffPIJ9Ojh7XvhBfi///O6RQwc6A2lVrOmX8sVERHfyczO5Ov1X+e37i7ZugSAxIqJDGsxjN4Ne9M1sStxUXF+rlQkcCj8BpOyZb0W3zy9esG2bV6r8B/+4C0XXeSNLRym2XREREqjw9mHmb1mNpOXTuaD5R+wM2MnkWGRdE7szHWtrqNPwz40qtJIo3GInITCbzBr3dpb/vlPb7i0adO8MJwXfIcO9VqCBwyADh28LhIiIhJ0DmUd4tM1nzJl6RSmrZjGroxdlI8uT/9G/bni3CvoXr87ZaPK+rtMkaCg8FsamMF553lLnqws2LkTJk/2wnG1at5YwyNHekFYREQCWkZWBrNWzWLKsilMXzGdPYf2UDGmIgMaDWBQk0FcUv8SoiOi/V2mSNBR+C2tIiIgORn27IGZM71W4alTvZbiDh28FuLp071AXL26v6sVERHgYOZBZq6ayeSlk/lw5YfsO7yPyrGVGXTuIAY1GUS3+t00s5pIESn8lnbly8Pgwd6Smem1CIP34Nz113utxh06HBlG7Zxz/FuviEiIOZB5gORfkpmydAofrfyI/Zn7qRJbhSHnDWFQk0F0TexKZHikv8sUKTUUfkNJZKS3AAwZAk2awAcfeK3Cf/6zt6xfDwkJ3tjCelhCJGiYWS/gWSAceMU599gx+/8FdM1dLQNUd85V9GmRkm/f4X18vPJjpiybQvIvyRzIPEC1MtW4tvm1XNnkSjondiYiTP+LFikJ+i8rVBWcWOOhh2DdOm9muYQEb//vfuc9ODdmDJx/vh8LFZHTMbNw4HngEiAdmGdm051zS/OOcc79scDxo4FWPi80xO09tJePVn7E5KWTmbFqBhlZGdSIq8HwFsMZ1GQQF9W9iPAwPZgsUtIUfsVTt64XeMFr9a1eHV5+Gd54Ay680AvBAwdqZjmRwNQWWOWcWwNgZpOAAcDSkxw/BPirj2oLabszdvPhyg+ZvHQys1bN4lD2IWqVq8UNrW9gUJNBdEzoqMAr4mNKMnI8M3j6afjrX2HCBPj3v+HKK+GRR+C++/xdnYgcLx5IK7CeDrQ70YFmVheoB3x+kv03AjcC1KlTp3irDBG7MnYxbfk0piybwierP+Fw9mHiy8VzU9JNXNnkStontCfMNBa7iL8o/MrJVagAf/wj3HYbfPQRtGnjbZ8xwxsp4rbb4Nxz/VujiPxWVwNTnHPZJ9rpnBsPjAdISkpyviwsmO04uINpy6cxeelkPlvzGZk5mdSpUIdRbUZxZdMraRvfVoFXJEAo/MrphYd7I0HkWb4cXn0VXnzRm2r59tuhZ0/NKifiPxuAhALrtXO3ncjVwK0lXlEIOJx9mI9WfsTEhRNJ/iWZrJwsEismcvsFtzOoySDa1GqjWdZEApDCr/x2f/wjXHstvPQSvPAC9OnjheBZs/xdmUiomgc0NLN6eKH3auCaYw8ys8ZAJeBb35ZXejjnSNmYwsSFE/nvz/9lx8Ed1Cxbk9vb3c7V511N65qtFXhFApzCrxROtWpw//3e8GhTphxp9T10CP72N28mucREv5YoEiqcc1lmNgqYhTfU2QTn3BIzexhIcc5Nzz30amCSc07dGX6jDXs28OaiN5m4cCLLti0jJiKGgY0HMqzFMLrX765hyUSCiPnyHpiUlORSUlJ8dj7xgy+/hG7dvBEjBgzwRom46CKNGSxBz8zmO+eS/F2HL4X6PftA5gGmLpvKxIUT+WzNZzgcHRM6MqzFMAY3HUyFmAr+LlFETuFk9239qirFq3NnSE31ukO89JI3pXLLlt6MctWq+bs6EZFTynE5fL3+ayb+NJHJSyez9/Be6laoy/0X3c/vW/yesyuf7e8SRaSIFH6l+NWuDY8+6nWLeOstmD0bqlb19iUnQ6tWULOmf2sUESlgzc41vL7wdV5f+Dprd62lbFRZrmxyJcNaDKNT3U4aqUGkFFH4lZJTpgzccIO3ABw86E2rfPAgXHWV1yUiKaT+iiwiAWR3xm6mLJ3CxIUT+Wr9VxhGt/rdeLjrw1zW+DLiouL8XaKIlACFX/Gd2FiYP9+bNOPVV+HNN6FDB/jXv6BtW39XJyIhIDsnm8/WfMbEhROZunwqGVkZNKrSiEcvfpRrm19LQoWE07+JiAQ1hV/xrbPPhmef9UaEePVVLwjHxHj70tO96ZPPOsu/NYpIqbN061Im/jSRNxe/yca9G6kUU4kRLUcwrMUw2sa31fBkIiFE4Vf8o3x5r9vD6NFHhkm75x6vj3C7dt5IEQMGeDPI6X9KIlII2w9s578//5eJCyeSsjGFcAunT8M+PNfrOfqe05foiGh/lygifqDwK/5VcFa4v/zFC7vTpsF993lLt27w2WfefucUhEXklA5nH2bGLzOYuHAiH638iMycTFqe1ZJ/9fwX1zS7hupx1f1dooj4mcKvBI5zz/UC8F/+Ahs2wPTpR8Jxdja0aOH1DR4wAC65xHugTkRCXo7LYW7aXN75+R0mLZnEtgPbqBFXg9FtRzOs5TCa12ju7xJFJIAo/Epgio+Hm28+sr5nDzRvDu+/7/UVjo31AvDdd3sPzYlISMkLvJOXTGbKsils3LuR6PBo+jfqz7AWw+h5dk/NuiYiJ6Q7gwSHSpXg7bfh8GGYM8frGjFtGuzb5+3/+WeYOdNrFW7Y0L+1ikiJOFng7d2wN4ObDKbvOX0pF13O32WKSIBT+JXgEhUF3bt7y3PPef2AAT79FO66y1vOPffIA3Nt2x7dr1hEgkqOy+HbtG95d8m7vLfsPTbs3ZAfeK9sciX9zumnwCsiv4nCrwQvsyMPwP3xj3DZZV4/4WnT4MknYexY2LYNoqPhl18gIeHIsGoiErDyAu/kpZOZsnTKUYH3iSZP0PecvpSPLu/vMkUkSCn8SumRmAi33eYtO3fC4sVe8AW4/HJYuxZ69fJahC+9FCpX9mu5InLEyQJvr7N78URTBV4RKT4Kv1I6VaoEF13kvXbOawn+4AOvZfi99yA83BtK7eGH/VqmSCjLcTl8l/4d7y5597jA+3iTx+nXqJ8Cr4gUO4VfKf3MvBbfXr3ghRcgJcXrGpE3pfK6ddCvHyQleSNKNGvmLdU1HqhIccsLvJOXTGby0sls2LuBqPAoep/dW4FXRHxC4VdCS1iYF3rzgi/Ajh3elMoffeQNo5bn44+hTx9YuRK+/dYLxE2aqN+wyG9UMPBOWTaF9D3pRIVHqYVXRPzitOHXzCYAfYEtzrnzcrc9BNwAbM097D7nXHJJFSlSolq1gk8+8V5v3uz1FV60CFq39rYlJ3sP1IHXXeKcc7wg/NxzUKMGHDzo9S3WqBLiR2bWC3gWCAdecc49doJjBgMPAQ5Y6Jy7pqTqyXE5fJ/+PZOXei28BQPvP7r9g37n9KNCTIWSOr2IyEmdScvva8BY4PVjtv/LOfdUsVck4k81anhL9+5Hto0eDb17e4E4LxgvWADlc1uqHnwQXnoJzjvvSLeJ5s3hwgs1HbP4hJmFA88DlwDpwDwzm+6cW1rgmIbAvUBH59xOMyuRfj3fp3/PO0veYcrSKaTtSVPgFZGAc9rw65ybY2aJPqhFJDCFh0OjRt5y5ZXH77/4YsjI8ELxu+96QbhqVdiyxdv/1FOwffuRUNyoEURG+vYapLRrC6xyzq0BMLNJwABgaYFjbgCed87tBHDObSmJQu77/D6+Xv81PRv05NFujyrwikjAKUqf31Fm9nsgBbgz74Z6LDO7EbgRoE6dOkU4nUiA6t3bW8AbWWLDBm/Ja/X97jtvlInMTG89MhIGDvSCMsA330DZst44xJUqqbVYCiMeSCuwng60O+aYcwDM7Bu8rhEPOedmHvtGRb1nv3jpi1SPq67AKyIBq7DhdxzwN7x+Y38D/glcd6IDnXPjgfEASUlJrpDnEwkOZlC7trfkmTLFm5Z5xYoj3SaqVfP2OeeNNLEz93fHuDjve4cOhQce8La9/rrXFSMhwVvKaTYrKZQIoCHQBagNzDGzZs65XQUPKuo9u2EVTS8uIoGtUOHXObc577WZvQx8VGwViZRGUVFHhlC7psAzRs55D9SlpR1Z0tOhQm6r2YEDMGzY0e9VoYI3RvGf/+x1t3jyySPBOCHBC89lyvju2iQQbAASCqzXzt1WUDrwvXMuE1hrZivxwvA835QoIhIYChV+zaymc25T7uplwM/FV5JICAkLgwsu8JYTiYmB1NTjw/G553r7N2zwHrg71tixcOut3v5HHjk6HOcF5KioErss8bl5QEMzq4cXeq8Gjh3J4QNgCPCqmVXF6waxxpdFiogEgjMZ6uy/eH8mq2pm6cBfgS5m1hKv20Mq8IeSK1EkhIWFQd263nIiDRp4Q61t2HB0QG7f3tufng6TJh3pVpHn3Xe9h/fmzvVakStVOnr5/e+hTh1v6Lc1a45sr1jxyJTREjCcc1lmNgqYhdefd4JzbomZPQykOOem5+7rYWZLgWzgLufcdv9VLSLiH2cy2sOQE2z+TwnUIiKFERPjheAGDY7f166dN4nH/v1eEM4Lx3ktzVlZkJMDq1Z5AXnnTq+rRffuXvhNTobrjunOHxsLP/zgDe32wQcwYcLR4bhSJRgxwhsKbsMG7z3z9sfG6oG+EpI71nryMdseLPDaAXfkLiIiIUszvImEgri4I8O1FXTRRTBnztHbDh/2hncD6NkTZsw4EozzlrPO8vbv2wfr13sP8e3cCXv2eNuHDPHC74svwt//fuS9o6K8gLxmjVfTs896ATo62gvx0dFef+W8mfYmT4aFC4/si4nxHvgbPtzbP28ebNt29PeXLXvkOvPqiY72zq3gLSIS8hR+ReRoBfsC16rlLSdz7bXekicrC3bv9lp5wRu1olmzo4Pzrl1HHsgzg+xsb3tGBhw6dPT7z5wJr73mtU7nqVr1SPh99FEvPBeUmAhr13qvr7gCPvvsyL7oaHj4Ye9hQRERCUnm/SXMN5KSklxKSorPzicipURW1pFwnJl5pOV59WrYutXbfuiQd0xUFPTq5e2fOtULwnnfm5EBPXpAt26/uQQzm++cSyrGqwp4umeLSDA72X1bLb8iEvgiIrzuDGXLHr39ZH2d81x2WcnWJSIiQSfM3wWIiIiIiPiKwq+IiIiIhAyFXxEREREJGQq/IiIiIhIyFH5FREREJGQo/IqIiIhIyFD4FREREZGQofArIiIiIiFD4VdEREREQobCr4iIiIiEDIVfEREREQkZCr8iIiIiEjIUfkVESgEz62VmK8xslZndc4L9w81sq5n9lLuM9EedIiL+FuHvAkREpGjMLBx4HrgESAfmmdl059zSYw59xzk3yucFiogEELX8iogEv7bAKufcGufcYWASMMDPNYmIBCSFXxGR4BcPpBVYT8/ddqwrzGyRmU0xswTflCYiElgUfkVEQsOHQKJzrjnwKTDxRAeZ2Y1mlmJmKVu3bvVpgSIivqDwKyIS/DYABVtya+duy+ec2+6cO5S7+gpw/oneyDk33jmX5JxLqlatWokUKyLiTwq/IiLBbx7Q0MzqmVkUcDUwveABZlazwGp/YJkP6xMRCRga7UFEJMg557LMbBQwCwgHJjjnlpjZw0CKc246cJuZ9QeygB3AcL8VLCLiRwq/IiKlgHMuGUg+ZtuDBV7fC9zr67pERAKNuj2IiIiISMhQ+BURERGRkKHwKyIiIiIhQ+FXREREREKGwq+IiIiIhAyFXxEREREJGQq/IiIiIhIyFH5FREREJGQo/IqIiIhIyFD4FREREZGQcdrwa2YTzGyLmf1cYFtlM/vUzH7J/VqpZMsUERERESm6M2n5fQ3odcy2e4DZzrmGwOzcdRERERGRgHba8OucmwPsOGbzAGBi7uuJwMDiLUtEREREpPgVts9vDefcptzXvwI1iqkeEREREZESU+QH3pxzDnAn229mN5pZipmlbN26tainExEREREptMKG381mVhMg9+uWkx3onBvvnEtyziVVq1atkKcTERERESm6wobf6cCw3NfDgGnFU46IiIiISMk5k6HO/gt8CzQys3Qzux54DLjEzH4Buueui4iIn5hZLzNbYWarzOykI/CY2RVm5swsyZf1iYgEiojTHeCcG3KSXd2KuRYRESkEMwsHngcuAdKBeWY23Tm39JjjygFjgO99X6WISGDQDG8iIsGvLbDKObfGOXcYmIQ3JOWx/gY8DmT4sjgRkUCi8CsiEvzigbQC6+m52/KZWWsgwTn38aneSCP0iEhpp/ArIlLKmVkY8DRw5+mO1Qg9IlLaKfyKiAS/DUBCgfXaudvylAPOA74ws1TgAmC6HnoTkVCk8CsiEvzmAQ3NrJ6ZRQFX4w1JCYBzbrdzrqpzLtE5lwh8B/R3zqX4p1wREf9R+BURCXLOuSxgFDALWAa865xbYmYPm1l//1YnIhJYTjvUmYiIBD7nXDKQfMy2B09ybBdf1CQiEojU8isiIiIiIUPhV0RERERChsKviIiIiIQMhV8RERERCRkKvyIiIiISMhR+RURERCRkKPyKiIiISMhQ+BURERGRkKHwKyIiIiIhQ+FXREREREKGwq+IiIiIhAyFXxEREREJGQq/IiIiIhIyFH5FREREJGQo/IqIiIhIyFD4FREREZGQofArIlIKmFkvM1thZqvM7J4T7L/JzBab2U9m9rWZNfFHnSIi/qbwKyIS5MwsHHge6A00AYacINy+7Zxr5pxrCTwBPO3bKkVEAoPCr4hI8GsLrHLOrXHOHQYmAQMKHuCc21NgNQ5wPqxPRCRgRPi7ABERKbJ4IK3AejrQ7tiDzOxW4A4gCrj4RG9kZjcCNwLUqVOn2AsVEfE3tfyKiIQI59zzzrkGwN3A/Sc5ZrxzLsk5l1StWjXfFigi4gMKvyIiwW8DkFBgvXbutpOZBAwsyYJERAKVwq+ISPCbBzQ0s3pmFgVcDUwveICZNSyweinwiw/rExEJGOrzKyIS5JxzWWY2CpgFhAMTnHNLzOxhIMU5Nx0YZWbdgUxgJzDMfxWLiPiPwq+ISCngnEsGko/Z9mCB12N8XpSISABStwcRERERCRkKvyIiIiISMhR+RURERCRkKPyKiIiISMgo0gNvZpYK7AWygSznXFJxFCUiIiIiUhKKY7SHrs65bcXwPiIiIiIiJUrdHkREREQkZBQ1/DrgEzObb2Y3nugAM7vRzFLMLGXr1q1FPJ2IiIiISOEVNfxe6JxrDfQGbjWzi449wDk33jmX5JxLqlatWhFPJyIiIiJSeEUKv865DblftwBTgbbFUZSIiIiISEkodPg1szgzK5f3GugB/FxchYmIiIiIFLeijPZQA5hqZnnv87ZzbmaxVCUiIiIiUgIKHX6dc2uAFsVYi4iIiIiEmJycHLKyssjMzCQ7O5vy5csDsGPHDrKysqhevXqxnq84xvkVERERkQDnnOPQoUNERkYSHh7Ojh07WL16Nfv372ffvn35X6+44goqVqzIV199xXvvvcf+/fs5dOgQWVlZZGVl8cILL1C1alXefvttXn311fztecvs2bMpX748Tz75JC+99FJ+sM3bv3nzZiIiIhg1ahQvvPACzrn8GmNjYzlw4AAAY8aMYfv27SQnJxfrz0HhV0RERCQAZWdns337dnbs2MHOnTvZtWsX+/bto127dtSpU4c1a9bw2muvsX///qOW+++/n9atW/Ppp59yyy235Afb/fv3k5OTw9y5c2nfvj3Tp09nxIgRx503KSmJihUr8vPPPzNhwgTi4uKIjY0lIiKCiIgIDh06BMDhw4fZv38/kZGRREVFUaZMGSIijkTL2rVrc8EFF+R/X2Rk5FH7e/bsSeXKlfP3R0REEBUVlb9/5MiRZGRkFPvP1Qqm7ZKWlJTkUlJSfHY+EZHiYmbzQ20Kd92zRYrOOcfBgwfZsWNH/lKnTh3q16/Ptm3b+Oc//5kfbvP233PPPQwePJgffviBdu3aHfeeb775JkOHDuXLL7+kS5culClThrJlyxIXF0dcXBxjx46lc+fOzJ8/n3/+85/ExcUdtX/o0KHUqVOHtLQ0Fi5ceNS+uLg4atWqRWRkpB9+WsXrZPdttfyKiJQCZtYLeBYIB15xzj12zP47gJFAFrAVuM45t87nhYoEsYMHD7Jp0yaioqKoXbs22dnZvPTSS/mhNS/A9uvXj5EjR7Jjxw5q1aqV31Ka5+GHH+aBBx4gIyODp556iipVqlCpUiUqV65MfHw8ZcuWBaBBgwaMHTs2f1+FChUoW7YsderUAaBTp05kZ2cTFnbiwbvOP/983n777ZNeT0JCAgkJCcX00wkeCr8iIkHOzMKB54FLgHRgnplNd84tLXDYj0CSc+6Amd0MPAFc5ftqRQJPTk4OW7ZsYcOGDWzYsIFy5crRtWtXAAYOHMiqVavYuHEjO3fuBGDEiBFMmDCBsLAwbr/9djIzM4mLi6Ny5cpUrlyZvXv3AlC+fHnGjBmTvz1vadiwIQDx8fEcPnyY3JGzjlOlShVuvfXWk9Z9stArp6bwKyIS/NoCq3JH4cHMJgEDgPzw65z7X4HjvwOu9WmFIn6yb98+NmzYwMaNG/PDbVxcHKNGjQKgc+fOzJ07l6ysrPzv6d69e374DQsLo2HDhnTu3Jn4+Hhq1qxJ06ZNATAz0tPTqVix4lF9VfNERETw+OOPn7S2k4VeKVkKvyIiwS8eSCuwng4c31HwiOuBGSVakYiPLF++nGXLlh0VbsPCwnj11VcB6N+/P//73/+O+p6kpKT88NurVy86duxIfHx8/lKwK8D7779/yvMX9zBcUvIUfkVEQoiZXQskAZ1Psv9G4EYgv1+hiD/9+uuvLFy4kBUrVrBixQqWL19OWloaK1aswMz4xz/+weuvvw54La21atXK71YAcMcdd3DddddRq1at/HCb16cW4N577/X5NYl/KfyKiAS/DUDBp1Zq5247ipl1B/4CdHbOHTp2P4BzbjwwHrzRHoq/VJHj7d27Nz/c5gXcl19+mQoVKvDvf/+bRx99FIAKFSrQuHFj2rdvT2ZmJlFRUdx7772MGTOG+Ph4qlWrdlw/2L59+/rjkiSAKfyKiAS/eUBDM6uHF3qvBq4peICZtQJeAno557b4vkQJddnZ2axfvz4/4A4aNIj4+HheffVVrrvuuvzjwsLCqFevHlu2bKFChQoMHz6cnj170qhRI6pXr35cP9nGjRv7+lIkyCn8iogEOedclpmNAmbhDXU2wTm3xMweBlKcc9OBJ4GywOTc8LDeOdffb0VLqbVnzx5WrFhBfHw8tWrVYv78+YwYMYKVK1ceNeRXYmIi8fHxtGvXjkcffZRGjRrRuHFjGjRoQHR0dP5xDRs2PKobg0hRKfyKiJQCzrlkIPmYbQ8WeN3d50VJqeWc4/Dhw0RHR7Nt2zbuv//+/BbdTZs2AfDcc88xevRoqlSpQt26denRoweNGzemUaNGNGrUiGrVqgHQpEkTmjRp4s/LkRCj8CsiIiIn5ZxjzZo1LFiwgAULFjB//nwWLFjAyJEjeeyxx4iNjWXKlCmcc8459OzZMz/gtm3bFvBaeD/88EM/X4XIEQq/IiIiAnj9cleuXMmCBQsICwtjyJAhALRp04adO3cSGRnJeeedx8CBA+nYsSMAcXFxbNu2zZ9li/wmCr8iIiIhKCcnJ39khMcff5wPP/yQn376if379wPe1LhDhgzBzHjjjTfyJ3co2B9XJBgp/IqIiJRyhw4d4ueff87vsrBgwQI2bdrE+vXrMTNSU1MxM66//npat25N69atjxpF4dJLL/Vj9SLFS+FXRESkFDlw4AALFy5kwYIFXH/99cTExPDAAw/w5JNPAt5Yua1bt+aqq67Kf2ht3Lhxfq5axHcUfkVERIKQc46cnBzCw8NZsGABzzzzDAsWLGDZsmXk5OQA0LZtW9q0acPQoUNp27YtrVu3pl69eseNlSsSShR+RUREApBzjqysLCIjI/n111+ZOHEiqamp+cu6det48803ufzyy9m9ezezZ8+mdevWXHHFFfldF2rXrg1AixYtaNGihZ+vSCQwKPyKiIj4QcGxcvfu3cu4ceNITU1l7dq1+eH2H//4B2PGjGH37t3cc889VKlShcTERJo2bcqll15KvXr1AOjSpQsbNhw3o7WInIDCr4iISAlwzpGRkUFsbCw5OTk8+eSTx7Xc3nrrrTz55JOEh4dz9913U7lyZerVq5cfblu3bg3A2WefzZ49eyhXrtwJz6VuDCJnTuFXRESkEJxz7N27l/LlywMwduxYli5delTA7d+/P5MmTSIsLIwnnngCMyMxMZEmTZrQp08fLr74YgDKlClzynAbHh5+0n0i8tso/IqIiJxAdnY2O3bsyJ+G9z//+Q/ff/8969atIzU1lfXr19OqVSvmzp2bv3/9+vUkJiZy7rnn0rt3by644IL890tLS6NMmTInPZ/CrYhvKPyKiEhIyszMZNOmTdSpUweAt99+m08//ZR169axbt061q9fz1lnnUVaWhoAH3zwAT/88AN169alRYsW9O/fn2bNmuW/37fffktMTMxJz3eq4CsivqPwKyIipVJGRgbr16/n7LPPJiwsjGnTpjF58uT8/rYbN27EzMjIyCAiIoK5c+fyySefkJiYSLt27Rg8eDD169fPf78PPviA8PDwk57vVMFXRAKHwq+IiJQKH330EW+88UZ+t4TNmzcDXneD2rVrs3LlSr755hvq1q1Lt27dqFu3LnXr1iU7O5uIiAj+/e9/M3bs2JO+/6mCr4gED4VfEREJOhs3bmTmzJnMnDmT+++/n+bNm5OTk8OPP/5I3bp16du3L4mJidStWze/L+1dd93FXXfdddL31IgJIqFB4VdERILCjh07eOKJJ5g5cyYLFy4EoFatWqSlpdG8eXP69+9P//79/VyliAQ6hV8REQlIaWlpzJgxg4oVKzJ48GCio6N5/vnnSUpK4vHHH6dXr140a9ZMLbYi8pso/IqIlAJm1gt4FggHXnHOPXbM/ouAZ4DmwNXOuSk+L/IMzJkzh+nTpzNjxgyWLl0KQP/+/Rk8eDBxcXFs3bpVD5aJSJGE+bsAEREpGjMLB54HegNNgCFm1uSYw9YDw4G3fVvdqaWmpvLOO+/krz/++OM899xz1KxZk6eeeoolS5bwwQcf5O9X8BWRolLLr4hI8GsLrHLOrQEws0nAAGBp3gHOudTcfTn+KDBPRkYGc+bMYcaMGcycOZPly5cD0LVrV6pXr87zzz9P1apVKVu2rD/LFJFSLODD7/XXQ1YWhIUdWcLDi2/9dMcG0mL2248XkZAQD6QVWE8H2hXmjczsRuBGIH/yh6JavXo1VapUoWLFikycOJGbbrqJ6OhoOnfuzB/+8Ad69+6dP4taYmJisZxTRORkAj78zp0LGRmQk+Mt2dlHXp9uPTvb39X7X2ECs79D/rHLmfxCcrpjCvNLzbE/ixP9bAq77WTr/viat4gAOOfGA+MBkpKSXGHe48CBA3z55ZfMmDGDGTNmsGrVKl5++WVGjhzJwIEDSUhIoEuXLprxTET8IuDD77JlRft+5woXnPPWC36/L5dTnfu31lSYayjO687KKvw1H/tvcqLvOdk++e0KhmFfLHnnLHj+U30trmPeegtatSrazyrAbAASCqzXzt3mczt37qRWrVpkZGQQGxtL165dGTNmDD179gSgRo0a9OnTxx+liYgAQRB+i8rMa/ULD4fISH9XI76UF6RPF6BP9cvGmWwr6vflnTtv3Vdf8177a8n7Nyr473Wqr8V5TClscJwHNDSzenih92rgGn8UUqlSJR566CFatWrFRRddpAfURCTgFCn8nm5oHRF/KviLj0hp5pzLMrNRwCy8+/EE59wSM3sYSHHOTTezNsBUoBLQz8z+zznXtCTqufvuu0vibUVEikWhw2+BoXUuwXu4Yp6ZTXfOLT31d4qISHFzziUDycdse7DA63l43SFEREJaWBG+N39oHefcYSBvaB0RERERkYBUlPB7oqF14o89yMxuNLMUM0vZunVrEU4nIiIiIlI0RQm/Z8Q5N945l+ScS8obx1FERERExB+KEn4DZmgdEREREZEzUZTwmz+0jplF4Q2tM714yhIRERERKX6FHu3hZEPrFFtlIiIiIiLFrEjj/J5oaB0RERERkUBlruC0RyV9MrOtwLpCfGtVYFsxlxPoQvGaITSvOxSvGYLvuus650LqqV3ds3+zULxuXXPoCMbrPuF926fht7DMLMU5l+TvOnwpFK8ZQvO6Q/GaIXSvOxSE6r9tKF63rjl0lKbrLvGhzkREREREAoXCr4iIiIiEjGAJv+P9XYAfhOI1Q2hedyheM4TudYeCUP23DcXr1jWHjlJz3UHR51dEREREpDgES8uviIiIiEiRBXT4NbNeZrbCzFaZ2T3+rscXzCzBzP5nZkvNbImZjfF3Tb5iZuFm9qOZfeTvWnzFzCqa2RQzW25my8ysvb9rKmlm9sfcz/bPZvZfM4vxd01SfELtvq17tu7Z/q6ppJXGe3bAhl8zCweeB3oDTYAhZtbEv1X5RBZwp3OuCXABcGuIXDfAGGCZv4vwsWeBmc65xkALSvn1m1k8cBuQ5Jw7D292yKv9W5UUlxC9b+ueHVp0zy4F9+yADb9AW2CVc26Nc+4wMAkY4OeaSpxzbpNzbkHu6714/2HF+7eqkmdmtYFLgVf8XYuvmFkF4CLgPwDOucPOuV1+Lco3IoBYM4sAygAb/VyPFJ+Qu2/rnq17tl+L8o1Sd88O5PAbD6QVWE8nBG4oBZlZItAK+N7PpfjCM8CfgRw/1+FL9YCtwKu5fzp8xczi/F1USXLObQCeAtYDm4DdzrlP/FuVFKOQvm/rnl3q6Z5dSu7ZgRx+Q5qZlQXeA253zu3xdz0lycz6Alucc/P9XYuPRQCtgXHOuVbAfqBU95E0s0p4LYH1gFpAnJld69+qRIpO9+yQoHt2KblnB3L43QAkFFivnbut1DOzSLyb6FvOuff9XY8PdAT6m1kq3p9JLzazN/1bkk+kA+nOubxWoil4N9bSrDuw1jm31TmXCbwPdPBzTVJ8QvK+rXu27tmlWKm8Zwdy+J0HNDSzemYWhdfBerqfaypxZmZ4/YmWOeee9nc9vuCcu9c5V9s5l4j37/y5cy7of7M8Hefcr0CamTXK3dQNWOrHknxhPXCBmZXJ/ax3o5Q/MBJiQu6+rXu27tl+LMkXSuU9O8LfBZyMcy7LzEYBs/CeLpzgnFvi57J8oSPwO2Cxmf2Uu+0+51yy/0qSEjQaeCs3KKwBRvi5nhLlnPvezKYAC/Cekv+RUjRrUKgL0fu27tmhRffsUnDP1gxvIiIiIhIyArnbg4iIiIhIsVL4FREREZGQofArIiIiIiFD4VdEREREQobCr4iIiIiEDIVfCThmlm1mPxVYim0GHTNLNLOfi+v9RERCne7ZEmwCdpxfCWkHnXMt/V2EiIicEd2zJaio5VeChpmlmtkTZrbYzH4ws7Nztyea2edmtsjMZptZndztNcxsqpktzF3ypmQMN7OXzWyJmX1iZrF+uygRkVJK92wJVAq/Eohij/kT2lUF9u12zjUDxgLP5G77NzDROdcceAt4Lnf7c8CXzrkWePOv58001RB43jnXFNgFXFGiVyMiUrrpni1BRTO8ScAxs33OubIn2J4KXOycW2NmkcCvzrkqZrYNqOmcy8zdvsk5V9XMtgK1nXOHCrxHIvCpc65h7vrdQKRz7u8+uDQRkVJH92wJNmr5lWDjTvL6tzhU4HU26vsuIlJSdM+WgKPwK8HmqgJfv819PRe4Ovf1UOCr3NezgZsBzCzczCr4qkgREQF0z5YApN+eJBDFmtlPBdZnOufyhs6pZGaL8FoChuRuGw28amZ3AVuBEbnbxwDjzex6vNaCm4FNJV28iEiI0T1bgor6/ErQyO0/luSc2+bvWkRE5NR0z5ZApW4PIiIiIhIy1PIrIiIiIiFDLb8iIiIiEjIUfkVEREQkZCj8ioiIiEjIUPgVERERkZCh8CsiIiIiIUPhV0RERERCxv8DrbHFzmufxTkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training result\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['nsp_loss'], 'b-', label='nsp_loss')\n",
    "plt.plot(history.history['mlm_loss'], 'r--', label='mlm_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['nsp_acc'], 'g-', label='nsp_acc')\n",
    "plt.plot(history.history['mlm_lm_acc'], 'k--', label='mlm_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cecaf1a",
   "metadata": {},
   "source": [
    "MLM테스크 인퍼런스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6c7372d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name_path = \"{model_dir}/bert_pre_train.hdf5\"\n",
    "\n",
    "def predict_masked_words(sentence, model, vocab_processor, config_obj, top_k=5):\n",
    "    \"\"\"\n",
    "    BERT 모델을 사용하여 문장 내 마스크된 단어를 예측합니다.\n",
    "    :param sentence: '[MASK]' 토큰이 포함된 입력 문장 문자열.\n",
    "    :param model: 훈련된 Keras BERT 모델.\n",
    "    :param vocab_processor: SentencePieceProcessor 인스턴스.\n",
    "    :param config_obj: 모델의 설정 객체.\n",
    "    :param top_k: 각 마스크에 대해 반환할 상위 예측 개수.\n",
    "    :return: 각 내부 리스트가 마스크에 대한 (토큰, 확률) 튜플을 포함하는 리스트의 리스트.\n",
    "    \"\"\"\n",
    "    if '[MASK]' not in sentence:\n",
    "        print(\"문장에서 [MASK] 토큰을 찾을 수 없습니다.\")\n",
    "        return []\n",
    "\n",
    "    tokens = [\"[CLS]\"] + vocab_processor.encode_as_pieces(sentence) + [\"[SEP]\"]\n",
    "    \n",
    "    masked_indices = [i for i, token in enumerate(tokens) if token == \"[MASK]\"]\n",
    "    if not masked_indices:\n",
    "        print(\"경고: '[MASK]' 토큰이 여러 조각으로 토큰화되었거나 토큰화 후 찾을 수 없습니다.\")\n",
    "        # '[MASK]'가 user_defined_symbol이 아니거나 어휘집에 보존되는 방식으로 포함되지 않은 경우 발생할 수 있습니다.\n",
    "        # 여러분의 어휘집 훈련(122번 셀)은 [MASK]를 user_defined_symbol로 포함하므로 괜찮을 것입니다.\n",
    "        return []\n",
    "\n",
    "    input_ids = [vocab_processor.piece_to_id(p) for p in tokens]\n",
    "    segment_ids = [0] * len(input_ids)\n",
    "\n",
    "    # 패딩\n",
    "    padding_length = config_obj.n_seq - len(input_ids)\n",
    "    if padding_length < 0:\n",
    "        print(f\"경고: 문장이 n_seq ({config_obj.n_seq})보다 깁니다. 자릅니다.\")\n",
    "        input_ids = input_ids[:config_obj.n_seq]\n",
    "        segment_ids = segment_ids[:config_obj.n_seq]\n",
    "        # 자르기로 인해 masked_indices가 영향을 받았다면 업데이트합니다.\n",
    "        masked_indices = [idx for idx in masked_indices if idx < config_obj.n_seq]\n",
    "        if not masked_indices:\n",
    "             print(\"자르기 후 [MASK] 토큰이 남아있지 않습니다.\")\n",
    "             return []\n",
    "    else:\n",
    "        input_ids += [vocab_processor.pad_id()] * padding_length\n",
    "        segment_ids += [0] * padding_length\n",
    "        \n",
    "    input_ids_np = np.array([input_ids])\n",
    "    segment_ids_np = np.array([segment_ids])\n",
    "\n",
    "    _, mlm_predictions = model.predict((input_ids_np, segment_ids_np), verbose=0)\n",
    "    \n",
    "    results = []\n",
    "    for mask_idx in masked_indices:\n",
    "        if mask_idx >= mlm_predictions.shape[1]: # 적절한 자르기 로직에서는 발생하지 않아야 합니다.\n",
    "            continue\n",
    "            \n",
    "        mask_predictions = mlm_predictions[0, mask_idx, :]\n",
    "        top_k_indices = np.argsort(mask_predictions)[-top_k:][::-1]\n",
    "        \n",
    "        top_k_tokens_probs = []\n",
    "        for token_id in top_k_indices:\n",
    "            token = vocab_processor.id_to_piece(int(token_id))\n",
    "            prob = mask_predictions[token_id]\n",
    "            top_k_tokens_probs.append((token, prob))\n",
    "        results.append(top_k_tokens_probs)\n",
    "        \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8b179",
   "metadata": {},
   "source": [
    "### MLM 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "916955dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlm_predictions(test_sentences, model, vocab_processor, config_obj, top_k=3):\n",
    "    \"\"\"\n",
    "    테스트 문장 리스트에 대해 MLM 예측을 실행하고 결과를 출력합니다.\n",
    "    \"\"\"\n",
    "    for sentence in test_sentences:\n",
    "        print(f\"입력: {sentence}\")\n",
    "        predictions = predict_masked_words(sentence, model, vocab_processor, config_obj, top_k=top_k)\n",
    "        if predictions:\n",
    "            for i, mask_preds in enumerate(predictions):\n",
    "                original_mask_token = f\"[MASK]_{i+1}\"\n",
    "                print(f\"  {original_mask_token} 예측:\")\n",
    "                for token, prob in mask_preds:\n",
    "                    # 표시를 위해 특수 밑줄 문자(U+2581)를 대체합니다 (필요한 경우).\n",
    "                    display_token = token.replace(u\"\\u2581\", \"_\") if isinstance(token, str) else token\n",
    "                    print(f\"    - \\\"{display_token}\\\" (확률: {prob:.4f})\")\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cb7e9fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: 주기율표에서 같은 족에 속하는 원소들은 유사한 화학적 [MASK] 가지는 경향이 있다.\n",
      "  [MASK]_1 예측:\n",
      "    - \"_성질을\" (확률: 0.1699)\n",
      "    - \"_다음과\" (확률: 0.0436)\n",
      "    - \"_구조를\" (확률: 0.0394)\n",
      "    - \"_다음을\" (확률: 0.0249)\n",
      "    - \"_의미를\" (확률: 0.0236)\n",
      "----------------------------------------\n",
      "입력: 조선 왕조의 제4대 국왕은 [MASK]대왕으로 알려져 있으며, 한글 창제와 같은 위대한 업적을 남겼다.\n",
      "  [MASK]_1 예측:\n",
      "    - \"_또는\" (확률: 0.0710)\n",
      "    - \"_왕조의\" (확률: 0.0231)\n",
      "    - \"_이름은\" (확률: 0.0191)\n",
      "    - \"_시대\" (확률: 0.0180)\n",
      "    - \"_왕\" (확률: 0.0151)\n",
      "----------------------------------------\n",
      "입력: 그 사건은 당시 사회에 큰 [MASK] 일으켰으며, 이후 관련 논쟁이 끊이지 않았다.\n",
      "  [MASK]_1 예측:\n",
      "    - \"_영향을\" (확률: 0.0306)\n",
      "    - \"_전쟁을\" (확률: 0.0192)\n",
      "    - \"_활동을\" (확률: 0.0165)\n",
      "    - \"_지원을\" (확률: 0.0164)\n",
      "    - \"_등을\" (확률: 0.0162)\n",
      "----------------------------------------\n",
      "입력: [MASK]는 양성자, 중성자, 그리고 전자로 구성된다.\n",
      "  [MASK]_1 예측:\n",
      "    - \"_중성자\" (확률: 0.5754)\n",
      "    - \"_양성\" (확률: 0.0609)\n",
      "    - \"_중성\" (확률: 0.0503)\n",
      "    - \"_원자핵\" (확률: 0.0182)\n",
      "    - \"_원자\" (확률: 0.0087)\n",
      "----------------------------------------\n",
      "입력: 빛은 전자기파의 일종으로, 파동성과 [MASK] 동시에 지니는 이중성을 나타낸다.\n",
      "  [MASK]_1 예측:\n",
      "    - \"_또는\" (확률: 0.0681)\n",
      "    - \"_및\" (확률: 0.0239)\n",
      "    - \"_구조를\" (확률: 0.0191)\n",
      "    - \"_같은\" (확률: 0.0175)\n",
      "    - \"_성질을\" (확률: 0.0127)\n",
      "----------------------------------------\n",
      "입력: 노무현 전 [MASK]은 참여정부 시절 권위주의 타파와 개혁을 강조했습니다.\n",
      "  [MASK]_1 예측:\n",
      "    - \"_노무현\" (확률: 0.4634)\n",
      "    - \"_대통령\" (확률: 0.0298)\n",
      "    - \"_이명박\" (확률: 0.0143)\n",
      "    - \"_이회\" (확률: 0.0125)\n",
      "    - \"_국회의원\" (확률: 0.0104)\n",
      "----------------------------------------\n",
      "입력: 지미 카터 전 대통령은 인권 외교를 강조했으며, 퇴임 후에는 국제 평화와 [MASK] 증진을 위한 활동에 힘썼습니다.\n",
      "  [MASK]_1 예측:\n",
      "    - \"_정부\" (확률: 0.0293)\n",
      "    - \"_외교\" (확률: 0.0252)\n",
      "    - \"_대통령의\" (확률: 0.0202)\n",
      "    - \"_경제\" (확률: 0.0198)\n",
      "    - \"_및\" (확률: 0.0193)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_data = [\"주기율표에서 같은 족에 속하는 원소들은 유사한 화학적 [MASK] 가지는 경향이 있다.\",\n",
    "            \"조선 왕조의 제4대 국왕은 [MASK]대왕으로 알려져 있으며, 한글 창제와 같은 위대한 업적을 남겼다.\",\n",
    "            \"그 사건은 당시 사회에 큰 [MASK] 일으켰으며, 이후 관련 논쟁이 끊이지 않았다.\",\n",
    "            \"[MASK]는 양성자, 중성자, 그리고 전자로 구성된다.\",\n",
    "            \"빛은 전자기파의 일종으로, 파동성과 [MASK] 동시에 지니는 이중성을 나타낸다.\",\n",
    "            \"노무현 전 [MASK]은 참여정부 시절 권위주의 타파와 개혁을 강조했습니다.\",\n",
    "            \"지미 카터 전 대통령은 인권 외교를 강조했으며, 퇴임 후에는 국제 평화와 [MASK] 증진을 위한 활동에 힘썼습니다.\"]\n",
    "\n",
    "\n",
    "run_mlm_predictions(test_data, pre_train_model, vocab, config, top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ec458",
   "metadata": {},
   "source": [
    "### 관측\n",
    "확률이 가장 높은 첫번째 예측 단어는 대부분 앞에 나온 단어와 똑같은 단어를 예측하거나\n",
    "\"또는\"과 같은 접속사들이 대부분이다. 압도적으로 높은 확률을 보이는 단어에 대한 규제가 있으면 예측성능이 올라갈 수 있겠다는 생각이 들었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92547914",
   "metadata": {},
   "source": [
    "### NSP 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "426bd026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NSP 예측 함수 ---\n",
    "def predict_next_sentence(sentence_a, sentence_b, model, vocab_processor, config_obj):\n",
    "    \"\"\"\n",
    "    두 문장이 주어졌을 때, 두 번째 문장이 첫 번째 문장의 다음 문장인지 예측합니다.\n",
    "    :param sentence_a: 첫 번째 문장 문자열.\n",
    "    :param sentence_b: 두 번째 문장 문자열.\n",
    "    :param model: 훈련된 Keras BERT 모델.\n",
    "    :param vocab_processor: SentencePieceProcessor 인스턴스.\n",
    "    :param config_obj: 모델의 설정 객체.\n",
    "    :return: (is_next_probability, is_not_next_probability) 튜플.\n",
    "    \"\"\"\n",
    "    tokens_a = vocab_processor.encode_as_pieces(sentence_a)\n",
    "    tokens_b = vocab_processor.encode_as_pieces(sentence_b)\n",
    "\n",
    "    tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "    \n",
    "    input_ids = [vocab_processor.piece_to_id(p) for p in tokens]\n",
    "    segment_ids = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "    # 패딩\n",
    "    padding_length = config_obj.n_seq - len(input_ids)\n",
    "    if padding_length < 0:\n",
    "        print(f\"경고: 두 문장의 총 길이가 n_seq ({config_obj.n_seq})보다 깁니다. 자릅니다.\")\n",
    "        # BERT의 pretrain 데이터 생성 방식(trim_tokens)과 유사하게 처리할 수 있으나,\n",
    "        # 여기서는 단순하게 최대 길이에 맞춰 자릅니다. 실제 NSP fine-tuning 시에는 더 정교한 처리가 필요할 수 있습니다.\n",
    "        input_ids = input_ids[:config_obj.n_seq]\n",
    "        segment_ids = segment_ids[:config_obj.n_seq]\n",
    "        # [SEP] 토큰이 잘리지 않도록 마지막 토큰은 [SEP]으로 설정 (필요시)\n",
    "        if vocab_processor.piece_to_id(\"[SEP]\") != input_ids[-1]:\n",
    "             input_ids[-1] = vocab_processor.piece_to_id(\"[SEP]\")\n",
    "    else:\n",
    "        input_ids += [vocab_processor.pad_id()] * padding_length\n",
    "        segment_ids += [0] * padding_length # 패딩 부분은 일반적으로 segment 0으로 처리\n",
    "        \n",
    "    input_ids_np = np.array([input_ids])\n",
    "    segment_ids_np = np.array([segment_ids])\n",
    "\n",
    "    nsp_predictions, _ = model.predict((input_ids_np, segment_ids_np), verbose=0)\n",
    "\n",
    "    is_next_prob = nsp_predictions[0][1] # IsNext일 확률\n",
    "    is_not_next_prob = nsp_predictions[0][0] # NotNext일 확률\n",
    "            \n",
    "    return is_next_prob, is_not_next_prob\n",
    "\n",
    "def run_nsp_predictions(sentence_pairs, model, vocab_processor, config_obj):\n",
    "    \"\"\"\n",
    "    문장 쌍 리스트에 대해 NSP 예측을 실행하고 결과를 출력합니다.\n",
    "    :param sentence_pairs: (sentence_a, sentence_b, is_actually_next) 튜플의 리스트.\n",
    "                          is_actually_next는 실제 정답 (True/False)입니다.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- NSP 예측 결과 ---\")\n",
    "    for i, (sent_a, sent_b, actual_is_next) in enumerate(sentence_pairs):\n",
    "        print(f\"\\n테스트 쌍 {i+1}:\")\n",
    "        print(f\"  문장 A: \\\"{sent_a}\\\"\")\n",
    "        print(f\"  문장 B: \\\"{sent_b}\\\"\")\n",
    "        \n",
    "        is_next_prob, is_not_next_prob = predict_next_sentence(sent_a, sent_b, model, vocab_processor, config_obj)\n",
    "        \n",
    "        predicted_is_next = is_next_prob > is_not_next_prob\n",
    "        \n",
    "        print(f\"  실제 다음 문장 여부: {'YES' if actual_is_next else 'NO'}\")\n",
    "        print(f\"  모델 예측: {'YES (다음 문장일 확률: {:.2f}%)' if predicted_is_next else 'NO (다음 문장이 아닐 확률: {:.2f}%)'}\")\n",
    "        print(f\"    (다음 문장일 확률: {is_next_prob:.4f}, 다음 문장이 아닐 확률: {is_not_next_prob:.4f})\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "65edb8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NSP 예측을 시작합니다 (준비된 'pre_train_model' 사용):\n",
      "\n",
      "--- NSP 예측 결과 ---\n",
      "\n",
      "테스트 쌍 1:\n",
      "  문장 A: \"추적추적 비가 내리는 날이었어.\"\n",
      "  문장 B: \"그날은 왠지 손님이 많아 첫 번에 삼십 전 둘째번 오십 전 오랜만에 받아보는 십 전짜리 백통화 서푼에\"\n",
      "  실제 다음 문장 여부: YES\n",
      "  모델 예측: YES (다음 문장일 확률: {:.2f}%)\n",
      "    (다음 문장일 확률: 0.7310, 다음 문장이 아닐 확률: 0.2690)\n",
      "\n",
      "테스트 쌍 2:\n",
      "  문장 A: \"손바닥 위엔 기쁨의 눈물이 흘러.\"\n",
      "  문장 B: \"대한민국은 아시아의 동쪽에 위치한다.\"\n",
      "  실제 다음 문장 여부: NO\n",
      "  모델 예측: YES (다음 문장일 확률: {:.2f}%)\n",
      "    (다음 문장일 확률: 0.7257, 다음 문장이 아닐 확률: 0.2743)\n",
      "\n",
      "테스트 쌍 3:\n",
      "  문장 A: \"이 인공지능 모델은 자연어 처리를 위해 설계되었습니다.\"\n",
      "  문장 B: \"특히 번역과 요약 작업에 뛰어난 성능을 보입니다.\"\n",
      "  실제 다음 문장 여부: YES\n",
      "  모델 예측: YES (다음 문장일 확률: {:.2f}%)\n",
      "    (다음 문장일 확률: 0.7310, 다음 문장이 아닐 확률: 0.2690)\n",
      "\n",
      "테스트 쌍 4:\n",
      "  문장 A: \"오늘 날씨가 정말 좋네요.\"\n",
      "  문장 B: \"내일은 전국적으로 비 소식이 있습니다.\"\n",
      "  실제 다음 문장 여부: YES\n",
      "  모델 예측: YES (다음 문장일 확률: {:.2f}%)\n",
      "    (다음 문장일 확률: 0.7310, 다음 문장이 아닐 확률: 0.2690)\n",
      "\n",
      "테스트 쌍 5:\n",
      "  문장 A: \"주기율표에서 같은 족에 속하는 원소들은 유사한 화학적 성질을 가진다.\"\n",
      "  문장 B: \"빛은 파동성과 입자성을 동시에 지닌다.\"\n",
      "  실제 다음 문장 여부: NO\n",
      "  모델 예측: NO (다음 문장이 아닐 확률: {:.2f}%)\n",
      "    (다음 문장일 확률: 0.2690, 다음 문장이 아닐 확률: 0.7310)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if hasattr(config, 'n_vocab') and config.n_vocab == 0 and 'vocab' in globals():\n",
    "    config.n_vocab = len(vocab)\n",
    "if hasattr(config, 'i_pad') and config.i_pad == 0 and 'vocab' in globals():\n",
    "    config.i_pad = vocab.pad_id()\n",
    "nsp_test_data = [\n",
    "    (\"추적추적 비가 내리는 날이었어.\", \"그날은 왠지 손님이 많아 첫 번에 삼십 전 둘째번 오십 전 오랜만에 받아보는 십 전짜리 백통화 서푼에\", True),\n",
    "    (\"손바닥 위엔 기쁨의 눈물이 흘러.\", \"대한민국은 아시아의 동쪽에 위치한다.\", False),\n",
    "    (\"이 인공지능 모델은 자연어 처리를 위해 설계되었습니다.\", \"특히 번역과 요약 작업에 뛰어난 성능을 보입니다.\", True),\n",
    "    (\"오늘 날씨가 정말 좋네요.\", \"내일은 전국적으로 비 소식이 있습니다.\", True), # 의미상 이어지지만, 직접적인 다음 문장이 아닐 수도 있음 (모델 판단 확인용)\n",
    "    (\"주기율표에서 같은 족에 속하는 원소들은 유사한 화학적 성질을 가진다.\", \"빛은 파동성과 입자성을 동시에 지닌다.\", False)\n",
    "]\n",
    "\n",
    "\n",
    "try:\n",
    "    # 이 변수들이 현재 스코프에 정의되어 있고 올바른 값을 가지고 있어야 합니다.\n",
    "    if 'vocab' in locals() and 'config' in locals() and 'pre_train_model' in locals() and pre_train_model is not None:\n",
    "        # config 객체가 n_vocab과 i_pad를 올바르게 가지고 있는지 확인 (MLM 예시와 동일하게)\n",
    "        if config.n_vocab == 0 or config.i_pad == -1: # vocab.pad_id()가 0일 수 있으므로, 초기화 여부로 판단\n",
    "             config.n_vocab = len(vocab)\n",
    "             config.i_pad = vocab.pad_id()\n",
    "             print(f\"Config 업데이트: n_vocab={config.n_vocab}, i_pad={config.i_pad}\")\n",
    "\n",
    "        print(\"\\nNSP 예측을 시작합니다 (준비된 'pre_train_model' 사용):\")\n",
    "        run_nsp_predictions(nsp_test_data, pre_train_model, vocab, config)\n",
    "    else:\n",
    "        print(\"오류: `vocab`, `config` 또는 `pre_train_model`이 준비되지 않았습니다.\")\n",
    "        print(\"NSP 예측을 실행하려면 이 변수들을 먼저 설정하거나 모델을 로드해야 합니다.\")\n",
    "        print(\"노트북의 이전 셀들을 실행하여 변수들이 준비되었는지 확인하세요.\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"실행 중 오류 발생: {e}\")\n",
    "    print(\"NSP 예측을 실행하기 전에 `vocab`, `config` 객체를 정의하고,\")\n",
    "    print(\"`pre_train_model`을 빌드하고 가중치를 로드해야 합니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615fad04",
   "metadata": {},
   "source": [
    "### 관측\n",
    "생각보다 괜찮은 정답률을 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc3f14a",
   "metadata": {},
   "source": [
    "# 회고\n",
    "두가지를 깨달았다. \n",
    "1. 트랜스포머에 모델에 대한 이해도와 코드를 더욱 공부해야겠다.\n",
    "2. 데이터전처리를 능수능란하게 할 수 있도록 노력해야겠다.\n",
    "\n",
    "BERT모델이 학습을 하는 과정을 텍스트로써는 이해했지만 실제로 확률적으로 중간에 마스킹하는 것과\n",
    "두 텍스트를 연결하면 토큰을 넣는과정에서 어려움을 겪었다.\n",
    "\n",
    "또한 \"또는\"과 같은 접속사가 많은 MLM에서 높은 예측값으로 측정된다.\n",
    "접속사 같은 것들에 대한 문제를 어떻게 해결해야할지 고민을 해보면 좋을 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
